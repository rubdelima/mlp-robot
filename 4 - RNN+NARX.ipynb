{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173d2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "from utils.narxwithga import NARXModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37166ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/input_scaler.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# === Load scalers and model ===\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m input_scaler = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/input_scaler.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m output_scaler = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mmodels/output_scaler.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m X_test_norm = np.load(\u001b[33m\"\u001b[39m\u001b[33mdata/X_test_norm.npy\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode)\u001b[39m\n\u001b[32m    648\u001b[39m         obj = _unpickle(fobj)\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    651\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[32m    652\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    653\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    654\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    655\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models/input_scaler.pkl'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "from utils.narxwithga import NARXModel\n",
    "import pandas as pd\n",
    "\n",
    "# === Load scalers and model ===\n",
    "input_scaler = joblib.load(\"scalers/input_scaler.pkl\")\n",
    "output_scaler = joblib.load(\"scalers/output_scaler.pkl\")\n",
    "X_test_norm = np.load(\"data/X_test_norm.npy\")\n",
    "input_dim = 24  # explicitly use 24 instead of loading from test shape\n",
    "\n",
    "model = NARXModel(input_dim=input_dim, hidden_dim=3, output_dim=2)\n",
    "model.load_state_dict(torch.load(\"models/best_ga_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# === Config ===\n",
    "input_delay = 4\n",
    "output_delay = 4\n",
    "angle_dim = 4\n",
    "coord_dim = 2\n",
    "\n",
    "df = pd.read_csv(\"data/train_data.csv\").dropna()\n",
    "\n",
    "columns = ['0.30','0.50','0.75','0.90','0.95','f']\n",
    "\n",
    "angles = df[['t0', 't1', 't2', 't3']].values\n",
    "coords = df[['xc', 'yc']].values\n",
    "\n",
    "# Use first `input_delay` and `output_delay` for delayed histories\n",
    "delayed_inputs = angles[:input_delay]     # shape: (4, 4)\n",
    "delayed_outputs = coords[:output_delay]   # shape: (4, 2)\n",
    "\n",
    "def run_narx(input_angles):\n",
    "    \"\"\"\n",
    "    Predicts (x, y) coordinates from a batch of joint angle predictions (Tensor).\n",
    "    input_angles: Tensor of shape (batch_size, 4)\n",
    "    Returns: Tensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    if input_angles.requires_grad:\n",
    "        input_angles = input_angles.detach()\n",
    "\n",
    "    input_angles = input_angles.cpu().numpy()\n",
    "    \n",
    "    preds = []\n",
    "    for angles in input_angles:\n",
    "        # Shift histories\n",
    "        global delayed_inputs, delayed_outputs\n",
    "        delayed_inputs = np.roll(delayed_inputs, shift=-1, axis=0)\n",
    "        delayed_outputs = np.roll(delayed_outputs, shift=-1, axis=0)\n",
    "\n",
    "        delayed_inputs[-1] = angles\n",
    "\n",
    "        flat_outputs = delayed_outputs.flatten()   # 4 * 2 = 8\n",
    "        flat_inputs = delayed_inputs.flatten()     # 4 * 4 = 16\n",
    "\n",
    "        narx_input = np.concatenate([flat_outputs, flat_inputs])  # 8 + 16 = 24\n",
    "\n",
    "        narx_input_scaled = input_scaler.transform([narx_input])\n",
    "        input_tensor = torch.tensor(narx_input_scaled, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = model(input_tensor).detach().numpy()\n",
    "            pred_original = output_scaler.inverse_transform(pred_scaled)\n",
    "\n",
    "        delayed_outputs[-1] = pred_original[0]\n",
    "        preds.append(pred_original[0])\n",
    "\n",
    "    return torch.tensor(preds, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ad9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rnn import ControlRNN\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f11038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model = ControlRNN(input_size=4, hidden_size=300, num_layers=1, dropout_rate=0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rnn_model.load_state_dict(torch.load(\"models/nn_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84b28a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1993)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_hist = torch.Tensor([[-5.652, 2.412, 6.1773],\n",
    "                              [-5.652, 2.412, 6.1773],\n",
    "                              [-5.652, 2.412, 6.1773],\n",
    "                              [-5.652, 2.412, 6.1773]])\n",
    "#torch.Tensor([[-0.77910448,  0.7426087,   1.08560483]])\n",
    "teste_pos = torch.Tensor((0.1, 0.1))\n",
    "\n",
    "((pos_hist[0][0]-teste_pos[0])**2 + (pos_hist[0][1]-teste_pos[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b9d6a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.6520,  2.4120,  6.1773],\n",
       "        [-5.6520,  2.4120,  6.1773],\n",
       "        [-5.6520,  2.4120,  6.1773],\n",
       "        [ 1.0000,  2.0000,  3.0000]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([pos_hist[1:], torch.Tensor([[1,2,3]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d814cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_pos(curr, tgt):\n",
    "    return ((curr[0]-tgt[0])**2 + (curr[1]-tgt[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b0767da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1993)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = dist_pos(pos_hist[-1], teste_pos)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8257ecd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae876820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.6520,  2.4120,  6.1773],\n",
       "         [-5.6520,  2.4120,  6.1773],\n",
       "         [-5.6520,  2.4120,  6.1773],\n",
       "         [-5.6520,  2.4120,  6.1773]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_hist.reshape(1,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27b29c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 29.0643,  60.5607, 145.2716,  80.9824], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0e3607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_18036\\113800326.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  return torch.tensor(preds, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4.8368, 0.7402],\n",
       "        [4.5515, 0.7548],\n",
       "        [4.5053, 1.4695],\n",
       "        [3.5248, 3.6261]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.tensor([0, 3, 4, 5], dtype=torch.float32)\n",
    "run_narx(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4e9c3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "099b5c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 4., 5.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.reshape(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80426423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 29.0643,  60.5607, 145.2716,  80.9824], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_pred.reshape(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e7c9fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.6520,  2.4120,  6.1773],\n",
       "        [-5.6520,  2.4120,  6.1773],\n",
       "        [-5.6520,  2.4120,  6.1773],\n",
       "        [-5.6520,  2.4120,  6.1773]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74b4d823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.2734,  16.3800],\n",
       "        [-12.2195,  38.2576],\n",
       "        [-47.7669, 116.4481],\n",
       "        [-27.5932,  72.0737]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_pred = rnn_model(pos_hist.reshape(1,4,3))\n",
    "pos = run_narx(theta_pred.reshape(4))\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = dist_pos(pos_hist[-1], teste_pos)\n",
    "\n",
    "while(dist>0.005):\n",
    "    theta_pred = rnn_model(pos_hist)\n",
    "    pos = narx_model(theta_pred)\n",
    "    #pos_hist = \n",
    "    #pos_hist = narx_model(theta_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils.functions import img2real\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>xc_px</th>\n",
       "      <th>yc_px</th>\n",
       "      <th>xc</th>\n",
       "      <th>yc</th>\n",
       "      <th>diagonal</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>30.100908</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>73.389373</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>33.363423</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-264.0</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>72.801099</td>\n",
       "      <td>0.988214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>36.636577</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-249.0</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.942609</td>\n",
       "      <td>72.780492</td>\n",
       "      <td>0.974219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>39.899092</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>0.728358</td>\n",
       "      <td>0.918261</td>\n",
       "      <td>72.835431</td>\n",
       "      <td>0.958709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>43.130102</td>\n",
       "      <td>31.753588</td>\n",
       "      <td>71.469230</td>\n",
       "      <td>39.715641</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>75.239617</td>\n",
       "      <td>0.957535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y     z         t0         t1         t2         t3  xc_px  \\\n",
       "7   0.16 -0.19  0.12  30.100908  33.948155  75.041009  41.092854  145.0   \n",
       "8   0.17 -0.18  0.12  33.363423  34.952635  76.655631  41.702995  160.0   \n",
       "9   0.18 -0.17  0.12  36.636577  34.952635  76.655631  41.702995  178.0   \n",
       "10  0.19 -0.16  0.12  39.899092  33.948155  75.041009  41.092854  191.0   \n",
       "11  0.20 -0.15  0.12  43.130102  31.753588  71.469230  39.715641  208.0   \n",
       "\n",
       "    yc_px        xc        yc   diagonal     error  \n",
       "7  -275.0  0.591045  0.987826  73.389373  1.000000  \n",
       "8  -264.0  0.635821  0.968696  72.801099  0.988214  \n",
       "9  -249.0  0.689552  0.942609  72.780492  0.974219  \n",
       "10 -235.0  0.728358  0.918261  72.835431  0.958709  \n",
       "11 -222.0  0.779104  0.895652  75.239617  0.957535  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_data.csv')\n",
    "df = df.dropna()\n",
    "df['error'] = np.sqrt((df['x']-df['xc'])**2 + (df['y']-df['yc'])**2)\n",
    "\n",
    "min_max_scalers = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in  ['xc', 'yc', 'error']:\n",
    "        min_max_scalers[column] = MinMaxScaler() #(df[column].min(), df[column].max())\n",
    "        df[column] = min_max_scalers[column].fit_transform(df[[column]])\n",
    "        with open('scalers/'+column+'.pkl', 'wb') as f:\n",
    "            pickle.dump(min_max_scalers[column], f)\n",
    "\n",
    "#with open('data/min_max_scalers.json', 'w') as f:\n",
    "#    json.dump(min_max_scalers, f)\n",
    "\n",
    "df.to_csv(f\"data/train_data_clean.csv\", index=False) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.652, 2.412)\n",
      "6.177354854628314\n",
      "[-0.77910448  0.7426087   1.08560483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pos_inicial = img2real((314,134),27) # pos_inicial e cameraHeight utilizado\n",
    "print(pos_inicial)\n",
    "\n",
    "error_start = np.sqrt((0.035-pos_inicial[0])**2 + (0-pos_inicial[1])**2)\n",
    "print(error_start)\n",
    "\n",
    "pos_inicial = np.array([\n",
    "    min_max_scalers['xc'].transform(np.array(pos_inicial[0]).reshape(1, -1))[0][0],\n",
    "    min_max_scalers['yc'].transform(np.array(pos_inicial[1]).reshape(1, -1))[0][0],\n",
    "    min_max_scalers['error'].transform(np.array(error_start).reshape(1, -1))[0][0]\n",
    "])\n",
    "\n",
    "print(pos_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_10376\\1405297032.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  output_data = torch.cat((output_data, torch.Tensor([row[['t0','t1','t2','t3']].values])))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1134,  0.6122,  0.1981],\n",
       "         [ 0.2119,  0.6817,  0.3258],\n",
       "         [ 0.4060,  0.8383,  0.6644]],\n",
       "\n",
       "        [[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1194,  0.5878,  0.1519],\n",
       "         [ 0.2119,  0.6817,  0.3258],\n",
       "         [ 0.4090,  0.8087,  0.6138]],\n",
       "\n",
       "        [[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1194,  0.5878,  0.1519],\n",
       "         [ 0.2687,  0.6713,  0.3185],\n",
       "         [ 0.4567,  0.7826,  0.5913]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1015,  0.4400,  0.1445],\n",
       "         [ 0.1015,  0.4400,  0.1445],\n",
       "         [ 0.1015,  0.4400,  0.1445]],\n",
       "\n",
       "        [[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1254,  0.4678,  0.0843],\n",
       "         [ 0.1254,  0.4678,  0.0843],\n",
       "         [ 0.1254,  0.4678,  0.0843]],\n",
       "\n",
       "        [[-0.7791,  0.7426,  1.0856],\n",
       "         [ 0.1403,  0.4765,  0.0614],\n",
       "         [ 0.1403,  0.4765,  0.0614],\n",
       "         [ 0.1403,  0.4765,  0.0614]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perc_pos(value, perc):\n",
    "    return int(value*perc)/100\n",
    "\n",
    "pos_inicial = pos_inicial.reshape(1,-1)\n",
    "input_data = torch.Tensor()\n",
    "output_data = torch.Tensor()\n",
    "\n",
    "for i in range(len(df)):\n",
    "     row = df.iloc[i]\n",
    "     x_fin, y_fin = row['x']*100, row['y']*100\n",
    "     pos_hist = torch.Tensor(pos_inicial)\n",
    "     for p in [0.25, 0.5, 0.75]:\n",
    "          check=True\n",
    "          while(check):\n",
    "               path_x = perc_pos(x_fin,p)\n",
    "               path_y = perc_pos(y_fin,p)\n",
    "               pos = df.loc[(df.x==path_x)&(df.y==path_y),['xc','yc','error']].values\n",
    "               if(pos.size==0):\n",
    "                    p += 0.05\n",
    "               else:\n",
    "                    check = False\n",
    "          pos_hist = torch.cat((pos_hist, torch.Tensor(pos)))\n",
    "     input_data = torch.cat((input_data, pos_hist.unsqueeze(0)))\n",
    "     output_data = torch.cat((output_data, torch.Tensor([row[['t0','t1','t2','t3']].values])))\n",
    "\n",
    "input_data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.1009,  33.9482,  75.0410,  41.0929],\n",
       "        [ 33.3634,  34.9526,  76.6556,  41.7030],\n",
       "        [ 36.6366,  34.9526,  76.6556,  41.7030],\n",
       "        ...,\n",
       "        [125.0000, 146.0643, 172.2480,  26.1836],\n",
       "        [110.9638, 152.7918, 172.6161,  19.8243],\n",
       "        [106.5650, 148.0869, 172.4426,  24.3557]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_test = X_test[4:,:,:]\n",
    "y_test = y_test[4:,:] # p/ evitar data leakage\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Separação em conj de validação\n",
    "#X_train, y_train, X_val, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "#train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Val-MSE: 32.721\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:relu, o:adam, wd:0\n",
      "[2] Val-MSE: 32.682\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:relu, o:adam, wd:0.0005\n",
      "[3] Val-MSE: 31.027\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:relu, o:sgd, wd:0\n",
      "[4] Val-MSE: 33.874\n",
      "[5] Val-MSE: 68.404\n",
      "[6] Val-MSE: 68.613\n",
      "[7] Val-MSE: 30.690\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:tanh, o:sgd, wd:0\n",
      "[8] Val-MSE: 30.674\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:tanh, o:sgd, wd:0.0005\n",
      "[9] Val-MSE: 28.743\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:relu, o:adam, wd:0\n",
      "[10] Val-MSE: 28.708\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:relu, o:adam, wd:0.0005\n",
      "[11] Val-MSE: nan\n",
      "[12] Val-MSE: nan\n",
      "[13] Val-MSE: 33.547\n",
      "[14] Val-MSE: 33.636\n",
      "[15] Val-MSE: 28.989\n",
      "[16] Val-MSE: 29.004\n",
      "[17] Val-MSE: 23.636\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.01, a:relu, o:adam, wd:0\n",
      "[18] Val-MSE: 26.732\n",
      "[19] Val-MSE: nan\n",
      "[20] Val-MSE: nan\n",
      "[21] Val-MSE: 28.903\n",
      "[22] Val-MSE: 28.902\n",
      "[23] Val-MSE: 32.273\n",
      "[24] Val-MSE: 32.274\n",
      "[25] Val-MSE: 31.684\n",
      "[26] Val-MSE: 31.631\n",
      "[27] Val-MSE: 32.356\n",
      "[28] Val-MSE: 33.916\n",
      "[29] Val-MSE: 69.384\n",
      "[30] Val-MSE: 69.107\n",
      "[31] Val-MSE: 30.197\n",
      "[32] Val-MSE: 30.272\n",
      "[33] Val-MSE: 26.555\n",
      "[34] Val-MSE: 26.238\n",
      "[35] Val-MSE: nan\n",
      "[36] Val-MSE: nan\n",
      "[37] Val-MSE: 33.739\n",
      "[38] Val-MSE: 33.745\n",
      "[39] Val-MSE: 29.074\n",
      "[40] Val-MSE: 29.075\n",
      "[41] Val-MSE: 15.509\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:2, dr:0, lr:0.01, a:relu, o:adam, wd:0\n",
      "[42] Val-MSE: 18.416\n",
      "[43] Val-MSE: nan\n",
      "[44] Val-MSE: nan\n",
      "[45] Val-MSE: 28.901\n",
      "[46] Val-MSE: 28.901\n",
      "[47] Val-MSE: 32.281\n",
      "[48] Val-MSE: 32.281\n",
      "[49] Val-MSE: 31.513\n",
      "[50] Val-MSE: 31.509\n",
      "[51] Val-MSE: 33.554\n",
      "[52] Val-MSE: 34.250\n",
      "[53] Val-MSE: 69.387\n",
      "[54] Val-MSE: 69.034\n",
      "[55] Val-MSE: 30.220\n",
      "[56] Val-MSE: 30.222\n",
      "[57] Val-MSE: 25.717\n",
      "[58] Val-MSE: 26.410\n",
      "[59] Val-MSE: nan\n",
      "[60] Val-MSE: nan\n",
      "[61] Val-MSE: 33.782\n",
      "[62] Val-MSE: 33.715\n",
      "[63] Val-MSE: 29.075\n",
      "[64] Val-MSE: 29.074\n",
      "[65] Val-MSE: 16.549\n",
      "[66] Val-MSE: 19.659\n",
      "[67] Val-MSE: nan\n",
      "[68] Val-MSE: nan\n",
      "[69] Val-MSE: 28.901\n",
      "[70] Val-MSE: 28.901\n",
      "[71] Val-MSE: 32.282\n",
      "[72] Val-MSE: 32.282\n",
      "[73] Val-MSE: 31.629\n",
      "[74] Val-MSE: 31.596\n",
      "[75] Val-MSE: 31.941\n",
      "[76] Val-MSE: 34.071\n",
      "[77] Val-MSE: 69.027\n",
      "[78] Val-MSE: 69.049\n",
      "[79] Val-MSE: 30.170\n",
      "[80] Val-MSE: 30.283\n",
      "[81] Val-MSE: 27.622\n",
      "[82] Val-MSE: 26.737\n",
      "[83] Val-MSE: nan\n",
      "[84] Val-MSE: nan\n",
      "[85] Val-MSE: 33.678\n",
      "[86] Val-MSE: 33.678\n",
      "[87] Val-MSE: 29.071\n",
      "[88] Val-MSE: 29.072\n",
      "[89] Val-MSE: 18.650\n",
      "[90] Val-MSE: 20.715\n",
      "[91] Val-MSE: nan\n",
      "[92] Val-MSE: nan\n",
      "[93] Val-MSE: 28.902\n",
      "[94] Val-MSE: 28.903\n",
      "[95] Val-MSE: 32.283\n",
      "[96] Val-MSE: 32.276\n",
      "[97] Val-MSE: 37.655\n",
      "[98] Val-MSE: 38.366\n",
      "[99] Val-MSE: 31.373\n",
      "[100] Val-MSE: 33.638\n",
      "[101] Val-MSE: 84.111\n",
      "[102] Val-MSE: 84.173\n",
      "[103] Val-MSE: 34.086\n",
      "[104] Val-MSE: 34.062\n",
      "[105] Val-MSE: 29.365\n",
      "[106] Val-MSE: 29.338\n",
      "[107] Val-MSE: 66.255\n",
      "[108] Val-MSE: nan\n",
      "[109] Val-MSE: 45.726\n",
      "[110] Val-MSE: 45.854\n",
      "[111] Val-MSE: 28.725\n",
      "[112] Val-MSE: 28.877\n",
      "[113] Val-MSE: 24.727\n",
      "[114] Val-MSE: 26.006\n",
      "[115] Val-MSE: nan\n",
      "[116] Val-MSE: nan\n",
      "[117] Val-MSE: 29.627\n",
      "[118] Val-MSE: 29.651\n",
      "[119] Val-MSE: 29.975\n",
      "[120] Val-MSE: 29.976\n",
      "[121] Val-MSE: 34.670\n",
      "[122] Val-MSE: 34.425\n",
      "[123] Val-MSE: 33.043\n",
      "[124] Val-MSE: 33.926\n",
      "[125] Val-MSE: 84.518\n",
      "[126] Val-MSE: 84.328\n",
      "[127] Val-MSE: 33.529\n",
      "[128] Val-MSE: 33.476\n",
      "[129] Val-MSE: 28.646\n",
      "[130] Val-MSE: 28.618\n",
      "[131] Val-MSE: nan\n",
      "[132] Val-MSE: nan\n",
      "[133] Val-MSE: 46.403\n",
      "[134] Val-MSE: 46.451\n",
      "[135] Val-MSE: 28.916\n",
      "[136] Val-MSE: 28.915\n",
      "[137] Val-MSE: 21.215\n",
      "[138] Val-MSE: 20.646\n",
      "[139] Val-MSE: nan\n",
      "[140] Val-MSE: nan\n",
      "[141] Val-MSE: 29.651\n",
      "[142] Val-MSE: 29.659\n",
      "[143] Val-MSE: 29.972\n",
      "[144] Val-MSE: 29.970\n",
      "[145] Val-MSE: 34.158\n",
      "[146] Val-MSE: 34.805\n",
      "[147] Val-MSE: 33.773\n",
      "[148] Val-MSE: 32.454\n",
      "[149] Val-MSE: 84.372\n",
      "[150] Val-MSE: 84.429\n",
      "[151] Val-MSE: 33.403\n",
      "[152] Val-MSE: 33.483\n",
      "[153] Val-MSE: 26.929\n",
      "[154] Val-MSE: 27.916\n",
      "[155] Val-MSE: nan\n",
      "[156] Val-MSE: nan\n",
      "[157] Val-MSE: 46.262\n",
      "[158] Val-MSE: 46.084\n",
      "[159] Val-MSE: 28.916\n",
      "[160] Val-MSE: 28.915\n",
      "[161] Val-MSE: 18.303\n",
      "[162] Val-MSE: 18.207\n",
      "[163] Val-MSE: nan\n",
      "[164] Val-MSE: nan\n",
      "[165] Val-MSE: 29.655\n",
      "[166] Val-MSE: 29.646\n",
      "[167] Val-MSE: 29.977\n",
      "[168] Val-MSE: 29.980\n",
      "[169] Val-MSE: 34.399\n",
      "[170] Val-MSE: 34.966\n",
      "[171] Val-MSE: 34.023\n",
      "[172] Val-MSE: 33.974\n",
      "[173] Val-MSE: 84.186\n",
      "[174] Val-MSE: 84.621\n",
      "[175] Val-MSE: 33.667\n",
      "[176] Val-MSE: 33.774\n",
      "[177] Val-MSE: 28.802\n",
      "[178] Val-MSE: 28.713\n",
      "[179] Val-MSE: nan\n",
      "[180] Val-MSE: nan\n",
      "[181] Val-MSE: 46.328\n",
      "[182] Val-MSE: 46.257\n",
      "[183] Val-MSE: 28.916\n",
      "[184] Val-MSE: 28.915\n",
      "[185] Val-MSE: 22.156\n",
      "[186] Val-MSE: 22.356\n",
      "[187] Val-MSE: nan\n",
      "[188] Val-MSE: nan\n",
      "[189] Val-MSE: 29.640\n",
      "[190] Val-MSE: 29.648\n",
      "[191] Val-MSE: 29.981\n",
      "[192] Val-MSE: 29.979\n",
      "[193] Val-MSE: 45.937\n",
      "[194] Val-MSE: 45.694\n",
      "[195] Val-MSE: 31.146\n",
      "[196] Val-MSE: 33.657\n",
      "[197] Val-MSE: 89.064\n",
      "[198] Val-MSE: 89.262\n",
      "[199] Val-MSE: 38.673\n",
      "[200] Val-MSE: 38.777\n",
      "[201] Val-MSE: 30.206\n",
      "[202] Val-MSE: 30.471\n",
      "[203] Val-MSE: nan\n",
      "[204] Val-MSE: nan\n",
      "[205] Val-MSE: 60.577\n",
      "[206] Val-MSE: 60.134\n",
      "[207] Val-MSE: 29.078\n",
      "[208] Val-MSE: 29.076\n",
      "[209] Val-MSE: 26.401\n",
      "[210] Val-MSE: 28.124\n",
      "[211] Val-MSE: nan\n",
      "[212] Val-MSE: 32.548\n",
      "[213] Val-MSE: 31.439\n",
      "[214] Val-MSE: 31.475\n",
      "[215] Val-MSE: 29.354\n",
      "[216] Val-MSE: 29.354\n",
      "[217] Val-MSE: 39.733\n",
      "[218] Val-MSE: 39.258\n",
      "[219] Val-MSE: 33.843\n",
      "[220] Val-MSE: 34.269\n",
      "[221] Val-MSE: 89.155\n",
      "[222] Val-MSE: 89.289\n",
      "[223] Val-MSE: 38.748\n",
      "[224] Val-MSE: 38.556\n",
      "[225] Val-MSE: 29.282\n",
      "[226] Val-MSE: 28.967\n",
      "[227] Val-MSE: nan\n",
      "[228] Val-MSE: nan\n",
      "[229] Val-MSE: 60.924\n",
      "[230] Val-MSE: 60.782\n",
      "[231] Val-MSE: 29.056\n",
      "[232] Val-MSE: 29.056\n",
      "[233] Val-MSE: 24.827\n",
      "[234] Val-MSE: 22.337\n",
      "[235] Val-MSE: nan\n",
      "[236] Val-MSE: nan\n",
      "[237] Val-MSE: 31.501\n",
      "[238] Val-MSE: 31.482\n",
      "[239] Val-MSE: 29.353\n",
      "[240] Val-MSE: 29.353\n",
      "[241] Val-MSE: 38.702\n",
      "[242] Val-MSE: 39.445\n",
      "[243] Val-MSE: 33.904\n",
      "[244] Val-MSE: 34.512\n",
      "[245] Val-MSE: 89.048\n",
      "[246] Val-MSE: 89.300\n",
      "[247] Val-MSE: 38.153\n",
      "[248] Val-MSE: 38.294\n",
      "[249] Val-MSE: 29.682\n",
      "[250] Val-MSE: 29.488\n",
      "[251] Val-MSE: nan\n",
      "[252] Val-MSE: nan\n",
      "[253] Val-MSE: 61.085\n",
      "[254] Val-MSE: 60.684\n",
      "[255] Val-MSE: 29.059\n",
      "[256] Val-MSE: 29.073\n",
      "[257] Val-MSE: 19.034\n",
      "[258] Val-MSE: 21.816\n",
      "[259] Val-MSE: nan\n",
      "[260] Val-MSE: nan\n",
      "[261] Val-MSE: 31.480\n",
      "[262] Val-MSE: 31.463\n",
      "[263] Val-MSE: 29.354\n",
      "[264] Val-MSE: 29.354\n",
      "[265] Val-MSE: 39.632\n",
      "[266] Val-MSE: 37.866\n",
      "[267] Val-MSE: 32.011\n",
      "[268] Val-MSE: 33.131\n",
      "[269] Val-MSE: 89.317\n",
      "[270] Val-MSE: 89.255\n",
      "[271] Val-MSE: 38.310\n",
      "[272] Val-MSE: 38.502\n",
      "[273] Val-MSE: 30.090\n",
      "[274] Val-MSE: 29.517\n",
      "[275] Val-MSE: nan\n",
      "[276] Val-MSE: nan\n",
      "[277] Val-MSE: 60.933\n",
      "[278] Val-MSE: 60.888\n",
      "[279] Val-MSE: 29.063\n",
      "[280] Val-MSE: 29.061\n",
      "[281] Val-MSE: 24.230\n",
      "[282] Val-MSE: 26.427\n",
      "[283] Val-MSE: nan\n",
      "[284] Val-MSE: nan\n",
      "[285] Val-MSE: 31.472\n",
      "[286] Val-MSE: 31.429\n",
      "[287] Val-MSE: 29.362\n",
      "[288] Val-MSE: 29.354\n",
      "Predição: tensor([[ 24.7151,  41.8472,  93.3944,  50.0768],\n",
      "        [ 28.4684,  46.8122,  98.0769,  50.2941],\n",
      "        [ 28.4283,  45.2733,  96.5983,  50.2562],\n",
      "        ...,\n",
      "        [118.1764, 127.5663, 168.3664,  38.4972],\n",
      "        [105.5752, 134.1811, 174.4617,  37.8972],\n",
      "        [ 99.6639, 136.2195, 176.3994,  37.8221]])\n"
     ]
    }
   ],
   "source": [
    "# Dados de exemplo\n",
    "# Suponha batch_size = 1, seq_len = 4, input_size = 2 (x, y)\n",
    "from itertools import product\n",
    "from utils.rnn import ControlRNN, train_net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Inicializa a RNN\n",
    "model = ControlRNN(input_size=4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "hidden_size = [300, 100, 50]\n",
    "num_layers = [1,2]\n",
    "dropout_rate = [0,0.25,0.75]\n",
    "learning_rate = [0.0001, 0.001, 0.01]\n",
    "weight_decay = [0, 0.0005]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adam', 'sgd']\n",
    "best_model = None\n",
    "best_score = None\n",
    "\n",
    "params_grid = product(hidden_size, num_layers, dropout_rate, learning_rate,\n",
    "                      activation, optimizer, weight_decay)\n",
    "\n",
    "count = 1\n",
    "for hs, nl, dr, lr, a, o, wd in params_grid:\n",
    "    if(not((dr>0) and (nl==1))):\n",
    "        model = ControlRNN(input_size=3, hidden_size=hs, \n",
    "                        num_layers=nl,\n",
    "                        activation=a, dropout_rate=dr)\n",
    "        if(o=='adam'):\n",
    "            opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        \n",
    "        model, _, scores = train_net(model, train_loader, test_loader, 25, opt, verbose=0)\n",
    "        score = np.mean(scores[1])\n",
    "        print(f'[{count}] Val-MSE: {score:.3f}')\n",
    "        if(best_score is None or best_score > score):\n",
    "            print('[Melhor modelo atualizado]')\n",
    "            print('hs:{}, nl:{}, dr:{}, lr:{}, a:{}, o:{}, wd:{}'.format(hs, nl, dr, lr, a, o, wd))\n",
    "            best_model = model\n",
    "            best_score = score\n",
    "        count += 1\n",
    "                                \n",
    "\n",
    "# Teste\n",
    "predicted = best_model(input_data).detach()\n",
    "print(\"Predição:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 40.5490\n",
      "RMSE: 6.3678\n"
     ]
    }
   ],
   "source": [
    "predicted = best_model(X_test).detach()\n",
    "\n",
    "score = ((predicted - y_test)**2).mean()\n",
    "\n",
    "print(f'''MSE: {score:.4f}\n",
    "RMSE: {score**0.5:.4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlRNN(\n",
       "  (rnn): RNN(3, 300, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=300, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor modelo:\n",
    "\n",
    "- Número de camadas recorrentes: 2\n",
    "- Número de neurônios ocultos: 300\n",
    "- Funcção de ativação: ReLU\n",
    "- Taxa de dropout: 0\n",
    "- Ottimizador: Adam\n",
    "- Learning rate: 0.01\n",
    "- Weight decay: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(, 'wb') as f:\n",
    "best_model.eval()\n",
    "torch.save(best_model.state_dict(), 'models/nn_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

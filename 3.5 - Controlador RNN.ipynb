{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils.functions import img2real\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>xe</th>\n",
       "      <th>ye</th>\n",
       "      <th>ze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15398</td>\n",
       "      <td>-0.112200</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>0.16352</td>\n",
       "      <td>-0.081858</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>0.14995</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>-0.029064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>0.16150</td>\n",
       "      <td>-0.064625</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>-0.020419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>0.16352</td>\n",
       "      <td>-0.081858</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>0.16783</td>\n",
       "      <td>-0.086808</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-0.007839</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y     z        xe        ye   ze\n",
       "0     0.00000  0.000000  0.00  0.000000  0.000000  0.0\n",
       "1     0.00000  0.000000  0.00  0.000000  0.000000  0.0\n",
       "2     0.00000  0.000000  0.00  0.000000  0.000000  0.0\n",
       "3     0.15398 -0.112200  0.12  0.014152  0.047550  0.0\n",
       "4     0.00000  0.000000  0.00  0.000000  0.000000  0.0\n",
       "...       ...       ...   ...       ...       ...  ...\n",
       "4047  0.16352 -0.081858  0.12  0.003757 -0.009588  0.0\n",
       "4048  0.14995 -0.043175  0.12  0.011834 -0.029064  0.0\n",
       "4049  0.16150 -0.064625  0.12  0.003944 -0.020419  0.0\n",
       "4050  0.16352 -0.081858  0.12  0.003757 -0.009588  0.0\n",
       "4051  0.16783 -0.086808  0.12  0.000363 -0.007839  0.0\n",
       "\n",
       "[4052 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('data/X.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.305360</td>\n",
       "      <td>1.5018</td>\n",
       "      <td>-1.3873</td>\n",
       "      <td>0.060087</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.155500</td>\n",
       "      <td>1.4828</td>\n",
       "      <td>-1.3671</td>\n",
       "      <td>0.058877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.141360</td>\n",
       "      <td>1.4745</td>\n",
       "      <td>-1.3582</td>\n",
       "      <td>0.058254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.081871</td>\n",
       "      <td>1.4284</td>\n",
       "      <td>-1.3077</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.081871</td>\n",
       "      <td>1.4284</td>\n",
       "      <td>-1.3077</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>-0.182560</td>\n",
       "      <td>1.5801</td>\n",
       "      <td>-1.4675</td>\n",
       "      <td>0.061984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>-0.295830</td>\n",
       "      <td>1.4827</td>\n",
       "      <td>-1.3671</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>-0.355970</td>\n",
       "      <td>1.4248</td>\n",
       "      <td>-1.3037</td>\n",
       "      <td>0.053386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>-0.355970</td>\n",
       "      <td>1.4248</td>\n",
       "      <td>-1.3037</td>\n",
       "      <td>0.053386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>-0.355970</td>\n",
       "      <td>1.4248</td>\n",
       "      <td>-1.3037</td>\n",
       "      <td>0.053386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t0      t1      t2        t3  t4  t5\n",
       "0    -0.305360  1.5018 -1.3873  0.060087   0   0\n",
       "1    -0.155500  1.4828 -1.3671  0.058877   0   0\n",
       "2    -0.141360  1.4745 -1.3582  0.058254   0   0\n",
       "3    -0.081871  1.4284 -1.3077  0.053806   0   0\n",
       "4    -0.081871  1.4284 -1.3077  0.053806   0   0\n",
       "...        ...     ...     ...       ...  ..  ..\n",
       "1008 -0.182560  1.5801 -1.4675  0.061984   0   0\n",
       "1009 -0.295830  1.4827 -1.3671  0.058875   0   0\n",
       "1010 -0.355970  1.4248 -1.3037  0.053386   0   0\n",
       "1011 -0.355970  1.4248 -1.3037  0.053386   0   0\n",
       "1012 -0.355970  1.4248 -1.3037  0.053386   0   0\n",
       "\n",
       "[1013 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/y.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>xc_px</th>\n",
       "      <th>yc_px</th>\n",
       "      <th>xc</th>\n",
       "      <th>yc</th>\n",
       "      <th>diagonal</th>\n",
       "      <th>xe</th>\n",
       "      <th>ye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>30.100908</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>73.389373</td>\n",
       "      <td>0.411584</td>\n",
       "      <td>0.012639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>33.363423</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-264.0</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>72.801099</td>\n",
       "      <td>0.367291</td>\n",
       "      <td>0.031970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>36.636577</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-249.0</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.942609</td>\n",
       "      <td>72.780492</td>\n",
       "      <td>0.313799</td>\n",
       "      <td>0.057993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>39.899092</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>0.728358</td>\n",
       "      <td>0.918261</td>\n",
       "      <td>72.835431</td>\n",
       "      <td>0.275639</td>\n",
       "      <td>0.082342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>43.130102</td>\n",
       "      <td>31.753588</td>\n",
       "      <td>71.469230</td>\n",
       "      <td>39.715641</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>75.239617</td>\n",
       "      <td>0.225213</td>\n",
       "      <td>0.105019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y     z         t0         t1         t2         t3  xc_px  \\\n",
       "7   0.16 -0.19  0.12  30.100908  33.948155  75.041009  41.092854  145.0   \n",
       "8   0.17 -0.18  0.12  33.363423  34.952635  76.655631  41.702995  160.0   \n",
       "9   0.18 -0.17  0.12  36.636577  34.952635  76.655631  41.702995  178.0   \n",
       "10  0.19 -0.16  0.12  39.899092  33.948155  75.041009  41.092854  191.0   \n",
       "11  0.20 -0.15  0.12  43.130102  31.753588  71.469230  39.715641  208.0   \n",
       "\n",
       "    yc_px        xc        yc   diagonal        xe        ye  \n",
       "7  -275.0  0.591045  0.987826  73.389373  0.411584  0.012639  \n",
       "8  -264.0  0.635821  0.968696  72.801099  0.367291  0.031970  \n",
       "9  -249.0  0.689552  0.942609  72.780492  0.313799  0.057993  \n",
       "10 -235.0  0.728358  0.918261  72.835431  0.275639  0.082342  \n",
       "11 -222.0  0.779104  0.895652  75.239617  0.225213  0.105019  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_data.csv')\n",
    "df = df.dropna()\n",
    "#df['error'] = np.sqrt((df['x']-df['xc'])**2 + (df['y']-df['yc'])**2)\n",
    "df['xe'] = df['x']-df['xc']\n",
    "df['ye'] = df['y']-df['yc']\n",
    "\n",
    "min_max_scalers = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in  ['xc', 'yc', 'xe', 'ye']:\n",
    "        min_max_scalers[column] = MinMaxScaler() #(df[column].min(), df[column].max())\n",
    "        df[column] = min_max_scalers[column].fit_transform(df[[column]])\n",
    "        with open('scalers/'+column+'.pkl', 'wb') as f:\n",
    "            pickle.dump(min_max_scalers[column], f)\n",
    "\n",
    "#with open('data/min_max_scalers.json', 'w') as f:\n",
    "#    json.dump(min_max_scalers, f)\n",
    "\n",
    "df.to_csv(f\"data/train_data_clean.csv\", index=False) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.652, 2.412)\n",
      "5.687 -2.412\n",
      "[-0.77910448  0.7426087   1.79778535  0.266171  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pos_inicial = img2real((314,134),27) # pos_inicial e cameraHeight utilizado\n",
    "print(pos_inicial)\n",
    "\n",
    "#error_start = np.sqrt((0.035-pos_inicial[0])**2 + (0-pos_inicial[1])**2)\n",
    "xe_start = 0.035-pos_inicial[0]\n",
    "ye_start = 0-pos_inicial[1]\n",
    "print(xe_start, ye_start)\n",
    "\n",
    "pos_inicial = np.array([\n",
    "    min_max_scalers['xc'].transform(np.array(pos_inicial[0]).reshape(1, -1))[0][0],\n",
    "    min_max_scalers['yc'].transform(np.array(pos_inicial[1]).reshape(1, -1))[0][0],\n",
    "    min_max_scalers['xe'].transform(np.array(xe_start).reshape(1, -1))[0][0],\n",
    "    min_max_scalers['ye'].transform(np.array(ye_start).reshape(1, -1))[0][0]\n",
    "])\n",
    "\n",
    "print(pos_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_start = df.iloc[2]\n",
    "row_start[['xc','yc','xe','ye']].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 path added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1731, 0.4087, 0.8256, 0.5929],\n",
       "         [0.2537, 0.4817, 0.7462, 0.5190],\n",
       "         [0.3254, 0.5478, 0.6760, 0.4517],\n",
       "         [0.4358, 0.6313, 0.5659, 0.3677]],\n",
       "\n",
       "        [[0.8358, 0.6765, 0.1687, 0.3232],\n",
       "         [0.6090, 0.4957, 0.3949, 0.5037],\n",
       "         [0.4627, 0.3757, 0.5400, 0.6247],\n",
       "         [0.2776, 0.2243, 0.7233, 0.7768]],\n",
       "\n",
       "        [[0.8955, 0.2870, 0.1107, 0.7119],\n",
       "         [0.6567, 0.4174, 0.3475, 0.5827],\n",
       "         [0.4687, 0.5078, 0.5339, 0.4920],\n",
       "         [0.2985, 0.5774, 0.7019, 0.4214]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2269, 0.7339, 0.7721, 0.2643],\n",
       "         [0.3552, 0.5826, 0.6453, 0.4164],\n",
       "         [0.4687, 0.4643, 0.5339, 0.5357],\n",
       "         [0.5910, 0.3061, 0.4133, 0.6935]],\n",
       "\n",
       "        [[0.7582, 0.2713, 0.2467, 0.7279],\n",
       "         [0.6000, 0.3548, 0.4041, 0.6448],\n",
       "         [0.5104, 0.4191, 0.4927, 0.5810],\n",
       "         [0.4179, 0.4904, 0.5843, 0.5097]],\n",
       "\n",
       "        [[0.5910, 0.3061, 0.4133, 0.6935],\n",
       "         [0.4687, 0.4643, 0.5339, 0.5357],\n",
       "         [0.3552, 0.5826, 0.6453, 0.4164],\n",
       "         [0.2299, 0.7183, 0.7690, 0.2803]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perc_pos(tgt, stt, perc):\n",
    "    return int((((tgt-stt)*perc)+stt))/100\n",
    "\n",
    "\n",
    "input_data = torch.Tensor()\n",
    "output_data = torch.Tensor()\n",
    "count = 0\n",
    "paths = []\n",
    "NUM_PATHS = 1000\n",
    "\n",
    "for _ in range(NUM_PATHS):\n",
    "     #row = df.iloc[i]\n",
    "     check = True\n",
    "     while check:\n",
    "          print('tentou')\n",
    "          idx_s = randint(0, len(df)-1)\n",
    "          idx_t = randint(0, len(df)-1)\n",
    "          check = (idx_s == idx_t) or (set([idx_s,idx_t]) in paths) or (abs(df.iloc[idx_s]['x']-df.iloc[idx_t]['x'])<0.05) or (abs(df.iloc[idx_s]['y']-df.iloc[idx_t]['y'])<0.05)\n",
    "\n",
    "     paths.append(set([idx_s,idx_t]))\n",
    "\n",
    "     row_start = df.iloc[idx_s]\n",
    "     x_start, y_start = row_start['x']*100, row_start['y']*100\n",
    "     pos_hist = torch.Tensor(row_start[['xc', 'yc', 'xe', 'ye']].values.reshape(1,-1))\n",
    "\n",
    "     row_fin = df.iloc[idx_t]\n",
    "     x_fin, y_fin = row_fin['x']*100, row_fin['y']*100\n",
    "\n",
    "     #pos_hist = torch.Tensor(pos_inicial)\n",
    "     for p in [0.25, 0.5, 0.75]:\n",
    "          check=True\n",
    "          c = 0\n",
    "          while(check):\n",
    "               path_x = perc_pos(x_fin,x_start,p)\n",
    "               path_y = perc_pos(y_fin,y_start,p)\n",
    "               pos = df.loc[(df.x==path_x)&(df.y==path_y),['xc','yc','xe','ye']].values\n",
    "               if(pos.size==0):\n",
    "                    p += 0.05\n",
    "                    if(c==20):\n",
    "                         print(x_start, y_start)\n",
    "                         print(x_fin, y_fin)\n",
    "                         print(p)\n",
    "                         print(path_x, path_y)\n",
    "                         print(pos)\n",
    "                    elif(c<20):\n",
    "                         print(p)\n",
    "               else:\n",
    "                    check = False\n",
    "               c+=1\n",
    "          pos_hist = torch.cat((pos_hist, torch.Tensor(pos)))\n",
    "     input_data = torch.cat((input_data, pos_hist.unsqueeze(0)))\n",
    "     output_data = torch.cat((output_data, torch.Tensor([row_fin[['t0','t1','t2','t3']].values])))\n",
    "     clear_output(wait=True)\n",
    "     print(f'{count} path added')\n",
    "     count +=1\n",
    "\n",
    "input_data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 46.3099,  81.3969, 136.9517,  55.5547],\n",
       "        [150.7100,  62.7777, 116.2649,  53.4872],\n",
       "        [ 26.8699, 128.7312, 168.1344,  39.4032],\n",
       "        ...,\n",
       "        [116.8699,  31.7536,  71.4692,  39.7156],\n",
       "        [ 74.8056, 122.3657, 165.6356,  43.2698],\n",
       "        [  7.3540,  88.6237, 143.6680,  55.0444]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_test = X_test[4:,:,:]\n",
    "y_test = y_test[4:,:] # p/ evitar data leakage\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Separação em conj de validação\n",
    "#X_train, y_train, X_val, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "#train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo\n",
    "# Suponha batch_size = 1, seq_len = 4, input_size = 2 (x, y)\n",
    "from itertools import product\n",
    "from utils.rnn import ControlRNN, train_net\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.Tensor([])\n",
    "y_tensor = torch.Tensor([])\n",
    "\n",
    "for group in range(len(y)):\n",
    "    X_tensor = torch.cat([X_tensor, torch.Tensor(X.loc[list(range(4*group,4*(group+1))),['x','y','xe','ye']].values).reshape(1,4,4)])\n",
    "    y_tensor = torch.cat([y_tensor, torch.Tensor(y.loc[group,['t0','t1','t2','t3']].values).reshape(1,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1540, -0.1122,  0.0142,  0.0476]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1540, -0.1122,  0.0142,  0.0476],\n",
       "         [ 0.1667, -0.0707,  0.0088,  0.0306]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1540, -0.1122,  0.0142,  0.0476],\n",
       "         [ 0.1667, -0.0707,  0.0088,  0.0306],\n",
       "         [ 0.1728, -0.0407,  0.0064,  0.0129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1096,  0.1003,  0.0302, -0.0957],\n",
       "         [ 0.1428,  0.0063,  0.0117, -0.0530],\n",
       "         [ 0.1499, -0.0432,  0.0118, -0.0291],\n",
       "         [ 0.1615, -0.0646,  0.0039, -0.0204]],\n",
       "\n",
       "        [[ 0.1428,  0.0063,  0.0117, -0.0530],\n",
       "         [ 0.1499, -0.0432,  0.0118, -0.0291],\n",
       "         [ 0.1615, -0.0646,  0.0039, -0.0204],\n",
       "         [ 0.1635, -0.0819,  0.0038, -0.0096]],\n",
       "\n",
       "        [[ 0.1499, -0.0432,  0.0118, -0.0291],\n",
       "         [ 0.1615, -0.0646,  0.0039, -0.0204],\n",
       "         [ 0.1635, -0.0819,  0.0038, -0.0096],\n",
       "         [ 0.1678, -0.0868,  0.0004, -0.0078]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_test = X_test[4:,:,:]\n",
    "y_test = y_test[4:,:] # p/ evitar data leakage\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Separação em conj de validação\n",
    "#X_train, y_train, X_val, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "#train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa a RNN\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Val-MSE: 0.271\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, wd:0\n",
      "[2] Val-MSE: 0.279\n",
      "[3] Val-MSE: 0.241\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, wd:0\n",
      "[4] Val-MSE: 0.226\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, wd:0.0005\n",
      "[5] Val-MSE: 0.267\n",
      "[6] Val-MSE: 0.261\n",
      "[7] Val-MSE: 0.267\n",
      "[8] Val-MSE: 0.271\n",
      "[9] Val-MSE: 0.273\n",
      "[10] Val-MSE: 0.256\n",
      "[11] Val-MSE: 0.267\n",
      "[12] Val-MSE: 0.263\n",
      "[13] Val-MSE: 0.266\n",
      "[14] Val-MSE: 0.273\n",
      "[15] Val-MSE: 0.268\n",
      "[16] Val-MSE: 0.258\n",
      "[17] Val-MSE: 0.266\n",
      "[18] Val-MSE: 0.263\n",
      "[19] Val-MSE: 0.264\n",
      "[20] Val-MSE: 0.277\n",
      "[21] Val-MSE: 0.269\n",
      "[22] Val-MSE: 0.259\n",
      "[23] Val-MSE: 0.267\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     18\u001b[39m opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m model, _, scores = \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m score = np.mean(scores[\u001b[32m1\u001b[39m])\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Val-MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\utils\\rnn.py:51\u001b[39m, in \u001b[36mtrain_net\u001b[39m\u001b[34m(model, tloader, vloader, num_epochs, optimizer, lossFunc, delta, patience, verbose)\u001b[39m\n\u001b[32m     49\u001b[39m optimizer.zero_grad() \u001b[38;5;66;03m# clears x.grad for every parameter x in the optimizer.\u001b[39;00m\n\u001b[32m     50\u001b[39m loss.backward() \u001b[38;5;66;03m# computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# updates the value of x using the gradient x.grad\u001b[39;00m\n\u001b[32m     53\u001b[39m train_loss += loss.item()\n\u001b[32m     54\u001b[39m l = np.sqrt(loss.item()) \u001b[38;5;66;03m# rmse loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pedro\\Documents\\NOVOdeltadelta\\pog\\mlp-robot\\.auto\\Lib\\site-packages\\torch\\optim\\adam.py:476\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    474\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    478\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "hidden_size = [300, 400]\n",
    "num_layers = [1,2]\n",
    "dropout_rate = [0,0.25,0.75]\n",
    "learning_rate = [0.0001, 0.001, 0.01]\n",
    "weight_decay = [0, 0.0005]\n",
    "#optimizer = ['adam', 'sgd']\n",
    "best_model = None\n",
    "best_score = None\n",
    "\n",
    "params_grid = product(hidden_size, num_layers, dropout_rate, learning_rate, weight_decay)\n",
    "\n",
    "count = 1\n",
    "for hs, nl, dr, lr, wd in tqdm(params_grid):\n",
    "    if(not((dr>0) and (nl==1))):\n",
    "        model = ControlRNN(input_size=4, hidden_size=hs, \n",
    "                        num_layers=nl, dropout_rate=dr)\n",
    "        #if(o=='adam'):\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        #else:\n",
    "        #    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        \n",
    "        model, _, scores = train_net(model, train_loader, test_loader, 30, opt, verbose=0)\n",
    "        score = np.mean(scores[1])\n",
    "        print(f'[{count}] Val-MSE: {score:.3f}')\n",
    "        if(best_score is None or best_score > score):\n",
    "            print('[Melhor modelo atualizado]')\n",
    "            print('hs:{}, nl:{}, dr:{}, lr:{}, wd:{}'.format(hs, nl, dr, lr, wd))\n",
    "            best_model = model\n",
    "            best_opt = opt\n",
    "            best_score = score\n",
    "        count += 1\n",
    "                                \n",
    "\n",
    "# Teste\n",
    "predicted = best_model(input_data).detach()\n",
    "print(\"Predição:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs:300, nl:1, dr:0, lr:0.001, wd:0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Train Loss: 0.6970, Eval Loss: 0.2655\n",
      "best_model updated\n",
      "Epoch [2/60], Train Loss: 0.3509, Eval Loss: 0.2651\n",
      "best_model updated\n",
      "Epoch [3/60], Train Loss: 0.3507, Eval Loss: 0.2652\n",
      "Epoch [4/60], Train Loss: 0.3500, Eval Loss: 0.2649\n",
      "best_model updated\n",
      "Epoch [5/60], Train Loss: 0.3493, Eval Loss: 0.2645\n",
      "best_model updated\n",
      "Epoch [6/60], Train Loss: 0.3487, Eval Loss: 0.2642\n",
      "best_model updated\n",
      "Epoch [7/60], Train Loss: 0.3481, Eval Loss: 0.2639\n",
      "best_model updated\n",
      "Epoch [8/60], Train Loss: 0.3476, Eval Loss: 0.2636\n",
      "best_model updated\n",
      "Epoch [9/60], Train Loss: 0.3471, Eval Loss: 0.2633\n",
      "best_model updated\n",
      "Epoch [10/60], Train Loss: 0.3466, Eval Loss: 0.2630\n",
      "best_model updated\n",
      "Epoch [11/60], Train Loss: 0.3460, Eval Loss: 0.2626\n",
      "best_model updated\n",
      "Epoch [12/60], Train Loss: 0.3455, Eval Loss: 0.2624\n",
      "best_model updated\n",
      "Epoch [13/60], Train Loss: 0.3449, Eval Loss: 0.2620\n",
      "best_model updated\n",
      "Epoch [14/60], Train Loss: 0.3443, Eval Loss: 0.2617\n",
      "best_model updated\n",
      "Epoch [15/60], Train Loss: 0.3436, Eval Loss: 0.2614\n",
      "best_model updated\n",
      "Epoch [16/60], Train Loss: 0.3427, Eval Loss: 0.2611\n",
      "best_model updated\n",
      "Epoch [17/60], Train Loss: 0.3418, Eval Loss: 0.2608\n",
      "best_model updated\n",
      "Epoch [18/60], Train Loss: 0.3408, Eval Loss: 0.2605\n",
      "best_model updated\n",
      "Epoch [19/60], Train Loss: 0.3395, Eval Loss: 0.2601\n",
      "best_model updated\n",
      "Epoch [20/60], Train Loss: 0.3380, Eval Loss: 0.2599\n",
      "best_model updated\n",
      "Epoch [21/60], Train Loss: 0.3361, Eval Loss: 0.2596\n",
      "best_model updated\n",
      "Epoch [22/60], Train Loss: 0.3341, Eval Loss: 0.2587\n",
      "best_model updated\n",
      "Epoch [23/60], Train Loss: 0.3317, Eval Loss: 0.2577\n",
      "best_model updated\n",
      "Epoch [24/60], Train Loss: 0.3290, Eval Loss: 0.2562\n",
      "best_model updated\n",
      "Epoch [25/60], Train Loss: 0.3263, Eval Loss: 0.2543\n",
      "best_model updated\n",
      "Epoch [26/60], Train Loss: 0.3234, Eval Loss: 0.2523\n",
      "best_model updated\n",
      "Epoch [27/60], Train Loss: 0.3205, Eval Loss: 0.2499\n",
      "best_model updated\n",
      "Epoch [28/60], Train Loss: 0.3173, Eval Loss: 0.2478\n",
      "best_model updated\n",
      "Epoch [29/60], Train Loss: 0.3143, Eval Loss: 0.2453\n",
      "best_model updated\n",
      "Epoch [30/60], Train Loss: 0.3112, Eval Loss: 0.2429\n",
      "best_model updated\n",
      "Epoch [31/60], Train Loss: 0.3079, Eval Loss: 0.2403\n",
      "best_model updated\n",
      "Epoch [32/60], Train Loss: 0.3045, Eval Loss: 0.2379\n",
      "best_model updated\n",
      "Epoch [33/60], Train Loss: 0.3005, Eval Loss: 0.2353\n",
      "best_model updated\n",
      "Epoch [34/60], Train Loss: 0.2969, Eval Loss: 0.2326\n",
      "best_model updated\n",
      "Epoch [35/60], Train Loss: 0.2931, Eval Loss: 0.2299\n",
      "best_model updated\n",
      "Epoch [36/60], Train Loss: 0.2890, Eval Loss: 0.2272\n",
      "best_model updated\n",
      "Epoch [37/60], Train Loss: 0.2849, Eval Loss: 0.2245\n",
      "best_model updated\n",
      "Epoch [38/60], Train Loss: 0.2811, Eval Loss: 0.2219\n",
      "best_model updated\n",
      "Epoch [39/60], Train Loss: 0.2774, Eval Loss: 0.2195\n",
      "best_model updated\n",
      "Epoch [40/60], Train Loss: 0.2744, Eval Loss: 0.2175\n",
      "best_model updated\n",
      "Epoch [41/60], Train Loss: 0.2714, Eval Loss: 0.2154\n",
      "best_model updated\n",
      "Epoch [42/60], Train Loss: 0.2693, Eval Loss: 0.2139\n",
      "best_model updated\n",
      "Epoch [43/60], Train Loss: 0.2674, Eval Loss: 0.2125\n",
      "best_model updated\n",
      "Epoch [44/60], Train Loss: 0.2660, Eval Loss: 0.2114\n",
      "best_model updated\n",
      "Epoch [45/60], Train Loss: 0.2648, Eval Loss: 0.2101\n",
      "best_model updated\n",
      "Epoch [46/60], Train Loss: 0.2640, Eval Loss: 0.2093\n",
      "best_model updated\n",
      "Epoch [47/60], Train Loss: 0.2629, Eval Loss: 0.2086\n",
      "best_model updated\n",
      "Epoch [48/60], Train Loss: 0.2626, Eval Loss: 0.2084\n",
      "best_model updated\n",
      "Epoch [49/60], Train Loss: 0.2617, Eval Loss: 0.2077\n",
      "best_model updated\n",
      "Epoch [50/60], Train Loss: 0.2614, Eval Loss: 0.2073\n",
      "best_model updated\n",
      "Epoch [51/60], Train Loss: 0.2610, Eval Loss: 0.2070\n",
      "best_model updated\n",
      "Epoch [52/60], Train Loss: 0.2605, Eval Loss: 0.2068\n",
      "best_model updated\n",
      "Epoch [53/60], Train Loss: 0.2601, Eval Loss: 0.2064\n",
      "best_model updated\n",
      "Epoch [54/60], Train Loss: 0.2598, Eval Loss: 0.2062\n",
      "best_model updated\n",
      "Epoch [55/60], Train Loss: 0.2594, Eval Loss: 0.2058\n",
      "best_model updated\n",
      "Epoch [56/60], Train Loss: 0.2592, Eval Loss: 0.2058\n",
      "best_model updated\n",
      "Epoch [57/60], Train Loss: 0.2589, Eval Loss: 0.2055\n",
      "best_model updated\n",
      "Epoch [58/60], Train Loss: 0.2586, Eval Loss: 0.2052\n",
      "best_model updated\n",
      "Epoch [59/60], Train Loss: 0.2584, Eval Loss: 0.2051\n",
      "best_model updated\n",
      "Epoch [60/60], Train Loss: 0.2580, Eval Loss: 0.2048\n",
      "best_model updated\n"
     ]
    }
   ],
   "source": [
    "full_loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=BATCH_SIZE)\n",
    "rnn_model = ControlRNN(input_size=4, hidden_size=300, num_layers=1, dropout_rate=0)\n",
    "opt = torch.optim.Adam(rnn_model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "rnn_model, _, scores = train_net(rnn_model, full_loader, full_loader, 60, opt, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0046\n",
      "RMSE: 0.0677\n"
     ]
    }
   ],
   "source": [
    "predicted = rnn_model(X_test).detach()\n",
    "\n",
    "score = ((predicted - y_test)**2).mean()\n",
    "\n",
    "print(f'''MSE: {score:.4f}\n",
    "RMSE: {score**0.5:.4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0460\n",
      "RMSE: 0.2145\n"
     ]
    }
   ],
   "source": [
    "predicted = rnn_model(X_test).detach()\n",
    "\n",
    "score = ((predicted - y_test)**2).mean()\n",
    "\n",
    "print(f'''MSE: {score:.4f}\n",
    "RMSE: {score**0.5:.4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 40.5490\n",
      "RMSE: 6.3678\n"
     ]
    }
   ],
   "source": [
    "predicted = best_model(X_test).detach()\n",
    "\n",
    "score = ((predicted - y_test)**2).mean()\n",
    "\n",
    "print(f'''MSE: {score:.4f}\n",
    "RMSE: {score**0.5:.4f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlRNN(\n",
       "  (rnn): RNN(3, 300, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=300, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.dropout_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor modelo:\n",
    "\n",
    "- Número de camadas recorrentes: 2\n",
    "- Número de neurônios ocultos: 300\n",
    "- Funcção de ativação: ReLU\n",
    "- Taxa de dropout: 0\n",
    "- Ottimizador: Adam\n",
    "- Learning rate: 0.01\n",
    "- Weight decay: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(, 'wb') as f:\n",
    "best_model.eval()\n",
    "torch.save(best_model.state_dict(), 'models/nn_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

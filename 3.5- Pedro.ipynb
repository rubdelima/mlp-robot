{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_data.csv')\n",
    "#df['xc_px'], df['yc_px'] = df['yc_px'], df['xc_px'] (não rodar isso)\n",
    "#df['xc'], df['yc'] = df['yc'], df['xc'] (não rodar isso) (deixei para dxar registrado)\n",
    "#df.to_csv(f\"data/train_data.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>xc_px</th>\n",
       "      <th>yc_px</th>\n",
       "      <th>xc</th>\n",
       "      <th>yc</th>\n",
       "      <th>diagonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>30.100908</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>73.389373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>33.363423</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.031304</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>72.801099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>36.636577</td>\n",
       "      <td>34.952635</td>\n",
       "      <td>76.655631</td>\n",
       "      <td>41.702995</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.057391</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.942609</td>\n",
       "      <td>72.780492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>39.899092</td>\n",
       "      <td>33.948155</td>\n",
       "      <td>75.041009</td>\n",
       "      <td>41.092854</td>\n",
       "      <td>0.728358</td>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.728358</td>\n",
       "      <td>0.918261</td>\n",
       "      <td>72.835431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>43.130102</td>\n",
       "      <td>31.753588</td>\n",
       "      <td>71.469230</td>\n",
       "      <td>39.715641</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.779104</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>75.239617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y     z         t0         t1         t2         t3     xc_px  \\\n",
       "7   0.16 -0.19  0.12  30.100908  33.948155  75.041009  41.092854  0.591045   \n",
       "8   0.17 -0.18  0.12  33.363423  34.952635  76.655631  41.702995  0.635821   \n",
       "9   0.18 -0.17  0.12  36.636577  34.952635  76.655631  41.702995  0.689552   \n",
       "10  0.19 -0.16  0.12  39.899092  33.948155  75.041009  41.092854  0.728358   \n",
       "11  0.20 -0.15  0.12  43.130102  31.753588  71.469230  39.715641  0.779104   \n",
       "\n",
       "       yc_px        xc        yc   diagonal  \n",
       "7   0.012174  0.591045  0.987826  73.389373  \n",
       "8   0.031304  0.635821  0.968696  72.801099  \n",
       "9   0.057391  0.689552  0.942609  72.780492  \n",
       "10  0.081739  0.728358  0.918261  72.835431  \n",
       "11  0.104348  0.779104  0.895652  75.239617  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "min_max_scalers = {}\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "for column in df.columns:\n",
    "    if column in  ['xc_px', 'yc_px', 'xc', 'yc']:\n",
    "        min_max_scalers[column] = MinMaxScaler() #(df[column].min(), df[column].max())\n",
    "        df[column] = min_max_scalers[column].fit_transform(df[[column]])\n",
    "        with open('scalers/'+column+'.pkl', 'wb') as f:\n",
    "            pickle.dump(min_max_scalers[column], f)\n",
    "\n",
    "    \n",
    "#with open('data/min_max_scalers.json', 'w') as f:\n",
    "#    json.dump(min_max_scalers, f)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Utilizando o Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_pos(value, perc):\n",
    "    return int(value*perc)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.1343e-01, 3.8783e-01, 1.1343e-01, 6.1217e-01],\n",
       "         [2.1194e-01, 3.1826e-01, 2.1194e-01, 6.8174e-01],\n",
       "         [4.0597e-01, 1.6174e-01, 4.0597e-01, 8.3826e-01]],\n",
       "\n",
       "        [[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.1940e-01, 4.1217e-01, 1.1940e-01, 5.8783e-01],\n",
       "         [2.1194e-01, 3.1826e-01, 2.1194e-01, 6.8174e-01],\n",
       "         [4.0896e-01, 1.9130e-01, 4.0896e-01, 8.0870e-01]],\n",
       "\n",
       "        [[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.1940e-01, 4.1217e-01, 1.1940e-01, 5.8783e-01],\n",
       "         [2.6866e-01, 3.2870e-01, 2.6866e-01, 6.7130e-01],\n",
       "         [4.5672e-01, 2.1739e-01, 4.5672e-01, 7.8261e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.0149e-01, 5.6000e-01, 1.0149e-01, 4.4000e-01],\n",
       "         [1.0149e-01, 5.6000e-01, 1.0149e-01, 4.4000e-01],\n",
       "         [1.0149e-01, 5.6000e-01, 1.0149e-01, 4.4000e-01]],\n",
       "\n",
       "        [[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.2537e-01, 5.3217e-01, 1.2537e-01, 4.6783e-01],\n",
       "         [1.2537e-01, 5.3217e-01, 1.2537e-01, 4.6783e-01],\n",
       "         [1.2537e-01, 5.3217e-01, 1.2537e-01, 4.6783e-01]],\n",
       "\n",
       "        [[3.1400e+02, 1.3400e+02, 3.5000e-02, 0.0000e+00],\n",
       "         [1.4030e-01, 5.2348e-01, 1.4030e-01, 4.7652e-01],\n",
       "         [1.4030e-01, 5.2348e-01, 1.4030e-01, 4.7652e-01],\n",
       "         [1.4030e-01, 5.2348e-01, 1.4030e-01, 4.7652e-01]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.Tensor()\n",
    "output_data = torch.Tensor()\n",
    "\n",
    "for i in range(len(df)):\n",
    "     row = df.iloc[i]\n",
    "     x_fin, y_fin = row['x']*100, row['y']*100\n",
    "     pos_hist = torch.Tensor([[314,134,0.035,0]])\n",
    "     for p in [0.25, 0.5, 0.75]:\n",
    "          check=True\n",
    "          while(check):\n",
    "               path_x = perc_pos(x_fin,p)\n",
    "               path_y = perc_pos(y_fin,p)\n",
    "               pos = df.loc[(df.x==path_x)&(df.y==path_y),['xc_px','yc_px','xc','yc']].values\n",
    "               if(pos.size==0):\n",
    "                    p += 0.05\n",
    "               else:\n",
    "                    check = False\n",
    "          pos_hist = torch.cat((pos_hist, torch.Tensor(pos)))\n",
    "     input_data = torch.cat((input_data, pos_hist.unsqueeze(0)))\n",
    "     output_data = torch.cat((output_data, torch.Tensor([row[['t0','t1','t2','t3']].values])))\n",
    "\n",
    "input_data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.1009,  33.9482,  75.0410,  41.0929],\n",
       "        [ 33.3634,  34.9526,  76.6556,  41.7030],\n",
       "        [ 36.6366,  34.9526,  76.6556,  41.7030],\n",
       "        ...,\n",
       "        [125.0000, 146.0643, 172.2480,  26.1836],\n",
       "        [110.9638, 152.7918, 172.6161,  19.8243],\n",
       "        [106.5650, 148.0869, 172.4426,  24.3557]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_test = X_test[4:,:,:]\n",
    "y_test = y_test[4:,:] # p/ evitar data leakage\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Separação em conj de validação\n",
    "#X_train, y_train, X_val, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "#train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a RNN simples\n",
    "class ControlRNN(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=32, num_layers=1, activation='tanh', dropout_rate=0):\n",
    "        super(ControlRNN, self).__init__()\n",
    "        # recebe as quatro últimas posições e dá a próxima posição como saída\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, \n",
    "                          nonlinearity=activation, dropout=dropout_rate, \n",
    "                          batch_first=True)\n",
    "        # recebe a próxima posição [x, y] e dá os thetas como saída\n",
    "        #self.dropout = nn.Dropout(p=drop_rate)\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos, _ = self.rnn(x)\n",
    "        new_pos = pos[:, -1, :]  # pegamos só a última saída\n",
    "        thetas = self.fc(new_pos)\n",
    "        return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, tloader, vloader, num_epochs, optimizer, lossFunc=nn.MSELoss(), delta=None, patience=None, verbose=2):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_train_score = None\n",
    "    best_val_score = None\n",
    "    for e in range(num_epochs):\n",
    "        train_loss = 0.0 # total loss during single epoch training\n",
    "        val_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (X_batch, y_batch) in enumerate(tloader):\n",
    "            #X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            pred = model(X_batch) # predictions based on batch X_batch\n",
    "            loss = lossFunc(pred, y_batch)  # calculates the loss function result\n",
    "            optimizer.zero_grad() # clears x.grad for every parameter x in the optimizer.\n",
    "            loss.backward() # computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x\n",
    "            optimizer.step() # updates the value of x using the gradient x.grad\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            l = np.sqrt(loss.item()) # rmse loss\n",
    "            train_loss += l # value of loss?\n",
    "            #print(f'Epoch [{e + 1}/{num_epochs}], Step [{i + 1}/{len(tloader)}], Loss: {l:.4f} ')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in vloader:\n",
    "                #X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                pred = model(X_batch)\n",
    "                l = np.sqrt(lossFunc(pred, y_batch).item()) #rmse loss\n",
    "                val_loss += l\n",
    "\n",
    "            avg_train_loss = train_loss / len(tloader)\n",
    "            avg_val_loss = val_loss / len(vloader)\n",
    "            if(verbose >= 1):\n",
    "                print(f'Epoch [{e + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Eval Loss: {avg_val_loss:.4f}')\n",
    "        train_losses.append(avg_train_loss)\n",
    "        test_losses.append(avg_val_loss)\n",
    "\n",
    "        # Armazenamento do melhor modelo com base no score de validação\n",
    "        if((best_val_score is None) or (best_val_score > avg_val_loss)):\n",
    "                    best_val_score = avg_val_loss\n",
    "                    best_e = e\n",
    "                    best_model = model\n",
    "                    if(verbose >= 2):\n",
    "                        print('best_model updated')\n",
    "\n",
    "        # Early stopping com base no score de treinamento (não foi usado mas enf)\n",
    "        if((delta is not None) and (patience is not None)):\n",
    "            if((best_train_score is None) or (best_train_score-avg_train_loss >= delta)):\n",
    "                counter = 0\n",
    "                best_train_score = avg_train_loss\n",
    "            else:\n",
    "                counter += 1\n",
    "                if(counter>=patience):\n",
    "                    if(verbose >= 2):\n",
    "                        print(\"Early Stopping!\")\n",
    "                    break\n",
    "\n",
    "    return best_model, best_e, (train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 6880.0900, Eval Loss: 31.2384\n",
      "Epoch [2/25], Train Loss: 883.3971, Eval Loss: 28.9562\n",
      "Epoch [3/25], Train Loss: 857.5703, Eval Loss: 28.9589\n",
      "Epoch [4/25], Train Loss: 857.7728, Eval Loss: 28.9853\n",
      "Epoch [5/25], Train Loss: 857.6602, Eval Loss: 29.0035\n",
      "Epoch [6/25], Train Loss: 857.5199, Eval Loss: 29.0146\n",
      "Epoch [7/25], Train Loss: 857.3793, Eval Loss: 29.0217\n",
      "Epoch [8/25], Train Loss: 857.2413, Eval Loss: 29.0257\n",
      "Epoch [9/25], Train Loss: 857.2956, Eval Loss: 29.0288\n",
      "Epoch [10/25], Train Loss: 857.0484, Eval Loss: 29.0301\n",
      "Epoch [11/25], Train Loss: 856.9115, Eval Loss: 29.0301\n",
      "Epoch [12/25], Train Loss: 856.7772, Eval Loss: 29.0294\n",
      "Epoch [13/25], Train Loss: 856.6415, Eval Loss: 29.0283\n",
      "Epoch [14/25], Train Loss: 856.4993, Eval Loss: 29.0279\n",
      "Epoch [15/25], Train Loss: 856.3509, Eval Loss: 29.0257\n",
      "Epoch [16/25], Train Loss: 856.2066, Eval Loss: 29.0239\n",
      "Epoch [17/25], Train Loss: 856.0592, Eval Loss: 29.0219\n",
      "Epoch [18/25], Train Loss: 855.9108, Eval Loss: 29.0194\n",
      "Epoch [19/25], Train Loss: 855.7539, Eval Loss: 29.0175\n",
      "Epoch [20/25], Train Loss: 855.5981, Eval Loss: 29.0148\n",
      "Epoch [21/25], Train Loss: 855.4437, Eval Loss: 29.0122\n",
      "Epoch [22/25], Train Loss: 855.2830, Eval Loss: 29.0093\n",
      "Epoch [23/25], Train Loss: 855.1233, Eval Loss: 29.0067\n",
      "Epoch [24/25], Train Loss: 854.9573, Eval Loss: 29.0039\n",
      "Epoch [25/25], Train Loss: 854.7960, Eval Loss: 29.0008\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.0001, a:relu, o:adam, wd:0\n",
      "Epoch [1/25], Train Loss: 7298.4800, Eval Loss: 34.8537\n",
      "Epoch [2/25], Train Loss: 896.1728, Eval Loss: 28.9691\n",
      "Epoch [3/25], Train Loss: 857.4389, Eval Loss: 28.9713\n",
      "Epoch [4/25], Train Loss: 857.6557, Eval Loss: 29.0000\n",
      "Epoch [5/25], Train Loss: 857.5047, Eval Loss: 29.0135\n",
      "Epoch [6/25], Train Loss: 857.4108, Eval Loss: 29.0222\n",
      "Epoch [7/25], Train Loss: 857.2684, Eval Loss: 29.0258\n",
      "Epoch [8/25], Train Loss: 857.1413, Eval Loss: 29.0279\n",
      "Epoch [9/25], Train Loss: 857.0139, Eval Loss: 29.0287\n",
      "Epoch [10/25], Train Loss: 856.9024, Eval Loss: 29.0294\n",
      "Epoch [11/25], Train Loss: 856.7743, Eval Loss: 29.0289\n",
      "Epoch [12/25], Train Loss: 856.6421, Eval Loss: 29.0274\n",
      "Epoch [13/25], Train Loss: 856.5440, Eval Loss: 29.0269\n",
      "Epoch [14/25], Train Loss: 856.3832, Eval Loss: 29.0251\n",
      "Epoch [15/25], Train Loss: 856.3450, Eval Loss: 29.0205\n",
      "Epoch [16/25], Train Loss: 856.1318, Eval Loss: 29.0213\n",
      "Epoch [17/25], Train Loss: 856.0187, Eval Loss: 29.0185\n",
      "Epoch [18/25], Train Loss: 855.8314, Eval Loss: 29.0161\n",
      "Epoch [19/25], Train Loss: 855.6586, Eval Loss: 29.0134\n",
      "Epoch [20/25], Train Loss: 855.5003, Eval Loss: 29.0077\n",
      "Epoch [21/25], Train Loss: 855.3321, Eval Loss: 29.0078\n",
      "Epoch [22/25], Train Loss: 855.1738, Eval Loss: 29.0056\n",
      "Epoch [23/25], Train Loss: 855.0180, Eval Loss: 29.0033\n",
      "Epoch [24/25], Train Loss: 854.8598, Eval Loss: 28.9994\n",
      "Epoch [25/25], Train Loss: 854.6847, Eval Loss: 28.9971\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8942.8982, Eval Loss: 90.6147\n",
      "Epoch [2/25], Train Loss: 8174.3116, Eval Loss: 87.2982\n",
      "Epoch [3/25], Train Loss: 7679.3594, Eval Loss: 84.8794\n",
      "Epoch [4/25], Train Loss: 7290.9070, Eval Loss: 82.7484\n",
      "Epoch [5/25], Train Loss: 6945.2474, Eval Loss: 80.7609\n",
      "Epoch [6/25], Train Loss: 6627.3550, Eval Loss: 78.8712\n",
      "Epoch [7/25], Train Loss: 6330.2726, Eval Loss: 77.0550\n",
      "Epoch [8/25], Train Loss: 6050.3276, Eval Loss: 75.2997\n",
      "Epoch [9/25], Train Loss: 5785.3254, Eval Loss: 73.5980\n",
      "Epoch [10/25], Train Loss: 5533.7789, Eval Loss: 71.9449\n",
      "Epoch [11/25], Train Loss: 5294.5887, Eval Loss: 70.3371\n",
      "Epoch [12/25], Train Loss: 5066.8902, Eval Loss: 68.7722\n",
      "Epoch [13/25], Train Loss: 4849.9702, Eval Loss: 67.2484\n",
      "Epoch [14/25], Train Loss: 4643.2188, Eval Loss: 65.7642\n",
      "Epoch [15/25], Train Loss: 4446.1008, Eval Loss: 64.3185\n",
      "Epoch [16/25], Train Loss: 4258.1362, Eval Loss: 62.9104\n",
      "Epoch [17/25], Train Loss: 4078.8874, Eval Loss: 61.5391\n",
      "Epoch [18/25], Train Loss: 3907.9515, Eval Loss: 60.2039\n",
      "Epoch [19/25], Train Loss: 3744.9526, Eval Loss: 58.9042\n",
      "Epoch [20/25], Train Loss: 3589.5387, Eval Loss: 57.6395\n",
      "Epoch [21/25], Train Loss: 3441.3777, Eval Loss: 56.4093\n",
      "Epoch [22/25], Train Loss: 3300.1551, Eval Loss: 55.2130\n",
      "Epoch [23/25], Train Loss: 3165.5726, Eval Loss: 54.0505\n",
      "Epoch [24/25], Train Loss: 3037.3456, Eval Loss: 52.9211\n",
      "Epoch [25/25], Train Loss: 2915.2033, Eval Loss: 51.8246\n",
      "Epoch [1/25], Train Loss: 8926.0129, Eval Loss: 90.4222\n",
      "Epoch [2/25], Train Loss: 8140.4581, Eval Loss: 87.1165\n",
      "Epoch [3/25], Train Loss: 7646.4703, Eval Loss: 84.6833\n",
      "Epoch [4/25], Train Loss: 7257.6096, Eval Loss: 82.5554\n",
      "Epoch [5/25], Train Loss: 6913.9158, Eval Loss: 80.5744\n",
      "Epoch [6/25], Train Loss: 6597.5868, Eval Loss: 78.6888\n",
      "Epoch [7/25], Train Loss: 6301.7674, Eval Loss: 76.8759\n",
      "Epoch [8/25], Train Loss: 6022.9460, Eval Loss: 75.1235\n",
      "Epoch [9/25], Train Loss: 5758.9846, Eval Loss: 73.4245\n",
      "Epoch [10/25], Train Loss: 5508.4223, Eval Loss: 71.7740\n",
      "Epoch [11/25], Train Loss: 5270.1751, Eval Loss: 70.1688\n",
      "Epoch [12/25], Train Loss: 5043.3871, Eval Loss: 68.6066\n",
      "Epoch [13/25], Train Loss: 4827.3512, Eval Loss: 67.0854\n",
      "Epoch [14/25], Train Loss: 4621.4621, Eval Loss: 65.6040\n",
      "Epoch [15/25], Train Loss: 4425.1872, Eval Loss: 64.1611\n",
      "Epoch [16/25], Train Loss: 4238.0487, Eval Loss: 62.7560\n",
      "Epoch [17/25], Train Loss: 4059.6108, Eval Loss: 61.3877\n",
      "Epoch [18/25], Train Loss: 3889.4714, Eval Loss: 60.0556\n",
      "Epoch [19/25], Train Loss: 3727.2555, Eval Loss: 58.7592\n",
      "Epoch [20/25], Train Loss: 3572.6116, Eval Loss: 57.4978\n",
      "Epoch [21/25], Train Loss: 3425.2079, Eval Loss: 56.2711\n",
      "Epoch [22/25], Train Loss: 3284.7301, Eval Loss: 55.0786\n",
      "Epoch [23/25], Train Loss: 3150.8793, Eval Loss: 53.9197\n",
      "Epoch [24/25], Train Loss: 3023.3712, Eval Loss: 52.7943\n",
      "Epoch [25/25], Train Loss: 2901.9344, Eval Loss: 51.7019\n",
      "Epoch [1/25], Train Loss: 6104.6225, Eval Loss: 49.9753\n",
      "Epoch [2/25], Train Loss: 1602.4829, Eval Loss: 31.7982\n",
      "Epoch [3/25], Train Loss: 941.1308, Eval Loss: 29.1788\n",
      "Epoch [4/25], Train Loss: 864.0301, Eval Loss: 28.9087\n",
      "Epoch [5/25], Train Loss: 855.0812, Eval Loss: 28.8933\n",
      "Epoch [6/25], Train Loss: 854.0420, Eval Loss: 28.8970\n",
      "Epoch [7/25], Train Loss: 853.9200, Eval Loss: 28.8992\n",
      "Epoch [8/25], Train Loss: 853.9042, Eval Loss: 28.9001\n",
      "Epoch [9/25], Train Loss: 853.9006, Eval Loss: 28.9004\n",
      "Epoch [10/25], Train Loss: 853.8985, Eval Loss: 28.9005\n",
      "Epoch [11/25], Train Loss: 853.8965, Eval Loss: 28.9005\n",
      "Epoch [12/25], Train Loss: 853.8945, Eval Loss: 28.9004\n",
      "Epoch [13/25], Train Loss: 853.8926, Eval Loss: 28.9004\n",
      "Epoch [14/25], Train Loss: 853.8906, Eval Loss: 28.9004\n",
      "Epoch [15/25], Train Loss: 853.8887, Eval Loss: 28.9003\n",
      "Epoch [16/25], Train Loss: 853.8867, Eval Loss: 28.9003\n",
      "Epoch [17/25], Train Loss: 853.8847, Eval Loss: 28.9003\n",
      "Epoch [18/25], Train Loss: 853.8827, Eval Loss: 28.9002\n",
      "Epoch [19/25], Train Loss: 853.8808, Eval Loss: 28.9002\n",
      "Epoch [20/25], Train Loss: 853.8788, Eval Loss: 28.9002\n",
      "Epoch [21/25], Train Loss: 853.8768, Eval Loss: 28.9001\n",
      "Epoch [22/25], Train Loss: 853.8748, Eval Loss: 28.9001\n",
      "Epoch [23/25], Train Loss: 853.8728, Eval Loss: 28.9000\n",
      "Epoch [24/25], Train Loss: 853.8707, Eval Loss: 28.9000\n",
      "Epoch [25/25], Train Loss: 853.8687, Eval Loss: 28.9000\n",
      "Epoch [1/25], Train Loss: 6203.1932, Eval Loss: 50.8367\n",
      "Epoch [2/25], Train Loss: 1641.8687, Eval Loss: 31.9598\n",
      "Epoch [3/25], Train Loss: 945.9313, Eval Loss: 29.1971\n",
      "Epoch [4/25], Train Loss: 864.5674, Eval Loss: 28.9097\n",
      "Epoch [5/25], Train Loss: 855.1172, Eval Loss: 28.8927\n",
      "Epoch [6/25], Train Loss: 854.0186, Eval Loss: 28.8963\n",
      "Epoch [7/25], Train Loss: 853.8892, Eval Loss: 28.8986\n",
      "Epoch [8/25], Train Loss: 853.8721, Eval Loss: 28.8995\n",
      "Epoch [9/25], Train Loss: 853.8681, Eval Loss: 28.8998\n",
      "Epoch [10/25], Train Loss: 853.8655, Eval Loss: 28.8998\n",
      "Epoch [11/25], Train Loss: 853.8631, Eval Loss: 28.8998\n",
      "Epoch [12/25], Train Loss: 853.8608, Eval Loss: 28.8998\n",
      "Epoch [13/25], Train Loss: 853.8584, Eval Loss: 28.8998\n",
      "Epoch [14/25], Train Loss: 853.8560, Eval Loss: 28.8997\n",
      "Epoch [15/25], Train Loss: 853.8535, Eval Loss: 28.8997\n",
      "Epoch [16/25], Train Loss: 853.8511, Eval Loss: 28.8996\n",
      "Epoch [17/25], Train Loss: 853.8486, Eval Loss: 28.8996\n",
      "Epoch [18/25], Train Loss: 853.8461, Eval Loss: 28.8995\n",
      "Epoch [19/25], Train Loss: 853.8435, Eval Loss: 28.8995\n",
      "Epoch [20/25], Train Loss: 853.8409, Eval Loss: 28.8994\n",
      "Epoch [21/25], Train Loss: 853.8383, Eval Loss: 28.8994\n",
      "Epoch [22/25], Train Loss: 853.8355, Eval Loss: 28.8993\n",
      "Epoch [23/25], Train Loss: 853.8328, Eval Loss: 28.8993\n",
      "Epoch [24/25], Train Loss: 853.8300, Eval Loss: 28.8992\n",
      "Epoch [25/25], Train Loss: 853.8271, Eval Loss: 28.8992\n",
      "Epoch [1/25], Train Loss: 1868.7241, Eval Loss: 29.0820\n",
      "Epoch [2/25], Train Loss: 884.4430, Eval Loss: 29.0368\n",
      "Epoch [3/25], Train Loss: 889.0083, Eval Loss: 28.9982\n",
      "Epoch [4/25], Train Loss: 892.7874, Eval Loss: 28.9687\n",
      "Epoch [5/25], Train Loss: 894.3298, Eval Loss: 28.9415\n",
      "Epoch [6/25], Train Loss: 894.6060, Eval Loss: 28.8939\n",
      "Epoch [7/25], Train Loss: 895.1102, Eval Loss: 28.8921\n",
      "Epoch [8/25], Train Loss: 890.5528, Eval Loss: 28.8533\n",
      "Epoch [9/25], Train Loss: 887.7642, Eval Loss: 28.8188\n",
      "Epoch [10/25], Train Loss: 885.4172, Eval Loss: 28.7878\n",
      "Epoch [11/25], Train Loss: 882.6744, Eval Loss: 28.7544\n",
      "Epoch [12/25], Train Loss: 880.5159, Eval Loss: 28.7274\n",
      "Epoch [13/25], Train Loss: 877.8995, Eval Loss: 28.6901\n",
      "Epoch [14/25], Train Loss: 875.2015, Eval Loss: 28.6499\n",
      "Epoch [15/25], Train Loss: 872.8142, Eval Loss: 28.6177\n",
      "Epoch [16/25], Train Loss: 869.9568, Eval Loss: 28.5766\n",
      "Epoch [17/25], Train Loss: 867.5248, Eval Loss: 28.5351\n",
      "Epoch [18/25], Train Loss: 864.9056, Eval Loss: 28.4796\n",
      "Epoch [19/25], Train Loss: 862.2064, Eval Loss: 28.4408\n",
      "Epoch [20/25], Train Loss: 859.2582, Eval Loss: 28.3862\n",
      "Epoch [21/25], Train Loss: 856.4310, Eval Loss: 28.3314\n",
      "Epoch [22/25], Train Loss: 853.1907, Eval Loss: 28.2688\n",
      "Epoch [23/25], Train Loss: 849.9539, Eval Loss: 28.2001\n",
      "Epoch [24/25], Train Loss: 846.4756, Eval Loss: 28.1265\n",
      "Epoch [25/25], Train Loss: 842.5844, Eval Loss: 28.0437\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:relu, o:adam, wd:0\n",
      "Epoch [1/25], Train Loss: 1842.4908, Eval Loss: 29.0155\n",
      "Epoch [2/25], Train Loss: 889.2372, Eval Loss: 29.0052\n",
      "Epoch [3/25], Train Loss: 892.7150, Eval Loss: 28.9955\n",
      "Epoch [4/25], Train Loss: 895.7809, Eval Loss: 28.9753\n",
      "Epoch [5/25], Train Loss: 896.5802, Eval Loss: 28.9504\n",
      "Epoch [6/25], Train Loss: 895.2044, Eval Loss: 28.9203\n",
      "Epoch [7/25], Train Loss: 893.2765, Eval Loss: 28.8881\n",
      "Epoch [8/25], Train Loss: 891.1797, Eval Loss: 28.8590\n",
      "Epoch [9/25], Train Loss: 888.0104, Eval Loss: 28.8266\n",
      "Epoch [10/25], Train Loss: 885.3613, Eval Loss: 28.7967\n",
      "Epoch [11/25], Train Loss: 882.6633, Eval Loss: 28.7634\n",
      "Epoch [12/25], Train Loss: 879.9993, Eval Loss: 28.7285\n",
      "Epoch [13/25], Train Loss: 877.5285, Eval Loss: 28.6930\n",
      "Epoch [14/25], Train Loss: 874.8650, Eval Loss: 28.6515\n",
      "Epoch [15/25], Train Loss: 872.1702, Eval Loss: 28.6109\n",
      "Epoch [16/25], Train Loss: 869.3038, Eval Loss: 28.5667\n",
      "Epoch [17/25], Train Loss: 866.4949, Eval Loss: 28.5190\n",
      "Epoch [18/25], Train Loss: 863.7948, Eval Loss: 28.4717\n",
      "Epoch [19/25], Train Loss: 861.0260, Eval Loss: 28.4201\n",
      "Epoch [20/25], Train Loss: 857.6913, Eval Loss: 28.3613\n",
      "Epoch [21/25], Train Loss: 854.2571, Eval Loss: 28.2994\n",
      "Epoch [22/25], Train Loss: 850.8296, Eval Loss: 28.2327\n",
      "Epoch [23/25], Train Loss: 847.1947, Eval Loss: 28.1573\n",
      "Epoch [24/25], Train Loss: 843.4173, Eval Loss: 28.0752\n",
      "Epoch [25/25], Train Loss: 839.2021, Eval Loss: 27.9832\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:relu, o:adam, wd:0.0005\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 7204.0994, Eval Loss: 73.1362\n",
      "Epoch [2/25], Train Loss: 4519.4940, Eval Loss: 58.3156\n",
      "Epoch [3/25], Train Loss: 2964.6155, Eval Loss: 47.6034\n",
      "Epoch [4/25], Train Loss: 2048.3096, Eval Loss: 40.1967\n",
      "Epoch [5/25], Train Loss: 1515.1199, Eval Loss: 35.3781\n",
      "Epoch [6/25], Train Loss: 1210.6248, Eval Loss: 32.4274\n",
      "Epoch [7/25], Train Loss: 1040.3334, Eval Loss: 30.7154\n",
      "Epoch [8/25], Train Loss: 947.4587, Eval Loss: 29.7747\n",
      "Epoch [9/25], Train Loss: 898.5017, Eval Loss: 29.2890\n",
      "Epoch [10/25], Train Loss: 873.8246, Eval Loss: 29.0560\n",
      "Epoch [11/25], Train Loss: 862.0416, Eval Loss: 28.9538\n",
      "Epoch [12/25], Train Loss: 856.7528, Eval Loss: 28.9141\n",
      "Epoch [13/25], Train Loss: 854.5395, Eval Loss: 28.9014\n",
      "Epoch [14/25], Train Loss: 853.6883, Eval Loss: 28.8990\n",
      "Epoch [15/25], Train Loss: 853.3986, Eval Loss: 28.8999\n",
      "Epoch [16/25], Train Loss: 853.3229, Eval Loss: 28.9013\n",
      "Epoch [17/25], Train Loss: 853.3215, Eval Loss: 28.9024\n",
      "Epoch [18/25], Train Loss: 853.3428, Eval Loss: 28.9032\n",
      "Epoch [19/25], Train Loss: 853.3695, Eval Loss: 28.9038\n",
      "Epoch [20/25], Train Loss: 853.3965, Eval Loss: 28.9041\n",
      "Epoch [21/25], Train Loss: 853.4226, Eval Loss: 28.9044\n",
      "Epoch [22/25], Train Loss: 853.4478, Eval Loss: 28.9046\n",
      "Epoch [23/25], Train Loss: 853.4722, Eval Loss: 28.9047\n",
      "Epoch [24/25], Train Loss: 853.4960, Eval Loss: 28.9049\n",
      "Epoch [25/25], Train Loss: 853.5191, Eval Loss: 28.9050\n",
      "Epoch [1/25], Train Loss: 7168.5027, Eval Loss: 72.9829\n",
      "Epoch [2/25], Train Loss: 4509.3479, Eval Loss: 58.2961\n",
      "Epoch [3/25], Train Loss: 2969.2191, Eval Loss: 47.6818\n",
      "Epoch [4/25], Train Loss: 2058.7523, Eval Loss: 40.3241\n",
      "Epoch [5/25], Train Loss: 1526.1420, Eval Loss: 35.5117\n",
      "Epoch [6/25], Train Loss: 1219.7881, Eval Loss: 32.5388\n",
      "Epoch [7/25], Train Loss: 1046.9139, Eval Loss: 30.7941\n",
      "Epoch [8/25], Train Loss: 951.6863, Eval Loss: 29.8235\n",
      "Epoch [9/25], Train Loss: 900.9797, Eval Loss: 29.3161\n",
      "Epoch [10/25], Train Loss: 875.1660, Eval Loss: 29.0695\n",
      "Epoch [11/25], Train Loss: 862.7175, Eval Loss: 28.9599\n",
      "Epoch [12/25], Train Loss: 857.0719, Eval Loss: 28.9164\n",
      "Epoch [13/25], Train Loss: 854.6821, Eval Loss: 28.9021\n",
      "Epoch [14/25], Train Loss: 853.7502, Eval Loss: 28.8991\n",
      "Epoch [15/25], Train Loss: 853.4263, Eval Loss: 28.8998\n",
      "Epoch [16/25], Train Loss: 853.3373, Eval Loss: 28.9011\n",
      "Epoch [17/25], Train Loss: 853.3313, Eval Loss: 28.9023\n",
      "Epoch [18/25], Train Loss: 853.3511, Eval Loss: 28.9032\n",
      "Epoch [19/25], Train Loss: 853.3774, Eval Loss: 28.9037\n",
      "Epoch [20/25], Train Loss: 853.4043, Eval Loss: 28.9041\n",
      "Epoch [21/25], Train Loss: 853.4304, Eval Loss: 28.9043\n",
      "Epoch [22/25], Train Loss: 853.4555, Eval Loss: 28.9045\n",
      "Epoch [23/25], Train Loss: 853.4797, Eval Loss: 28.9047\n",
      "Epoch [24/25], Train Loss: 853.5033, Eval Loss: 28.9048\n",
      "Epoch [25/25], Train Loss: 853.5262, Eval Loss: 28.9049\n",
      "Epoch [1/25], Train Loss: 1602.6534, Eval Loss: 29.0736\n",
      "Epoch [2/25], Train Loss: 862.6268, Eval Loss: 29.0730\n",
      "Epoch [3/25], Train Loss: 862.5996, Eval Loss: 29.0724\n",
      "Epoch [4/25], Train Loss: 862.5685, Eval Loss: 29.0715\n",
      "Epoch [5/25], Train Loss: 862.5294, Eval Loss: 29.0701\n",
      "Epoch [6/25], Train Loss: 862.4822, Eval Loss: 29.0672\n",
      "Epoch [7/25], Train Loss: 862.4513, Eval Loss: 29.0606\n",
      "Epoch [8/25], Train Loss: 862.4592, Eval Loss: 29.0488\n",
      "Epoch [9/25], Train Loss: 862.7435, Eval Loss: 29.0517\n",
      "Epoch [10/25], Train Loss: 862.1965, Eval Loss: 29.0420\n",
      "Epoch [11/25], Train Loss: 861.9931, Eval Loss: 29.0305\n",
      "Epoch [12/25], Train Loss: 861.4821, Eval Loss: 29.0090\n",
      "Epoch [13/25], Train Loss: 860.6650, Eval Loss: 28.9758\n",
      "Epoch [14/25], Train Loss: 858.8520, Eval Loss: 28.9030\n",
      "Epoch [15/25], Train Loss: 854.9142, Eval Loss: 28.7487\n",
      "Epoch [16/25], Train Loss: 846.2373, Eval Loss: 28.4859\n",
      "Epoch [17/25], Train Loss: 832.6311, Eval Loss: 28.7284\n",
      "Epoch [18/25], Train Loss: 819.7156, Eval Loss: 28.0106\n",
      "Epoch [19/25], Train Loss: 799.7037, Eval Loss: 27.3664\n",
      "Epoch [20/25], Train Loss: 775.9883, Eval Loss: 25.3374\n",
      "Epoch [21/25], Train Loss: 750.7929, Eval Loss: 24.5554\n",
      "Epoch [22/25], Train Loss: 736.5283, Eval Loss: 24.3280\n",
      "Epoch [23/25], Train Loss: 674.6141, Eval Loss: 24.4190\n",
      "Epoch [24/25], Train Loss: 714.9895, Eval Loss: 24.2884\n",
      "Epoch [25/25], Train Loss: 696.4916, Eval Loss: 26.4206\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:tanh, o:sgd, wd:0\n",
      "Epoch [1/25], Train Loss: 1607.0863, Eval Loss: 29.0727\n",
      "Epoch [2/25], Train Loss: 862.5921, Eval Loss: 29.0717\n",
      "Epoch [3/25], Train Loss: 862.5565, Eval Loss: 29.0705\n",
      "Epoch [4/25], Train Loss: 862.5217, Eval Loss: 29.0689\n",
      "Epoch [5/25], Train Loss: 862.4798, Eval Loss: 29.0666\n",
      "Epoch [6/25], Train Loss: 862.4104, Eval Loss: 29.0665\n",
      "Epoch [7/25], Train Loss: 862.3270, Eval Loss: 29.0637\n",
      "Epoch [8/25], Train Loss: 862.2142, Eval Loss: 29.0577\n",
      "Epoch [9/25], Train Loss: 862.0602, Eval Loss: 29.0490\n",
      "Epoch [10/25], Train Loss: 861.9244, Eval Loss: 29.0416\n",
      "Epoch [11/25], Train Loss: 861.6911, Eval Loss: 29.0191\n",
      "Epoch [12/25], Train Loss: 861.1413, Eval Loss: 28.9873\n",
      "Epoch [13/25], Train Loss: 859.9805, Eval Loss: 28.9488\n",
      "Epoch [14/25], Train Loss: 856.9137, Eval Loss: 28.8668\n",
      "Epoch [15/25], Train Loss: 851.1310, Eval Loss: 28.6914\n",
      "Epoch [16/25], Train Loss: 838.1226, Eval Loss: 28.1550\n",
      "Epoch [17/25], Train Loss: 816.8849, Eval Loss: 27.5627\n",
      "Epoch [18/25], Train Loss: 787.0661, Eval Loss: 26.6559\n",
      "Epoch [19/25], Train Loss: 801.2409, Eval Loss: 26.4278\n",
      "Epoch [20/25], Train Loss: 736.5401, Eval Loss: 25.6729\n",
      "Epoch [21/25], Train Loss: 731.4679, Eval Loss: 25.6278\n",
      "Epoch [22/25], Train Loss: 721.1355, Eval Loss: 24.6454\n",
      "Epoch [23/25], Train Loss: 707.0529, Eval Loss: 26.5436\n",
      "Epoch [24/25], Train Loss: 706.7358, Eval Loss: 23.7357\n",
      "Epoch [25/25], Train Loss: 714.1603, Eval Loss: 26.4335\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.001, a:tanh, o:sgd, wd:0.0005\n",
      "Epoch [1/25], Train Loss: 3114.9193, Eval Loss: 29.7975\n",
      "Epoch [2/25], Train Loss: 956.8258, Eval Loss: 30.5020\n",
      "Epoch [3/25], Train Loss: 954.6961, Eval Loss: 30.5874\n",
      "Epoch [4/25], Train Loss: 947.4190, Eval Loss: 31.0865\n",
      "Epoch [5/25], Train Loss: 926.9447, Eval Loss: 30.2558\n",
      "Epoch [6/25], Train Loss: 927.3830, Eval Loss: 29.4734\n",
      "Epoch [7/25], Train Loss: 892.5346, Eval Loss: 29.5904\n",
      "Epoch [8/25], Train Loss: 904.5749, Eval Loss: 29.3960\n",
      "Epoch [9/25], Train Loss: 869.4078, Eval Loss: 29.0984\n",
      "Epoch [10/25], Train Loss: 880.4492, Eval Loss: 28.6413\n",
      "Epoch [11/25], Train Loss: 847.5073, Eval Loss: 28.4030\n",
      "Epoch [12/25], Train Loss: 854.5939, Eval Loss: 27.1497\n",
      "Epoch [13/25], Train Loss: 833.8981, Eval Loss: 27.3485\n",
      "Epoch [14/25], Train Loss: 812.2175, Eval Loss: 26.6295\n",
      "Epoch [15/25], Train Loss: 793.5441, Eval Loss: 26.2135\n",
      "Epoch [16/25], Train Loss: 763.2229, Eval Loss: 25.7362\n",
      "Epoch [17/25], Train Loss: 725.4036, Eval Loss: 25.0644\n",
      "Epoch [18/25], Train Loss: 724.4693, Eval Loss: 24.7383\n",
      "Epoch [19/25], Train Loss: 698.8240, Eval Loss: 24.5086\n",
      "Epoch [20/25], Train Loss: 724.5457, Eval Loss: 24.5437\n",
      "Epoch [21/25], Train Loss: 650.8778, Eval Loss: 24.1598\n",
      "Epoch [22/25], Train Loss: 638.0749, Eval Loss: 21.4745\n",
      "Epoch [23/25], Train Loss: 557.9343, Eval Loss: 20.6646\n",
      "Epoch [24/25], Train Loss: 477.7971, Eval Loss: 17.5631\n",
      "Epoch [25/25], Train Loss: 389.9027, Eval Loss: 16.4652\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:1, dr:0, lr:0.01, a:relu, o:adam, wd:0\n",
      "Epoch [1/25], Train Loss: 2346.9700, Eval Loss: 30.4453\n",
      "Epoch [2/25], Train Loss: 965.9118, Eval Loss: 31.7087\n",
      "Epoch [3/25], Train Loss: 969.6529, Eval Loss: 31.6901\n",
      "Epoch [4/25], Train Loss: 964.7228, Eval Loss: 31.4925\n",
      "Epoch [5/25], Train Loss: 958.4848, Eval Loss: 31.3239\n",
      "Epoch [6/25], Train Loss: 949.9111, Eval Loss: 31.1144\n",
      "Epoch [7/25], Train Loss: 942.4429, Eval Loss: 30.8607\n",
      "Epoch [8/25], Train Loss: 929.6205, Eval Loss: 30.6532\n",
      "Epoch [9/25], Train Loss: 921.3223, Eval Loss: 30.0376\n",
      "Epoch [10/25], Train Loss: 897.5417, Eval Loss: 29.8320\n",
      "Epoch [11/25], Train Loss: 894.2167, Eval Loss: 28.2532\n",
      "Epoch [12/25], Train Loss: 926.5793, Eval Loss: 27.9422\n",
      "Epoch [13/25], Train Loss: 858.5579, Eval Loss: 27.8420\n",
      "Epoch [14/25], Train Loss: 840.2776, Eval Loss: 27.5902\n",
      "Epoch [15/25], Train Loss: 819.7955, Eval Loss: 27.2823\n",
      "Epoch [16/25], Train Loss: 791.7272, Eval Loss: 26.1271\n",
      "Epoch [17/25], Train Loss: 781.2562, Eval Loss: 26.1514\n",
      "Epoch [18/25], Train Loss: 810.8760, Eval Loss: 25.3782\n",
      "Epoch [19/25], Train Loss: 743.4244, Eval Loss: 25.2237\n",
      "Epoch [20/25], Train Loss: 716.6090, Eval Loss: 24.8823\n",
      "Epoch [21/25], Train Loss: 713.8815, Eval Loss: 24.7930\n",
      "Epoch [22/25], Train Loss: 687.7182, Eval Loss: 24.9596\n",
      "Epoch [23/25], Train Loss: 658.3055, Eval Loss: 23.1865\n",
      "Epoch [24/25], Train Loss: 620.1453, Eval Loss: 21.2176\n",
      "Epoch [25/25], Train Loss: 560.2493, Eval Loss: 20.9370\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 2422.4948, Eval Loss: 28.9329\n",
      "Epoch [2/25], Train Loss: 857.8739, Eval Loss: 28.8851\n",
      "Epoch [3/25], Train Loss: 857.1419, Eval Loss: 28.8864\n",
      "Epoch [4/25], Train Loss: 857.5181, Eval Loss: 28.8868\n",
      "Epoch [5/25], Train Loss: 857.8125, Eval Loss: 28.8876\n",
      "Epoch [6/25], Train Loss: 858.0736, Eval Loss: 28.8888\n",
      "Epoch [7/25], Train Loss: 858.3109, Eval Loss: 28.8904\n",
      "Epoch [8/25], Train Loss: 858.5283, Eval Loss: 28.8923\n",
      "Epoch [9/25], Train Loss: 858.7277, Eval Loss: 28.8942\n",
      "Epoch [10/25], Train Loss: 858.9105, Eval Loss: 28.8961\n",
      "Epoch [11/25], Train Loss: 859.0781, Eval Loss: 28.8979\n",
      "Epoch [12/25], Train Loss: 859.2316, Eval Loss: 28.8995\n",
      "Epoch [13/25], Train Loss: 859.3726, Eval Loss: 28.9010\n",
      "Epoch [14/25], Train Loss: 859.5027, Eval Loss: 28.9024\n",
      "Epoch [15/25], Train Loss: 859.6230, Eval Loss: 28.9037\n",
      "Epoch [16/25], Train Loss: 859.7347, Eval Loss: 28.9050\n",
      "Epoch [17/25], Train Loss: 859.8388, Eval Loss: 28.9062\n",
      "Epoch [18/25], Train Loss: 859.9358, Eval Loss: 28.9074\n",
      "Epoch [19/25], Train Loss: 860.0264, Eval Loss: 28.9087\n",
      "Epoch [20/25], Train Loss: 860.1110, Eval Loss: 28.9099\n",
      "Epoch [21/25], Train Loss: 860.1899, Eval Loss: 28.9111\n",
      "Epoch [22/25], Train Loss: 860.2634, Eval Loss: 28.9124\n",
      "Epoch [23/25], Train Loss: 860.3319, Eval Loss: 28.9136\n",
      "Epoch [24/25], Train Loss: 860.3955, Eval Loss: 28.9149\n",
      "Epoch [25/25], Train Loss: 860.4546, Eval Loss: 28.9161\n",
      "Epoch [1/25], Train Loss: 2423.1923, Eval Loss: 28.9327\n",
      "Epoch [2/25], Train Loss: 857.8655, Eval Loss: 28.8851\n",
      "Epoch [3/25], Train Loss: 857.1317, Eval Loss: 28.8865\n",
      "Epoch [4/25], Train Loss: 857.5095, Eval Loss: 28.8869\n",
      "Epoch [5/25], Train Loss: 857.8042, Eval Loss: 28.8876\n",
      "Epoch [6/25], Train Loss: 858.0641, Eval Loss: 28.8888\n",
      "Epoch [7/25], Train Loss: 858.3008, Eval Loss: 28.8904\n",
      "Epoch [8/25], Train Loss: 858.5181, Eval Loss: 28.8922\n",
      "Epoch [9/25], Train Loss: 858.7182, Eval Loss: 28.8942\n",
      "Epoch [10/25], Train Loss: 858.9024, Eval Loss: 28.8961\n",
      "Epoch [11/25], Train Loss: 859.0716, Eval Loss: 28.8979\n",
      "Epoch [12/25], Train Loss: 859.2270, Eval Loss: 28.8996\n",
      "Epoch [13/25], Train Loss: 859.3698, Eval Loss: 28.9011\n",
      "Epoch [14/25], Train Loss: 859.5012, Eval Loss: 28.9025\n",
      "Epoch [15/25], Train Loss: 859.6225, Eval Loss: 28.9039\n",
      "Epoch [16/25], Train Loss: 859.7350, Eval Loss: 28.9052\n",
      "Epoch [17/25], Train Loss: 859.8394, Eval Loss: 28.9064\n",
      "Epoch [18/25], Train Loss: 859.9367, Eval Loss: 28.9076\n",
      "Epoch [19/25], Train Loss: 860.0273, Eval Loss: 28.9089\n",
      "Epoch [20/25], Train Loss: 860.1119, Eval Loss: 28.9101\n",
      "Epoch [21/25], Train Loss: 860.1907, Eval Loss: 28.9113\n",
      "Epoch [22/25], Train Loss: 860.2640, Eval Loss: 28.9125\n",
      "Epoch [23/25], Train Loss: 860.3323, Eval Loss: 28.9138\n",
      "Epoch [24/25], Train Loss: 860.3957, Eval Loss: 28.9150\n",
      "Epoch [25/25], Train Loss: 860.4160, Eval Loss: 28.9382\n",
      "Epoch [1/25], Train Loss: 1340.8325, Eval Loss: 32.2343\n",
      "Epoch [2/25], Train Loss: 1048.3977, Eval Loss: 32.2817\n",
      "Epoch [3/25], Train Loss: 1051.5125, Eval Loss: 32.2802\n",
      "Epoch [4/25], Train Loss: 1051.0586, Eval Loss: 32.2821\n",
      "Epoch [5/25], Train Loss: 1051.5277, Eval Loss: 32.2836\n",
      "Epoch [6/25], Train Loss: 1051.3169, Eval Loss: 32.2833\n",
      "Epoch [7/25], Train Loss: 1051.8736, Eval Loss: 32.2835\n",
      "Epoch [8/25], Train Loss: 1051.7549, Eval Loss: 32.2843\n",
      "Epoch [9/25], Train Loss: 1051.7327, Eval Loss: 32.2838\n",
      "Epoch [10/25], Train Loss: 1051.7102, Eval Loss: 32.2843\n",
      "Epoch [11/25], Train Loss: 1051.7265, Eval Loss: 32.2840\n",
      "Epoch [12/25], Train Loss: 1051.6694, Eval Loss: 32.2841\n",
      "Epoch [13/25], Train Loss: 1051.7182, Eval Loss: 32.2839\n",
      "Epoch [14/25], Train Loss: 1051.7246, Eval Loss: 32.2718\n",
      "Epoch [15/25], Train Loss: 1051.5063, Eval Loss: 32.2841\n",
      "Epoch [16/25], Train Loss: 1051.6825, Eval Loss: 32.2833\n",
      "Epoch [17/25], Train Loss: 1051.5564, Eval Loss: 32.2840\n",
      "Epoch [18/25], Train Loss: 1051.7015, Eval Loss: 32.2832\n",
      "Epoch [19/25], Train Loss: 1051.4073, Eval Loss: 32.2510\n",
      "Epoch [20/25], Train Loss: 1051.6191, Eval Loss: 32.2841\n",
      "Epoch [21/25], Train Loss: 1051.6078, Eval Loss: 32.2841\n",
      "Epoch [22/25], Train Loss: 1051.7278, Eval Loss: 32.2841\n",
      "Epoch [23/25], Train Loss: 1051.4003, Eval Loss: 32.2839\n",
      "Epoch [24/25], Train Loss: 1051.7050, Eval Loss: 32.2836\n",
      "Epoch [25/25], Train Loss: 1051.6534, Eval Loss: 32.2841\n",
      "Epoch [1/25], Train Loss: 1313.0119, Eval Loss: 32.2758\n",
      "Epoch [2/25], Train Loss: 1051.4595, Eval Loss: 32.2751\n",
      "Epoch [3/25], Train Loss: 1051.0220, Eval Loss: 32.2582\n",
      "Epoch [4/25], Train Loss: 1050.7039, Eval Loss: 32.2655\n",
      "Epoch [5/25], Train Loss: 1051.0734, Eval Loss: 32.2748\n",
      "Epoch [6/25], Train Loss: 1050.8184, Eval Loss: 32.2619\n",
      "Epoch [7/25], Train Loss: 1051.2080, Eval Loss: 32.2775\n",
      "Epoch [8/25], Train Loss: 1051.1680, Eval Loss: 32.2881\n",
      "Epoch [9/25], Train Loss: 1051.5332, Eval Loss: 32.2828\n",
      "Epoch [10/25], Train Loss: 1051.5510, Eval Loss: 32.2722\n",
      "Epoch [11/25], Train Loss: 1051.1051, Eval Loss: 32.2811\n",
      "Epoch [12/25], Train Loss: 1051.2027, Eval Loss: 32.2817\n",
      "Epoch [13/25], Train Loss: 1051.3887, Eval Loss: 32.2813\n",
      "Epoch [14/25], Train Loss: 1051.2921, Eval Loss: 32.2816\n",
      "Epoch [15/25], Train Loss: 1051.5543, Eval Loss: 32.2813\n",
      "Epoch [16/25], Train Loss: 1051.4849, Eval Loss: 32.2812\n",
      "Epoch [17/25], Train Loss: 1051.5776, Eval Loss: 32.2816\n",
      "Epoch [18/25], Train Loss: 1051.4605, Eval Loss: 32.2817\n",
      "Epoch [19/25], Train Loss: 1051.5380, Eval Loss: 32.2813\n",
      "Epoch [20/25], Train Loss: 1051.5292, Eval Loss: 32.2806\n",
      "Epoch [21/25], Train Loss: 1051.2149, Eval Loss: 32.2467\n",
      "Epoch [22/25], Train Loss: 1045.2696, Eval Loss: 32.2817\n",
      "Epoch [23/25], Train Loss: 1051.3535, Eval Loss: 32.2817\n",
      "Epoch [24/25], Train Loss: 1051.4719, Eval Loss: 32.2822\n",
      "Epoch [25/25], Train Loss: 1051.9247, Eval Loss: 32.2815\n",
      "Epoch [1/25], Train Loss: 4752.6455, Eval Loss: 30.6720\n",
      "Epoch [2/25], Train Loss: 862.6323, Eval Loss: 29.0585\n",
      "Epoch [3/25], Train Loss: 859.4537, Eval Loss: 29.0819\n",
      "Epoch [4/25], Train Loss: 859.7684, Eval Loss: 29.0885\n",
      "Epoch [5/25], Train Loss: 860.0917, Eval Loss: 29.0934\n",
      "Epoch [6/25], Train Loss: 860.3740, Eval Loss: 29.0989\n",
      "Epoch [7/25], Train Loss: 860.5378, Eval Loss: 29.1026\n",
      "Epoch [8/25], Train Loss: 860.6581, Eval Loss: 29.1066\n",
      "Epoch [9/25], Train Loss: 860.7275, Eval Loss: 29.1084\n",
      "Epoch [10/25], Train Loss: 860.7706, Eval Loss: 29.1092\n",
      "Epoch [11/25], Train Loss: 860.7695, Eval Loss: 29.1100\n",
      "Epoch [12/25], Train Loss: 860.7038, Eval Loss: 29.1103\n",
      "Epoch [13/25], Train Loss: 860.6236, Eval Loss: 29.1095\n",
      "Epoch [14/25], Train Loss: 860.5605, Eval Loss: 29.1091\n",
      "Epoch [15/25], Train Loss: 860.4648, Eval Loss: 29.1081\n",
      "Epoch [16/25], Train Loss: 860.3507, Eval Loss: 29.1062\n",
      "Epoch [17/25], Train Loss: 860.2151, Eval Loss: 29.1043\n",
      "Epoch [18/25], Train Loss: 860.0953, Eval Loss: 29.1022\n",
      "Epoch [19/25], Train Loss: 859.9288, Eval Loss: 29.0990\n",
      "Epoch [20/25], Train Loss: 859.7722, Eval Loss: 29.0962\n",
      "Epoch [21/25], Train Loss: 859.5995, Eval Loss: 29.0932\n",
      "Epoch [22/25], Train Loss: 859.4443, Eval Loss: 29.0910\n",
      "Epoch [23/25], Train Loss: 859.2720, Eval Loss: 29.0874\n",
      "Epoch [24/25], Train Loss: 859.0539, Eval Loss: 29.0860\n",
      "Epoch [25/25], Train Loss: 858.8959, Eval Loss: 29.0802\n",
      "Epoch [1/25], Train Loss: 4945.1312, Eval Loss: 31.0070\n",
      "Epoch [2/25], Train Loss: 866.9145, Eval Loss: 29.0653\n",
      "Epoch [3/25], Train Loss: 859.3055, Eval Loss: 29.0984\n",
      "Epoch [4/25], Train Loss: 859.8534, Eval Loss: 29.1123\n",
      "Epoch [5/25], Train Loss: 860.2553, Eval Loss: 29.1211\n",
      "Epoch [6/25], Train Loss: 860.5259, Eval Loss: 29.1344\n",
      "Epoch [7/25], Train Loss: 860.7337, Eval Loss: 29.1337\n",
      "Epoch [8/25], Train Loss: 860.8715, Eval Loss: 29.1383\n",
      "Epoch [9/25], Train Loss: 861.0987, Eval Loss: 29.1433\n",
      "Epoch [10/25], Train Loss: 861.1076, Eval Loss: 29.1423\n",
      "Epoch [11/25], Train Loss: 861.1771, Eval Loss: 29.1479\n",
      "Epoch [12/25], Train Loss: 861.1607, Eval Loss: 29.1467\n",
      "Epoch [13/25], Train Loss: 861.0943, Eval Loss: 29.1458\n",
      "Epoch [14/25], Train Loss: 861.0332, Eval Loss: 29.1450\n",
      "Epoch [15/25], Train Loss: 860.9128, Eval Loss: 29.1421\n",
      "Epoch [16/25], Train Loss: 860.8321, Eval Loss: 29.1404\n",
      "Epoch [17/25], Train Loss: 860.8370, Eval Loss: 29.1392\n",
      "Epoch [18/25], Train Loss: 860.6421, Eval Loss: 29.1358\n",
      "Epoch [19/25], Train Loss: 860.5300, Eval Loss: 29.1335\n",
      "Epoch [20/25], Train Loss: 860.3873, Eval Loss: 29.1302\n",
      "Epoch [21/25], Train Loss: 860.2422, Eval Loss: 29.1280\n",
      "Epoch [22/25], Train Loss: 860.0801, Eval Loss: 29.1237\n",
      "Epoch [23/25], Train Loss: 859.9622, Eval Loss: 29.1216\n",
      "Epoch [24/25], Train Loss: 859.8595, Eval Loss: 29.1192\n",
      "Epoch [25/25], Train Loss: 859.6135, Eval Loss: 29.1163\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9207.7203, Eval Loss: 94.9920\n",
      "Epoch [2/25], Train Loss: 9282.1354, Eval Loss: 94.5952\n",
      "Epoch [3/25], Train Loss: 9499.4129, Eval Loss: 94.3874\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8756.3310, Eval Loss: 89.6460\n",
      "Epoch [2/25], Train Loss: 8085.5777, Eval Loss: 87.1641\n",
      "Epoch [3/25], Train Loss: 7687.0454, Eval Loss: 85.0658\n",
      "Epoch [4/25], Train Loss: 7337.8630, Eval Loss: 83.1073\n",
      "Epoch [5/25], Train Loss: 7014.6665, Eval Loss: 81.2329\n",
      "Epoch [6/25], Train Loss: 6710.5557, Eval Loss: 79.4216\n",
      "Epoch [7/25], Train Loss: 6422.3800, Eval Loss: 77.6633\n",
      "Epoch [8/25], Train Loss: 6148.3159, Eval Loss: 75.9524\n",
      "Epoch [9/25], Train Loss: 5887.1394, Eval Loss: 74.2850\n",
      "Epoch [10/25], Train Loss: 5637.9428, Eval Loss: 72.6589\n",
      "Epoch [11/25], Train Loss: 5400.0027, Eval Loss: 71.0722\n",
      "Epoch [12/25], Train Loss: 5172.7128, Eval Loss: 69.5237\n",
      "Epoch [13/25], Train Loss: 4955.5451, Eval Loss: 68.0124\n",
      "Epoch [14/25], Train Loss: 4748.0285, Eval Loss: 66.5373\n",
      "Epoch [15/25], Train Loss: 4549.7329, Eval Loss: 65.0980\n",
      "Epoch [16/25], Train Loss: 4360.2612, Eval Loss: 63.6938\n",
      "Epoch [17/25], Train Loss: 4179.2419, Eval Loss: 62.3242\n",
      "Epoch [18/25], Train Loss: 4006.3251, Eval Loss: 60.9888\n",
      "Epoch [19/25], Train Loss: 3841.1787, Eval Loss: 59.6873\n",
      "Epoch [20/25], Train Loss: 3683.4869, Eval Loss: 58.4191\n",
      "Epoch [21/25], Train Loss: 3532.9479, Eval Loss: 57.1841\n",
      "Epoch [22/25], Train Loss: 3389.2726, Eval Loss: 55.9819\n",
      "Epoch [23/25], Train Loss: 3252.1838, Eval Loss: 54.8122\n",
      "Epoch [24/25], Train Loss: 3121.4154, Eval Loss: 53.6747\n",
      "Epoch [25/25], Train Loss: 2996.7115, Eval Loss: 52.5691\n",
      "Epoch [1/25], Train Loss: 8721.8433, Eval Loss: 89.5394\n",
      "Epoch [2/25], Train Loss: 8073.2041, Eval Loss: 87.1286\n",
      "Epoch [3/25], Train Loss: 7682.4597, Eval Loss: 85.0533\n",
      "Epoch [4/25], Train Loss: 7336.0390, Eval Loss: 83.1049\n",
      "Epoch [5/25], Train Loss: 7014.0415, Eval Loss: 81.2348\n",
      "Epoch [6/25], Train Loss: 6710.3693, Eval Loss: 79.4245\n",
      "Epoch [7/25], Train Loss: 6422.1884, Eval Loss: 77.6652\n",
      "Epoch [8/25], Train Loss: 6147.8349, Eval Loss: 75.9516\n",
      "Epoch [9/25], Train Loss: 5886.1784, Eval Loss: 74.2804\n",
      "Epoch [10/25], Train Loss: 5636.3701, Eval Loss: 72.6496\n",
      "Epoch [11/25], Train Loss: 5397.7276, Eval Loss: 71.0574\n",
      "Epoch [12/25], Train Loss: 5169.6737, Eval Loss: 69.5029\n",
      "Epoch [13/25], Train Loss: 4951.7030, Eval Loss: 67.9850\n",
      "Epoch [14/25], Train Loss: 4743.3609, Eval Loss: 66.5031\n",
      "Epoch [15/25], Train Loss: 4544.2317, Eval Loss: 65.0566\n",
      "Epoch [16/25], Train Loss: 4353.9289, Eval Loss: 63.6449\n",
      "Epoch [17/25], Train Loss: 4172.0904, Eval Loss: 62.2677\n",
      "Epoch [18/25], Train Loss: 3998.3738, Eval Loss: 60.9245\n",
      "Epoch [19/25], Train Loss: 3832.4537, Eval Loss: 59.6151\n",
      "Epoch [20/25], Train Loss: 3674.0195, Eval Loss: 58.3391\n",
      "Epoch [21/25], Train Loss: 3522.7738, Eval Loss: 57.0963\n",
      "Epoch [22/25], Train Loss: 3378.4312, Eval Loss: 55.8864\n",
      "Epoch [23/25], Train Loss: 3240.7179, Eval Loss: 54.7090\n",
      "Epoch [24/25], Train Loss: 3109.3697, Eval Loss: 53.5641\n",
      "Epoch [25/25], Train Loss: 2984.1328, Eval Loss: 52.4513\n",
      "Epoch [1/25], Train Loss: 5726.6559, Eval Loss: 47.6949\n",
      "Epoch [2/25], Train Loss: 1504.1133, Eval Loss: 31.4048\n",
      "Epoch [3/25], Train Loss: 929.4635, Eval Loss: 29.1338\n",
      "Epoch [4/25], Train Loss: 862.6383, Eval Loss: 28.9044\n",
      "Epoch [5/25], Train Loss: 854.8857, Eval Loss: 28.8927\n",
      "Epoch [6/25], Train Loss: 853.9865, Eval Loss: 28.8965\n",
      "Epoch [7/25], Train Loss: 853.8820, Eval Loss: 28.8987\n",
      "Epoch [8/25], Train Loss: 853.8697, Eval Loss: 28.8995\n",
      "Epoch [9/25], Train Loss: 853.8680, Eval Loss: 28.8998\n",
      "Epoch [10/25], Train Loss: 853.8675, Eval Loss: 28.8999\n",
      "Epoch [11/25], Train Loss: 853.8672, Eval Loss: 28.8999\n",
      "Epoch [12/25], Train Loss: 853.8669, Eval Loss: 28.8999\n",
      "Epoch [13/25], Train Loss: 853.8666, Eval Loss: 28.8999\n",
      "Epoch [14/25], Train Loss: 853.8663, Eval Loss: 28.8999\n",
      "Epoch [15/25], Train Loss: 853.8660, Eval Loss: 28.8999\n",
      "Epoch [16/25], Train Loss: 853.8657, Eval Loss: 28.8999\n",
      "Epoch [17/25], Train Loss: 853.8653, Eval Loss: 28.8999\n",
      "Epoch [18/25], Train Loss: 853.8650, Eval Loss: 28.8999\n",
      "Epoch [19/25], Train Loss: 853.8647, Eval Loss: 28.8999\n",
      "Epoch [20/25], Train Loss: 853.8644, Eval Loss: 28.8999\n",
      "Epoch [21/25], Train Loss: 853.8641, Eval Loss: 28.8999\n",
      "Epoch [22/25], Train Loss: 853.8638, Eval Loss: 28.8999\n",
      "Epoch [23/25], Train Loss: 853.8635, Eval Loss: 28.8999\n",
      "Epoch [24/25], Train Loss: 853.8632, Eval Loss: 28.8999\n",
      "Epoch [25/25], Train Loss: 853.8629, Eval Loss: 28.8999\n",
      "Epoch [1/25], Train Loss: 5663.1200, Eval Loss: 47.1687\n",
      "Epoch [2/25], Train Loss: 1481.6933, Eval Loss: 31.3149\n",
      "Epoch [3/25], Train Loss: 926.8261, Eval Loss: 29.1240\n",
      "Epoch [4/25], Train Loss: 862.3433, Eval Loss: 28.9038\n",
      "Epoch [5/25], Train Loss: 854.8601, Eval Loss: 28.8929\n",
      "Epoch [6/25], Train Loss: 853.9914, Eval Loss: 28.8967\n",
      "Epoch [7/25], Train Loss: 853.8901, Eval Loss: 28.8988\n",
      "Epoch [8/25], Train Loss: 853.8781, Eval Loss: 28.8997\n",
      "Epoch [9/25], Train Loss: 853.8764, Eval Loss: 28.9000\n",
      "Epoch [10/25], Train Loss: 853.8759, Eval Loss: 28.9001\n",
      "Epoch [11/25], Train Loss: 853.8755, Eval Loss: 28.9001\n",
      "Epoch [12/25], Train Loss: 853.8752, Eval Loss: 28.9001\n",
      "Epoch [13/25], Train Loss: 853.8749, Eval Loss: 28.9001\n",
      "Epoch [14/25], Train Loss: 853.8745, Eval Loss: 28.9001\n",
      "Epoch [15/25], Train Loss: 853.8742, Eval Loss: 28.9001\n",
      "Epoch [16/25], Train Loss: 853.8739, Eval Loss: 28.9001\n",
      "Epoch [17/25], Train Loss: 853.8735, Eval Loss: 28.9001\n",
      "Epoch [18/25], Train Loss: 853.8732, Eval Loss: 28.9001\n",
      "Epoch [19/25], Train Loss: 853.8729, Eval Loss: 28.9000\n",
      "Epoch [20/25], Train Loss: 853.8725, Eval Loss: 28.9000\n",
      "Epoch [21/25], Train Loss: 853.8722, Eval Loss: 28.9000\n",
      "Epoch [22/25], Train Loss: 853.8719, Eval Loss: 28.9000\n",
      "Epoch [23/25], Train Loss: 853.8716, Eval Loss: 28.9000\n",
      "Epoch [24/25], Train Loss: 853.8712, Eval Loss: 28.9000\n",
      "Epoch [25/25], Train Loss: 853.8709, Eval Loss: 28.9000\n",
      "Epoch [1/25], Train Loss: 1669.3106, Eval Loss: 29.4210\n",
      "Epoch [2/25], Train Loss: 929.5975, Eval Loss: 29.0307\n",
      "Epoch [3/25], Train Loss: 941.4815, Eval Loss: 29.1256\n",
      "Epoch [4/25], Train Loss: 937.8930, Eval Loss: 29.0977\n",
      "Epoch [5/25], Train Loss: 933.9248, Eval Loss: 29.0724\n",
      "Epoch [6/25], Train Loss: 928.8505, Eval Loss: 28.9745\n",
      "Epoch [7/25], Train Loss: 924.1123, Eval Loss: 28.9856\n",
      "Epoch [8/25], Train Loss: 920.9470, Eval Loss: 28.8516\n",
      "Epoch [9/25], Train Loss: 914.1364, Eval Loss: 28.8171\n",
      "Epoch [10/25], Train Loss: 909.1665, Eval Loss: 28.7833\n",
      "Epoch [11/25], Train Loss: 904.4563, Eval Loss: 28.7722\n",
      "Epoch [12/25], Train Loss: 909.3430, Eval Loss: 28.7033\n",
      "Epoch [13/25], Train Loss: 897.6826, Eval Loss: 28.6650\n",
      "Epoch [14/25], Train Loss: 890.2070, Eval Loss: 28.6091\n",
      "Epoch [15/25], Train Loss: 886.5714, Eval Loss: 28.5409\n",
      "Epoch [16/25], Train Loss: 881.9284, Eval Loss: 28.5353\n",
      "Epoch [17/25], Train Loss: 880.6115, Eval Loss: 28.3779\n",
      "Epoch [18/25], Train Loss: 869.5890, Eval Loss: 28.2435\n",
      "Epoch [19/25], Train Loss: 863.5218, Eval Loss: 28.0745\n",
      "Epoch [20/25], Train Loss: 855.8851, Eval Loss: 27.9027\n",
      "Epoch [21/25], Train Loss: 846.1644, Eval Loss: 27.6744\n",
      "Epoch [22/25], Train Loss: 832.6079, Eval Loss: 27.3951\n",
      "Epoch [23/25], Train Loss: 817.9091, Eval Loss: 27.1148\n",
      "Epoch [24/25], Train Loss: 798.3740, Eval Loss: 26.7484\n",
      "Epoch [25/25], Train Loss: 774.3850, Eval Loss: 26.3542\n",
      "Epoch [1/25], Train Loss: 1614.4566, Eval Loss: 29.1114\n",
      "Epoch [2/25], Train Loss: 939.5254, Eval Loss: 29.3227\n",
      "Epoch [3/25], Train Loss: 941.8970, Eval Loss: 29.3747\n",
      "Epoch [4/25], Train Loss: 936.2934, Eval Loss: 29.2764\n",
      "Epoch [5/25], Train Loss: 932.4088, Eval Loss: 29.1329\n",
      "Epoch [6/25], Train Loss: 929.1852, Eval Loss: 28.9945\n",
      "Epoch [7/25], Train Loss: 924.5598, Eval Loss: 28.8965\n",
      "Epoch [8/25], Train Loss: 919.0953, Eval Loss: 28.8419\n",
      "Epoch [9/25], Train Loss: 913.1043, Eval Loss: 28.8062\n",
      "Epoch [10/25], Train Loss: 908.5716, Eval Loss: 28.7696\n",
      "Epoch [11/25], Train Loss: 903.0600, Eval Loss: 28.7312\n",
      "Epoch [12/25], Train Loss: 898.4919, Eval Loss: 28.6858\n",
      "Epoch [13/25], Train Loss: 893.9173, Eval Loss: 28.6361\n",
      "Epoch [14/25], Train Loss: 889.5906, Eval Loss: 28.5789\n",
      "Epoch [15/25], Train Loss: 884.6797, Eval Loss: 28.5034\n",
      "Epoch [16/25], Train Loss: 879.7629, Eval Loss: 28.4205\n",
      "Epoch [17/25], Train Loss: 874.1925, Eval Loss: 28.3183\n",
      "Epoch [18/25], Train Loss: 867.4488, Eval Loss: 28.1884\n",
      "Epoch [19/25], Train Loss: 860.6204, Eval Loss: 28.0355\n",
      "Epoch [20/25], Train Loss: 851.4000, Eval Loss: 27.8440\n",
      "Epoch [21/25], Train Loss: 841.5160, Eval Loss: 27.6099\n",
      "Epoch [22/25], Train Loss: 827.2057, Eval Loss: 27.3436\n",
      "Epoch [23/25], Train Loss: 815.3957, Eval Loss: 27.6275\n",
      "Epoch [24/25], Train Loss: 791.9223, Eval Loss: 26.6738\n",
      "Epoch [25/25], Train Loss: 769.5572, Eval Loss: 26.3732\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 7150.1237, Eval Loss: 73.3974\n",
      "Epoch [2/25], Train Loss: 4582.1829, Eval Loss: 58.9150\n",
      "Epoch [3/25], Train Loss: 3036.3747, Eval Loss: 48.2666\n",
      "Epoch [4/25], Train Loss: 2108.4515, Eval Loss: 40.7954\n",
      "Epoch [5/25], Train Loss: 1559.8844, Eval Loss: 35.8525\n",
      "Epoch [6/25], Train Loss: 1241.5030, Eval Loss: 32.7665\n",
      "Epoch [7/25], Train Loss: 1060.3464, Eval Loss: 30.9371\n",
      "Epoch [8/25], Train Loss: 959.6858, Eval Loss: 29.9079\n",
      "Epoch [9/25], Train Loss: 905.5329, Eval Loss: 29.3624\n",
      "Epoch [10/25], Train Loss: 877.6183, Eval Loss: 29.0929\n",
      "Epoch [11/25], Train Loss: 863.9555, Eval Loss: 28.9705\n",
      "Epoch [12/25], Train Loss: 857.6517, Eval Loss: 28.9206\n",
      "Epoch [13/25], Train Loss: 854.9295, Eval Loss: 28.9033\n",
      "Epoch [14/25], Train Loss: 853.8415, Eval Loss: 28.8992\n",
      "Epoch [15/25], Train Loss: 853.4498, Eval Loss: 28.8995\n",
      "Epoch [16/25], Train Loss: 853.3337, Eval Loss: 28.9008\n",
      "Epoch [17/25], Train Loss: 853.3177, Eval Loss: 28.9020\n",
      "Epoch [18/25], Train Loss: 853.3343, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 853.3597, Eval Loss: 28.9036\n",
      "Epoch [20/25], Train Loss: 853.3865, Eval Loss: 28.9040\n",
      "Epoch [21/25], Train Loss: 853.4126, Eval Loss: 28.9043\n",
      "Epoch [22/25], Train Loss: 853.4379, Eval Loss: 28.9045\n",
      "Epoch [23/25], Train Loss: 853.4623, Eval Loss: 28.9046\n",
      "Epoch [24/25], Train Loss: 853.4861, Eval Loss: 28.9048\n",
      "Epoch [25/25], Train Loss: 853.5092, Eval Loss: 28.9049\n",
      "Epoch [1/25], Train Loss: 7215.3755, Eval Loss: 73.6968\n",
      "Epoch [2/25], Train Loss: 4609.8767, Eval Loss: 59.0345\n",
      "Epoch [3/25], Train Loss: 3041.4323, Eval Loss: 48.2474\n",
      "Epoch [4/25], Train Loss: 2102.6577, Eval Loss: 40.6935\n",
      "Epoch [5/25], Train Loss: 1550.6046, Eval Loss: 35.7227\n",
      "Epoch [6/25], Train Loss: 1232.6325, Eval Loss: 32.6487\n",
      "Epoch [7/25], Train Loss: 1053.4966, Eval Loss: 30.8497\n",
      "Epoch [8/25], Train Loss: 955.0822, Eval Loss: 29.8518\n",
      "Epoch [9/25], Train Loss: 902.7483, Eval Loss: 29.3305\n",
      "Epoch [10/25], Train Loss: 876.0738, Eval Loss: 29.0765\n",
      "Epoch [11/25], Train Loss: 863.1609, Eval Loss: 28.9630\n",
      "Epoch [12/25], Train Loss: 857.2693, Eval Loss: 28.9175\n",
      "Epoch [13/25], Train Loss: 854.7554, Eval Loss: 28.9023\n",
      "Epoch [14/25], Train Loss: 853.7648, Eval Loss: 28.8989\n",
      "Epoch [15/25], Train Loss: 853.4151, Eval Loss: 28.8995\n",
      "Epoch [16/25], Train Loss: 853.3156, Eval Loss: 28.9009\n",
      "Epoch [17/25], Train Loss: 853.3056, Eval Loss: 28.9021\n",
      "Epoch [18/25], Train Loss: 853.3240, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 853.3499, Eval Loss: 28.9036\n",
      "Epoch [20/25], Train Loss: 853.3768, Eval Loss: 28.9040\n",
      "Epoch [21/25], Train Loss: 853.4029, Eval Loss: 28.9043\n",
      "Epoch [22/25], Train Loss: 853.4282, Eval Loss: 28.9045\n",
      "Epoch [23/25], Train Loss: 853.4528, Eval Loss: 28.9046\n",
      "Epoch [24/25], Train Loss: 853.4767, Eval Loss: 28.9048\n",
      "Epoch [25/25], Train Loss: 853.5000, Eval Loss: 28.9049\n",
      "Epoch [1/25], Train Loss: 1533.6681, Eval Loss: 29.0751\n",
      "Epoch [2/25], Train Loss: 862.6465, Eval Loss: 29.0750\n",
      "Epoch [3/25], Train Loss: 862.6424, Eval Loss: 29.0749\n",
      "Epoch [4/25], Train Loss: 862.6381, Eval Loss: 29.0748\n",
      "Epoch [5/25], Train Loss: 862.6335, Eval Loss: 29.0746\n",
      "Epoch [6/25], Train Loss: 862.6286, Eval Loss: 29.0745\n",
      "Epoch [7/25], Train Loss: 862.6231, Eval Loss: 29.0743\n",
      "Epoch [8/25], Train Loss: 862.6171, Eval Loss: 29.0741\n",
      "Epoch [9/25], Train Loss: 862.6102, Eval Loss: 29.0738\n",
      "Epoch [10/25], Train Loss: 862.6023, Eval Loss: 29.0735\n",
      "Epoch [11/25], Train Loss: 862.5933, Eval Loss: 29.0731\n",
      "Epoch [12/25], Train Loss: 862.5830, Eval Loss: 29.0725\n",
      "Epoch [13/25], Train Loss: 862.5710, Eval Loss: 29.0718\n",
      "Epoch [14/25], Train Loss: 862.5566, Eval Loss: 29.0709\n",
      "Epoch [15/25], Train Loss: 862.5392, Eval Loss: 29.0697\n",
      "Epoch [16/25], Train Loss: 862.5186, Eval Loss: 29.0680\n",
      "Epoch [17/25], Train Loss: 862.4951, Eval Loss: 29.0658\n",
      "Epoch [18/25], Train Loss: 862.4701, Eval Loss: 29.0626\n",
      "Epoch [19/25], Train Loss: 862.4469, Eval Loss: 29.0582\n",
      "Epoch [20/25], Train Loss: 862.4406, Eval Loss: 29.0524\n",
      "Epoch [21/25], Train Loss: 862.4625, Eval Loss: 29.0458\n",
      "Epoch [22/25], Train Loss: 862.4560, Eval Loss: 29.0384\n",
      "Epoch [23/25], Train Loss: 862.3447, Eval Loss: 29.0330\n",
      "Epoch [24/25], Train Loss: 862.5364, Eval Loss: 29.0315\n",
      "Epoch [25/25], Train Loss: 861.7949, Eval Loss: 29.0035\n",
      "Epoch [1/25], Train Loss: 1568.8447, Eval Loss: 29.0749\n",
      "Epoch [2/25], Train Loss: 862.6383, Eval Loss: 29.0747\n",
      "Epoch [3/25], Train Loss: 862.6345, Eval Loss: 29.0746\n",
      "Epoch [4/25], Train Loss: 862.6304, Eval Loss: 29.0745\n",
      "Epoch [5/25], Train Loss: 862.6262, Eval Loss: 29.0744\n",
      "Epoch [6/25], Train Loss: 862.6215, Eval Loss: 29.0742\n",
      "Epoch [7/25], Train Loss: 862.6164, Eval Loss: 29.0740\n",
      "Epoch [8/25], Train Loss: 862.6108, Eval Loss: 29.0738\n",
      "Epoch [9/25], Train Loss: 862.6045, Eval Loss: 29.0736\n",
      "Epoch [10/25], Train Loss: 862.5972, Eval Loss: 29.0733\n",
      "Epoch [11/25], Train Loss: 862.5890, Eval Loss: 29.0729\n",
      "Epoch [12/25], Train Loss: 862.5794, Eval Loss: 29.0724\n",
      "Epoch [13/25], Train Loss: 862.5685, Eval Loss: 29.0718\n",
      "Epoch [14/25], Train Loss: 862.5560, Eval Loss: 29.0711\n",
      "Epoch [15/25], Train Loss: 862.5416, Eval Loss: 29.0701\n",
      "Epoch [16/25], Train Loss: 862.5242, Eval Loss: 29.0689\n",
      "Epoch [17/25], Train Loss: 862.5025, Eval Loss: 29.0672\n",
      "Epoch [18/25], Train Loss: 862.4759, Eval Loss: 29.0648\n",
      "Epoch [19/25], Train Loss: 862.4453, Eval Loss: 29.0613\n",
      "Epoch [20/25], Train Loss: 862.4167, Eval Loss: 29.0560\n",
      "Epoch [21/25], Train Loss: 862.3947, Eval Loss: 29.0483\n",
      "Epoch [22/25], Train Loss: 862.3928, Eval Loss: 29.0376\n",
      "Epoch [23/25], Train Loss: 862.3670, Eval Loss: 29.0250\n",
      "Epoch [24/25], Train Loss: 862.3117, Eval Loss: 29.0224\n",
      "Epoch [25/25], Train Loss: 862.3800, Eval Loss: 29.0185\n",
      "Epoch [1/25], Train Loss: 21631.6840, Eval Loss: 29.4361\n",
      "Epoch [2/25], Train Loss: 1057.4090, Eval Loss: 31.5550\n",
      "Epoch [3/25], Train Loss: 965.5095, Eval Loss: 31.6183\n",
      "Epoch [4/25], Train Loss: 953.8770, Eval Loss: 31.1774\n",
      "Epoch [5/25], Train Loss: 949.0985, Eval Loss: 30.5542\n",
      "Epoch [6/25], Train Loss: 945.0566, Eval Loss: 30.0122\n",
      "Epoch [7/25], Train Loss: 925.0518, Eval Loss: 30.5095\n",
      "Epoch [8/25], Train Loss: 922.8456, Eval Loss: 29.3949\n",
      "Epoch [9/25], Train Loss: 907.4440, Eval Loss: 29.0197\n",
      "Epoch [10/25], Train Loss: 890.8572, Eval Loss: 29.0888\n",
      "Epoch [11/25], Train Loss: 871.8639, Eval Loss: 28.5311\n",
      "Epoch [12/25], Train Loss: 841.3937, Eval Loss: 27.9832\n",
      "Epoch [13/25], Train Loss: 802.8324, Eval Loss: 25.9400\n",
      "Epoch [14/25], Train Loss: 764.8667, Eval Loss: 25.4075\n",
      "Epoch [15/25], Train Loss: 792.1392, Eval Loss: 25.2919\n",
      "Epoch [16/25], Train Loss: 782.3383, Eval Loss: 24.9770\n",
      "Epoch [17/25], Train Loss: 721.2378, Eval Loss: 25.1138\n",
      "Epoch [18/25], Train Loss: 717.5205, Eval Loss: 25.3352\n",
      "Epoch [19/25], Train Loss: 701.6978, Eval Loss: 24.5151\n",
      "Epoch [20/25], Train Loss: 676.2978, Eval Loss: 23.9303\n",
      "Epoch [21/25], Train Loss: 666.1469, Eval Loss: 23.1688\n",
      "Epoch [22/25], Train Loss: 611.2128, Eval Loss: 22.4333\n",
      "Epoch [23/25], Train Loss: 569.8918, Eval Loss: 21.2243\n",
      "Epoch [24/25], Train Loss: 508.4331, Eval Loss: 19.9088\n",
      "Epoch [25/25], Train Loss: 444.5732, Eval Loss: 18.6896\n",
      "Epoch [1/25], Train Loss: 2526.0109, Eval Loss: 31.4252\n",
      "Epoch [2/25], Train Loss: 940.8950, Eval Loss: 28.9479\n",
      "Epoch [3/25], Train Loss: 970.2809, Eval Loss: 28.8651\n",
      "Epoch [4/25], Train Loss: 956.5425, Eval Loss: 29.9958\n",
      "Epoch [5/25], Train Loss: 963.6535, Eval Loss: 30.1022\n",
      "Epoch [6/25], Train Loss: 906.7149, Eval Loss: 27.9882\n",
      "Epoch [7/25], Train Loss: 847.8493, Eval Loss: 26.4888\n",
      "Epoch [8/25], Train Loss: 900.6696, Eval Loss: 25.8052\n",
      "Epoch [9/25], Train Loss: 740.0457, Eval Loss: 24.7363\n",
      "Epoch [10/25], Train Loss: 702.0427, Eval Loss: 24.2042\n",
      "Epoch [11/25], Train Loss: 684.1340, Eval Loss: 24.1661\n",
      "Epoch [12/25], Train Loss: 676.2207, Eval Loss: 23.9247\n",
      "Epoch [13/25], Train Loss: 667.1014, Eval Loss: 24.3724\n",
      "Epoch [14/25], Train Loss: 657.7652, Eval Loss: 23.9014\n",
      "Epoch [15/25], Train Loss: 653.2431, Eval Loss: 23.8983\n",
      "Epoch [16/25], Train Loss: 622.3189, Eval Loss: 23.5016\n",
      "Epoch [17/25], Train Loss: 676.1994, Eval Loss: 21.9077\n",
      "Epoch [18/25], Train Loss: 544.6654, Eval Loss: 18.6769\n",
      "Epoch [19/25], Train Loss: 374.0613, Eval Loss: 14.8306\n",
      "Epoch [20/25], Train Loss: 267.6094, Eval Loss: 13.9714\n",
      "Epoch [21/25], Train Loss: 286.1928, Eval Loss: 15.4066\n",
      "Epoch [22/25], Train Loss: 196.5185, Eval Loss: 12.5328\n",
      "Epoch [23/25], Train Loss: 174.6450, Eval Loss: 11.6587\n",
      "Epoch [24/25], Train Loss: 141.5510, Eval Loss: 10.2754\n",
      "Epoch [25/25], Train Loss: 118.2917, Eval Loss: 9.1441\n",
      "[Melhor modelo atualizado]\n",
      "hs:300, nl:2, dr:0, lr:0.01, a:relu, o:adam, wd:0.0005\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 2445.4110, Eval Loss: 28.9290\n",
      "Epoch [2/25], Train Loss: 857.6844, Eval Loss: 28.8850\n",
      "Epoch [3/25], Train Loss: 857.0814, Eval Loss: 28.8862\n",
      "Epoch [4/25], Train Loss: 857.4562, Eval Loss: 28.8866\n",
      "Epoch [5/25], Train Loss: 857.7482, Eval Loss: 28.8873\n",
      "Epoch [6/25], Train Loss: 858.0076, Eval Loss: 28.8884\n",
      "Epoch [7/25], Train Loss: 858.2446, Eval Loss: 28.8900\n",
      "Epoch [8/25], Train Loss: 858.4623, Eval Loss: 28.8918\n",
      "Epoch [9/25], Train Loss: 858.6629, Eval Loss: 28.8937\n",
      "Epoch [10/25], Train Loss: 858.8475, Eval Loss: 28.8956\n",
      "Epoch [11/25], Train Loss: 859.0172, Eval Loss: 28.8973\n",
      "Epoch [12/25], Train Loss: 859.1732, Eval Loss: 28.8990\n",
      "Epoch [13/25], Train Loss: 859.3167, Eval Loss: 28.9005\n",
      "Epoch [14/25], Train Loss: 859.4492, Eval Loss: 28.9019\n",
      "Epoch [15/25], Train Loss: 859.5719, Eval Loss: 28.9032\n",
      "Epoch [16/25], Train Loss: 859.6860, Eval Loss: 28.9044\n",
      "Epoch [17/25], Train Loss: 859.7923, Eval Loss: 28.9057\n",
      "Epoch [18/25], Train Loss: 859.8916, Eval Loss: 28.9069\n",
      "Epoch [19/25], Train Loss: 859.9844, Eval Loss: 28.9081\n",
      "Epoch [20/25], Train Loss: 860.0711, Eval Loss: 28.9094\n",
      "Epoch [21/25], Train Loss: 860.1521, Eval Loss: 28.9106\n",
      "Epoch [22/25], Train Loss: 860.2277, Eval Loss: 28.9118\n",
      "Epoch [23/25], Train Loss: 860.2982, Eval Loss: 28.9131\n",
      "Epoch [24/25], Train Loss: 860.3639, Eval Loss: 28.9143\n",
      "Epoch [25/25], Train Loss: 860.4249, Eval Loss: 28.9155\n",
      "Epoch [1/25], Train Loss: 2431.7992, Eval Loss: 28.9323\n",
      "Epoch [2/25], Train Loss: 857.7539, Eval Loss: 28.8852\n",
      "Epoch [3/25], Train Loss: 857.1058, Eval Loss: 28.8861\n",
      "Epoch [4/25], Train Loss: 857.4772, Eval Loss: 28.8865\n",
      "Epoch [5/25], Train Loss: 857.7673, Eval Loss: 28.8872\n",
      "Epoch [6/25], Train Loss: 858.0259, Eval Loss: 28.8884\n",
      "Epoch [7/25], Train Loss: 858.2622, Eval Loss: 28.8899\n",
      "Epoch [8/25], Train Loss: 858.4793, Eval Loss: 28.8917\n",
      "Epoch [9/25], Train Loss: 858.6790, Eval Loss: 28.8936\n",
      "Epoch [10/25], Train Loss: 858.8626, Eval Loss: 28.8955\n",
      "Epoch [11/25], Train Loss: 859.0311, Eval Loss: 28.8973\n",
      "Epoch [12/25], Train Loss: 859.1859, Eval Loss: 28.8989\n",
      "Epoch [13/25], Train Loss: 859.3283, Eval Loss: 28.9004\n",
      "Epoch [14/25], Train Loss: 859.4598, Eval Loss: 28.9017\n",
      "Epoch [15/25], Train Loss: 859.5818, Eval Loss: 28.9030\n",
      "Epoch [16/25], Train Loss: 859.6953, Eval Loss: 28.9043\n",
      "Epoch [17/25], Train Loss: 859.8011, Eval Loss: 28.9056\n",
      "Epoch [18/25], Train Loss: 859.9000, Eval Loss: 28.9068\n",
      "Epoch [19/25], Train Loss: 859.9924, Eval Loss: 28.9081\n",
      "Epoch [20/25], Train Loss: 860.0788, Eval Loss: 28.9093\n",
      "Epoch [21/25], Train Loss: 860.1595, Eval Loss: 28.9105\n",
      "Epoch [22/25], Train Loss: 860.2348, Eval Loss: 28.9118\n",
      "Epoch [23/25], Train Loss: 860.3049, Eval Loss: 28.9130\n",
      "Epoch [24/25], Train Loss: 860.3702, Eval Loss: 28.9143\n",
      "Epoch [25/25], Train Loss: 860.4310, Eval Loss: 28.9155\n",
      "Epoch [1/25], Train Loss: 1341.3370, Eval Loss: 32.2825\n",
      "Epoch [2/25], Train Loss: 1051.3752, Eval Loss: 32.2798\n",
      "Epoch [3/25], Train Loss: 1051.5263, Eval Loss: 32.2812\n",
      "Epoch [4/25], Train Loss: 1051.4881, Eval Loss: 32.2828\n",
      "Epoch [5/25], Train Loss: 1051.3047, Eval Loss: 32.2825\n",
      "Epoch [6/25], Train Loss: 1051.5665, Eval Loss: 32.2828\n",
      "Epoch [7/25], Train Loss: 1051.4509, Eval Loss: 32.2830\n",
      "Epoch [8/25], Train Loss: 1051.6649, Eval Loss: 32.2828\n",
      "Epoch [9/25], Train Loss: 1051.6646, Eval Loss: 32.2827\n",
      "Epoch [10/25], Train Loss: 1053.0429, Eval Loss: 32.2830\n",
      "Epoch [11/25], Train Loss: 1051.6740, Eval Loss: 32.2832\n",
      "Epoch [12/25], Train Loss: 1051.6632, Eval Loss: 32.2825\n",
      "Epoch [13/25], Train Loss: 1051.3151, Eval Loss: 32.2801\n",
      "Epoch [14/25], Train Loss: 1051.3909, Eval Loss: 32.2829\n",
      "Epoch [15/25], Train Loss: 1051.5894, Eval Loss: 32.2827\n",
      "Epoch [16/25], Train Loss: 1051.3293, Eval Loss: 32.2831\n",
      "Epoch [17/25], Train Loss: 1051.6692, Eval Loss: 32.2830\n",
      "Epoch [18/25], Train Loss: 1051.6579, Eval Loss: 32.2827\n",
      "Epoch [19/25], Train Loss: 1051.6037, Eval Loss: 32.2828\n",
      "Epoch [20/25], Train Loss: 1051.6539, Eval Loss: 32.2828\n",
      "Epoch [21/25], Train Loss: 1051.6181, Eval Loss: 32.2829\n",
      "Epoch [22/25], Train Loss: 1051.6303, Eval Loss: 32.2827\n",
      "Epoch [23/25], Train Loss: 1051.6683, Eval Loss: 32.2829\n",
      "Epoch [24/25], Train Loss: 1051.4552, Eval Loss: 32.2830\n",
      "Epoch [25/25], Train Loss: 1051.6512, Eval Loss: 32.2830\n",
      "Epoch [1/25], Train Loss: 1325.9575, Eval Loss: 32.2826\n",
      "Epoch [2/25], Train Loss: 1051.7144, Eval Loss: 32.2795\n",
      "Epoch [3/25], Train Loss: 1051.5254, Eval Loss: 32.2835\n",
      "Epoch [4/25], Train Loss: 1051.6564, Eval Loss: 32.2833\n",
      "Epoch [5/25], Train Loss: 1051.7316, Eval Loss: 32.2841\n",
      "Epoch [6/25], Train Loss: 1051.4756, Eval Loss: 32.2838\n",
      "Epoch [7/25], Train Loss: 1051.5954, Eval Loss: 32.2833\n",
      "Epoch [8/25], Train Loss: 1051.7079, Eval Loss: 32.2839\n",
      "Epoch [9/25], Train Loss: 1051.6901, Eval Loss: 32.2840\n",
      "Epoch [10/25], Train Loss: 1051.9652, Eval Loss: 32.2842\n",
      "Epoch [11/25], Train Loss: 1051.7365, Eval Loss: 32.2840\n",
      "Epoch [12/25], Train Loss: 1051.7256, Eval Loss: 32.2842\n",
      "Epoch [13/25], Train Loss: 1051.7445, Eval Loss: 32.2843\n",
      "Epoch [14/25], Train Loss: 1051.7730, Eval Loss: 32.2843\n",
      "Epoch [15/25], Train Loss: 1051.7498, Eval Loss: 32.2843\n",
      "Epoch [16/25], Train Loss: 1051.7009, Eval Loss: 32.2843\n",
      "Epoch [17/25], Train Loss: 1051.7429, Eval Loss: 32.2841\n",
      "Epoch [18/25], Train Loss: 1051.7248, Eval Loss: 32.2842\n",
      "Epoch [19/25], Train Loss: 1051.7333, Eval Loss: 32.2838\n",
      "Epoch [20/25], Train Loss: 1051.8010, Eval Loss: 32.2842\n",
      "Epoch [21/25], Train Loss: 1051.6508, Eval Loss: 32.2842\n",
      "Epoch [22/25], Train Loss: 1051.5761, Eval Loss: 32.2842\n",
      "Epoch [23/25], Train Loss: 1051.7427, Eval Loss: 32.2842\n",
      "Epoch [24/25], Train Loss: 1051.7345, Eval Loss: 32.2842\n",
      "Epoch [25/25], Train Loss: 1051.7543, Eval Loss: 32.2842\n",
      "Epoch [1/25], Train Loss: 5012.6939, Eval Loss: 31.3574\n",
      "Epoch [2/25], Train Loss: 879.1242, Eval Loss: 29.0274\n",
      "Epoch [3/25], Train Loss: 870.4268, Eval Loss: 29.0349\n",
      "Epoch [4/25], Train Loss: 872.6251, Eval Loss: 29.0858\n",
      "Epoch [5/25], Train Loss: 872.4523, Eval Loss: 29.1494\n",
      "Epoch [6/25], Train Loss: 868.6782, Eval Loss: 29.0852\n",
      "Epoch [7/25], Train Loss: 869.5206, Eval Loss: 29.0603\n",
      "Epoch [8/25], Train Loss: 874.2652, Eval Loss: 29.1155\n",
      "Epoch [9/25], Train Loss: 874.1548, Eval Loss: 29.4297\n",
      "Epoch [10/25], Train Loss: 873.4546, Eval Loss: 29.1278\n",
      "Epoch [11/25], Train Loss: 868.8207, Eval Loss: 29.2493\n",
      "Epoch [12/25], Train Loss: 862.5932, Eval Loss: 29.2674\n",
      "Epoch [13/25], Train Loss: 861.9647, Eval Loss: 29.1415\n",
      "Epoch [14/25], Train Loss: 875.2416, Eval Loss: 29.1352\n",
      "Epoch [15/25], Train Loss: 868.8984, Eval Loss: 29.1167\n",
      "Epoch [16/25], Train Loss: 869.9679, Eval Loss: 29.1522\n",
      "Epoch [17/25], Train Loss: 873.5615, Eval Loss: 29.2708\n",
      "Epoch [18/25], Train Loss: 872.9100, Eval Loss: 29.1383\n",
      "Epoch [19/25], Train Loss: 867.6166, Eval Loss: 29.0828\n",
      "Epoch [20/25], Train Loss: 875.2729, Eval Loss: 29.1290\n",
      "Epoch [21/25], Train Loss: 876.8000, Eval Loss: 29.2561\n",
      "Epoch [22/25], Train Loss: 863.5365, Eval Loss: 29.2124\n",
      "Epoch [23/25], Train Loss: 864.5321, Eval Loss: 29.1412\n",
      "Epoch [24/25], Train Loss: 876.4281, Eval Loss: 29.3030\n",
      "Epoch [25/25], Train Loss: 864.3916, Eval Loss: 29.0712\n",
      "Epoch [1/25], Train Loss: 4763.7468, Eval Loss: 30.3076\n",
      "Epoch [2/25], Train Loss: 875.5115, Eval Loss: 29.1033\n",
      "Epoch [3/25], Train Loss: 866.6648, Eval Loss: 29.1671\n",
      "Epoch [4/25], Train Loss: 864.5080, Eval Loss: 29.1436\n",
      "Epoch [5/25], Train Loss: 865.4613, Eval Loss: 29.0384\n",
      "Epoch [6/25], Train Loss: 873.2611, Eval Loss: 29.1374\n",
      "Epoch [7/25], Train Loss: 874.4307, Eval Loss: 29.3782\n",
      "Epoch [8/25], Train Loss: 876.1723, Eval Loss: 29.1649\n",
      "Epoch [9/25], Train Loss: 871.0548, Eval Loss: 29.1237\n",
      "Epoch [10/25], Train Loss: 868.7820, Eval Loss: 29.2390\n",
      "Epoch [11/25], Train Loss: 872.6737, Eval Loss: 29.3187\n",
      "Epoch [12/25], Train Loss: 873.8737, Eval Loss: 29.2825\n",
      "Epoch [13/25], Train Loss: 866.5332, Eval Loss: 29.4372\n",
      "Epoch [14/25], Train Loss: 879.5028, Eval Loss: 29.2680\n",
      "Epoch [15/25], Train Loss: 866.3553, Eval Loss: 29.1881\n",
      "Epoch [16/25], Train Loss: 866.8613, Eval Loss: 29.4455\n",
      "Epoch [17/25], Train Loss: 861.0946, Eval Loss: 29.2101\n",
      "Epoch [18/25], Train Loss: 866.4463, Eval Loss: 29.3823\n",
      "Epoch [19/25], Train Loss: 875.9937, Eval Loss: 29.3936\n",
      "Epoch [20/25], Train Loss: 870.3036, Eval Loss: 29.4245\n",
      "Epoch [21/25], Train Loss: 864.4539, Eval Loss: 29.2668\n",
      "Epoch [22/25], Train Loss: 873.2422, Eval Loss: 29.3844\n",
      "Epoch [23/25], Train Loss: 863.9279, Eval Loss: 29.2564\n",
      "Epoch [24/25], Train Loss: 866.5066, Eval Loss: 29.4029\n",
      "Epoch [25/25], Train Loss: 867.8414, Eval Loss: 29.2831\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8751.2451, Eval Loss: 89.6082\n",
      "Epoch [2/25], Train Loss: 8081.1400, Eval Loss: 87.1297\n",
      "Epoch [3/25], Train Loss: 7682.4671, Eval Loss: 85.0364\n",
      "Epoch [4/25], Train Loss: 7333.5418, Eval Loss: 83.0801\n",
      "Epoch [5/25], Train Loss: 7010.5469, Eval Loss: 81.2069\n",
      "Epoch [6/25], Train Loss: 6706.5472, Eval Loss: 79.3963\n",
      "Epoch [7/25], Train Loss: 6418.4729, Eval Loss: 77.6386\n",
      "Epoch [8/25], Train Loss: 6144.5011, Eval Loss: 75.9279\n",
      "Epoch [9/25], Train Loss: 5883.4044, Eval Loss: 74.2608\n",
      "Epoch [10/25], Train Loss: 5634.2916, Eval Loss: 72.6348\n",
      "Epoch [11/25], Train Loss: 5396.4158, Eval Loss: 71.0483\n",
      "Epoch [12/25], Train Loss: 5169.1823, Eval Loss: 69.4998\n",
      "Epoch [13/25], Train Loss: 4952.0745, Eval Loss: 67.9884\n",
      "Epoch [14/25], Train Loss: 4744.6052, Eval Loss: 66.5133\n",
      "Epoch [15/25], Train Loss: 4546.3597, Eval Loss: 65.0739\n",
      "Epoch [16/25], Train Loss: 4356.9229, Eval Loss: 63.6696\n",
      "Epoch [17/25], Train Loss: 4175.9364, Eval Loss: 62.2998\n",
      "Epoch [18/25], Train Loss: 4003.0449, Eval Loss: 60.9642\n",
      "Epoch [19/25], Train Loss: 3837.9200, Eval Loss: 59.6623\n",
      "Epoch [20/25], Train Loss: 3680.2453, Eval Loss: 58.3938\n",
      "Epoch [21/25], Train Loss: 3529.7201, Eval Loss: 57.1585\n",
      "Epoch [22/25], Train Loss: 3386.0534, Eval Loss: 55.9558\n",
      "Epoch [23/25], Train Loss: 3248.9680, Eval Loss: 54.7856\n",
      "Epoch [24/25], Train Loss: 3118.1962, Eval Loss: 53.6476\n",
      "Epoch [25/25], Train Loss: 2993.4875, Eval Loss: 52.5415\n",
      "Epoch [1/25], Train Loss: 8792.2731, Eval Loss: 89.8387\n",
      "Epoch [2/25], Train Loss: 8122.1117, Eval Loss: 87.3619\n",
      "Epoch [3/25], Train Loss: 7721.2039, Eval Loss: 85.2600\n",
      "Epoch [4/25], Train Loss: 7370.1029, Eval Loss: 83.2966\n",
      "Epoch [5/25], Train Loss: 7045.1090, Eval Loss: 81.4165\n",
      "Epoch [6/25], Train Loss: 6739.2722, Eval Loss: 79.5993\n",
      "Epoch [7/25], Train Loss: 6449.4140, Eval Loss: 77.8349\n",
      "Epoch [8/25], Train Loss: 6173.7367, Eval Loss: 76.1174\n",
      "Epoch [9/25], Train Loss: 5910.9639, Eval Loss: 74.4435\n",
      "Epoch [10/25], Train Loss: 5660.2146, Eval Loss: 72.8106\n",
      "Epoch [11/25], Train Loss: 5420.7825, Eval Loss: 71.2171\n",
      "Epoch [12/25], Train Loss: 5192.0386, Eval Loss: 69.6616\n",
      "Epoch [13/25], Train Loss: 4973.4697, Eval Loss: 68.1433\n",
      "Epoch [14/25], Train Loss: 4764.5885, Eval Loss: 66.6612\n",
      "Epoch [15/25], Train Loss: 4564.9858, Eval Loss: 65.2147\n",
      "Epoch [16/25], Train Loss: 4374.2527, Eval Loss: 63.8035\n",
      "Epoch [17/25], Train Loss: 4192.0282, Eval Loss: 62.4268\n",
      "Epoch [18/25], Train Loss: 4017.9557, Eval Loss: 61.0845\n",
      "Epoch [19/25], Train Loss: 3851.7176, Eval Loss: 59.7760\n",
      "Epoch [20/25], Train Loss: 3692.9862, Eval Loss: 58.5011\n",
      "Epoch [21/25], Train Loss: 3541.4660, Eval Loss: 57.2595\n",
      "Epoch [22/25], Train Loss: 3396.8672, Eval Loss: 56.0508\n",
      "Epoch [23/25], Train Loss: 3258.9117, Eval Loss: 54.8748\n",
      "Epoch [24/25], Train Loss: 3127.3342, Eval Loss: 53.7313\n",
      "Epoch [25/25], Train Loss: 3001.8793, Eval Loss: 52.6199\n",
      "Epoch [1/25], Train Loss: 5745.9827, Eval Loss: 47.6190\n",
      "Epoch [2/25], Train Loss: 1502.8355, Eval Loss: 31.3790\n",
      "Epoch [3/25], Train Loss: 929.2440, Eval Loss: 29.1278\n",
      "Epoch [4/25], Train Loss: 862.5913, Eval Loss: 28.9032\n",
      "Epoch [5/25], Train Loss: 854.9003, Eval Loss: 28.8930\n",
      "Epoch [6/25], Train Loss: 853.9449, Eval Loss: 28.8972\n",
      "Epoch [7/25], Train Loss: 853.8845, Eval Loss: 28.8995\n",
      "Epoch [8/25], Train Loss: 853.8658, Eval Loss: 28.9004\n",
      "Epoch [9/25], Train Loss: 853.8586, Eval Loss: 28.9008\n",
      "Epoch [10/25], Train Loss: 853.8420, Eval Loss: 28.9008\n",
      "Epoch [11/25], Train Loss: 853.8314, Eval Loss: 28.9009\n",
      "Epoch [12/25], Train Loss: 853.8292, Eval Loss: 28.9009\n",
      "Epoch [13/25], Train Loss: 853.7960, Eval Loss: 28.9009\n",
      "Epoch [14/25], Train Loss: 853.8962, Eval Loss: 28.9008\n",
      "Epoch [15/25], Train Loss: 853.8475, Eval Loss: 28.9009\n",
      "Epoch [16/25], Train Loss: 853.9087, Eval Loss: 28.9009\n",
      "Epoch [17/25], Train Loss: 853.8125, Eval Loss: 28.9009\n",
      "Epoch [18/25], Train Loss: 853.8457, Eval Loss: 28.9009\n",
      "Epoch [19/25], Train Loss: 853.8473, Eval Loss: 28.9009\n",
      "Epoch [20/25], Train Loss: 853.8687, Eval Loss: 28.9009\n",
      "Epoch [21/25], Train Loss: 853.8362, Eval Loss: 28.9009\n",
      "Epoch [22/25], Train Loss: 853.8524, Eval Loss: 28.9008\n",
      "Epoch [23/25], Train Loss: 853.8223, Eval Loss: 28.9008\n",
      "Epoch [24/25], Train Loss: 853.7558, Eval Loss: 28.9008\n",
      "Epoch [25/25], Train Loss: 853.8521, Eval Loss: 28.9008\n",
      "Epoch [1/25], Train Loss: 5864.7881, Eval Loss: 48.3240\n",
      "Epoch [2/25], Train Loss: 1532.3353, Eval Loss: 31.4955\n",
      "Epoch [3/25], Train Loss: 932.7442, Eval Loss: 29.1407\n",
      "Epoch [4/25], Train Loss: 862.9924, Eval Loss: 28.9041\n",
      "Epoch [5/25], Train Loss: 855.0115, Eval Loss: 28.8928\n",
      "Epoch [6/25], Train Loss: 853.9577, Eval Loss: 28.8971\n",
      "Epoch [7/25], Train Loss: 853.8995, Eval Loss: 28.8994\n",
      "Epoch [8/25], Train Loss: 853.7905, Eval Loss: 28.9004\n",
      "Epoch [9/25], Train Loss: 853.7471, Eval Loss: 28.9007\n",
      "Epoch [10/25], Train Loss: 853.8756, Eval Loss: 28.9008\n",
      "Epoch [11/25], Train Loss: 853.8413, Eval Loss: 28.9008\n",
      "Epoch [12/25], Train Loss: 853.8342, Eval Loss: 28.9009\n",
      "Epoch [13/25], Train Loss: 853.7765, Eval Loss: 28.9009\n",
      "Epoch [14/25], Train Loss: 853.8991, Eval Loss: 28.9008\n",
      "Epoch [15/25], Train Loss: 853.8708, Eval Loss: 28.9009\n",
      "Epoch [16/25], Train Loss: 853.8171, Eval Loss: 28.9009\n",
      "Epoch [17/25], Train Loss: 853.8703, Eval Loss: 28.9009\n",
      "Epoch [18/25], Train Loss: 853.8630, Eval Loss: 28.9008\n",
      "Epoch [19/25], Train Loss: 853.8471, Eval Loss: 28.9008\n",
      "Epoch [20/25], Train Loss: 853.8285, Eval Loss: 28.9008\n",
      "Epoch [21/25], Train Loss: 853.8636, Eval Loss: 28.9008\n",
      "Epoch [22/25], Train Loss: 853.7819, Eval Loss: 28.9008\n",
      "Epoch [23/25], Train Loss: 853.8357, Eval Loss: 28.9008\n",
      "Epoch [24/25], Train Loss: 853.8470, Eval Loss: 28.9008\n",
      "Epoch [25/25], Train Loss: 853.7831, Eval Loss: 28.9008\n",
      "Epoch [1/25], Train Loss: 1653.7850, Eval Loss: 29.3245\n",
      "Epoch [2/25], Train Loss: 952.4290, Eval Loss: 29.2728\n",
      "Epoch [3/25], Train Loss: 999.8608, Eval Loss: 29.2133\n",
      "Epoch [4/25], Train Loss: 936.2107, Eval Loss: 28.9472\n",
      "Epoch [5/25], Train Loss: 925.6084, Eval Loss: 28.9826\n",
      "Epoch [6/25], Train Loss: 920.9027, Eval Loss: 29.0541\n",
      "Epoch [7/25], Train Loss: 945.9949, Eval Loss: 28.8954\n",
      "Epoch [8/25], Train Loss: 943.5099, Eval Loss: 28.8668\n",
      "Epoch [9/25], Train Loss: 923.3105, Eval Loss: 28.9102\n",
      "Epoch [10/25], Train Loss: 936.3580, Eval Loss: 28.8040\n",
      "Epoch [11/25], Train Loss: 924.5320, Eval Loss: 28.8032\n",
      "Epoch [12/25], Train Loss: 937.9070, Eval Loss: 28.7687\n",
      "Epoch [13/25], Train Loss: 912.8083, Eval Loss: 28.6816\n",
      "Epoch [14/25], Train Loss: 928.4834, Eval Loss: 28.7434\n",
      "Epoch [15/25], Train Loss: 916.1851, Eval Loss: 28.9530\n",
      "Epoch [16/25], Train Loss: 909.5572, Eval Loss: 28.5553\n",
      "Epoch [17/25], Train Loss: 876.2995, Eval Loss: 28.5288\n",
      "Epoch [18/25], Train Loss: 884.8991, Eval Loss: 28.4608\n",
      "Epoch [19/25], Train Loss: 879.8235, Eval Loss: 28.3380\n",
      "Epoch [20/25], Train Loss: 892.5902, Eval Loss: 28.2536\n",
      "Epoch [21/25], Train Loss: 882.1607, Eval Loss: 28.1642\n",
      "Epoch [22/25], Train Loss: 883.7567, Eval Loss: 28.0242\n",
      "Epoch [23/25], Train Loss: 861.5735, Eval Loss: 27.8697\n",
      "Epoch [24/25], Train Loss: 869.1854, Eval Loss: 27.6712\n",
      "Epoch [25/25], Train Loss: 841.8039, Eval Loss: 27.4233\n",
      "Epoch [1/25], Train Loss: 1544.1828, Eval Loss: 29.8721\n",
      "Epoch [2/25], Train Loss: 945.6768, Eval Loss: 29.7308\n",
      "Epoch [3/25], Train Loss: 967.3562, Eval Loss: 29.4537\n",
      "Epoch [4/25], Train Loss: 952.9352, Eval Loss: 30.1871\n",
      "Epoch [5/25], Train Loss: 943.7012, Eval Loss: 29.4635\n",
      "Epoch [6/25], Train Loss: 950.0753, Eval Loss: 29.7766\n",
      "Epoch [7/25], Train Loss: 981.0239, Eval Loss: 28.9131\n",
      "Epoch [8/25], Train Loss: 933.9263, Eval Loss: 29.1008\n",
      "Epoch [9/25], Train Loss: 916.6294, Eval Loss: 28.8536\n",
      "Epoch [10/25], Train Loss: 938.0627, Eval Loss: 28.8626\n",
      "Epoch [11/25], Train Loss: 915.3624, Eval Loss: 28.8423\n",
      "Epoch [12/25], Train Loss: 905.5203, Eval Loss: 28.9629\n",
      "Epoch [13/25], Train Loss: 896.8615, Eval Loss: 28.6390\n",
      "Epoch [14/25], Train Loss: 915.2339, Eval Loss: 28.5592\n",
      "Epoch [15/25], Train Loss: 911.7339, Eval Loss: 28.5962\n",
      "Epoch [16/25], Train Loss: 895.9609, Eval Loss: 28.4299\n",
      "Epoch [17/25], Train Loss: 900.0207, Eval Loss: 28.3033\n",
      "Epoch [18/25], Train Loss: 885.6367, Eval Loss: 28.2527\n",
      "Epoch [19/25], Train Loss: 880.2294, Eval Loss: 28.2059\n",
      "Epoch [20/25], Train Loss: 861.2916, Eval Loss: 27.9819\n",
      "Epoch [21/25], Train Loss: 866.4538, Eval Loss: 27.7923\n",
      "Epoch [22/25], Train Loss: 848.9160, Eval Loss: 27.3970\n",
      "Epoch [23/25], Train Loss: 828.4138, Eval Loss: 27.0441\n",
      "Epoch [24/25], Train Loss: 830.6629, Eval Loss: 26.7551\n",
      "Epoch [25/25], Train Loss: 791.4451, Eval Loss: 26.7768\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 7182.1528, Eval Loss: 73.4858\n",
      "Epoch [2/25], Train Loss: 4586.1892, Eval Loss: 58.8517\n",
      "Epoch [3/25], Train Loss: 3025.2589, Eval Loss: 48.0834\n",
      "Epoch [4/25], Train Loss: 2090.8268, Eval Loss: 40.5469\n",
      "Epoch [5/25], Train Loss: 1541.6649, Eval Loss: 35.6014\n",
      "Epoch [6/25], Train Loss: 1226.0756, Eval Loss: 32.5584\n",
      "Epoch [7/25], Train Loss: 1048.9866, Eval Loss: 30.7892\n",
      "Epoch [8/25], Train Loss: 952.2082, Eval Loss: 29.8150\n",
      "Epoch [9/25], Train Loss: 901.0548, Eval Loss: 29.3101\n",
      "Epoch [10/25], Train Loss: 875.1497, Eval Loss: 29.0663\n",
      "Epoch [11/25], Train Loss: 862.6931, Eval Loss: 28.9583\n",
      "Epoch [12/25], Train Loss: 857.0494, Eval Loss: 28.9156\n",
      "Epoch [13/25], Train Loss: 854.6596, Eval Loss: 28.9016\n",
      "Epoch [14/25], Train Loss: 853.7264, Eval Loss: 28.8988\n",
      "Epoch [15/25], Train Loss: 853.4017, Eval Loss: 28.8995\n",
      "Epoch [16/25], Train Loss: 853.3117, Eval Loss: 28.9009\n",
      "Epoch [17/25], Train Loss: 853.3050, Eval Loss: 28.9021\n",
      "Epoch [18/25], Train Loss: 853.3246, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 853.3509, Eval Loss: 28.9035\n",
      "Epoch [20/25], Train Loss: 853.3775, Eval Loss: 28.9039\n",
      "Epoch [21/25], Train Loss: 853.4036, Eval Loss: 28.9042\n",
      "Epoch [22/25], Train Loss: 853.4290, Eval Loss: 28.9044\n",
      "Epoch [23/25], Train Loss: 853.4533, Eval Loss: 28.9045\n",
      "Epoch [24/25], Train Loss: 853.4773, Eval Loss: 28.9047\n",
      "Epoch [25/25], Train Loss: 853.5004, Eval Loss: 28.9048\n",
      "Epoch [1/25], Train Loss: 7137.1026, Eval Loss: 73.2334\n",
      "Epoch [2/25], Train Loss: 4555.5670, Eval Loss: 58.6684\n",
      "Epoch [3/25], Train Loss: 3007.6320, Eval Loss: 47.9688\n",
      "Epoch [4/25], Train Loss: 2081.3575, Eval Loss: 40.4846\n",
      "Epoch [5/25], Train Loss: 1536.8880, Eval Loss: 35.5733\n",
      "Epoch [6/25], Train Loss: 1223.8723, Eval Loss: 32.5487\n",
      "Epoch [7/25], Train Loss: 1048.0662, Eval Loss: 30.7872\n",
      "Epoch [8/25], Train Loss: 951.8534, Eval Loss: 29.8154\n",
      "Epoch [9/25], Train Loss: 900.9245, Eval Loss: 29.3108\n",
      "Epoch [10/25], Train Loss: 875.1032, Eval Loss: 29.0668\n",
      "Epoch [11/25], Train Loss: 862.6777, Eval Loss: 28.9586\n",
      "Epoch [12/25], Train Loss: 857.0458, Eval Loss: 28.9158\n",
      "Epoch [13/25], Train Loss: 854.6612, Eval Loss: 28.9018\n",
      "Epoch [14/25], Train Loss: 853.7303, Eval Loss: 28.8989\n",
      "Epoch [15/25], Train Loss: 853.4060, Eval Loss: 28.8996\n",
      "Epoch [16/25], Train Loss: 853.3167, Eval Loss: 28.9010\n",
      "Epoch [17/25], Train Loss: 853.3106, Eval Loss: 28.9022\n",
      "Epoch [18/25], Train Loss: 853.3301, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 853.3561, Eval Loss: 28.9036\n",
      "Epoch [20/25], Train Loss: 853.3835, Eval Loss: 28.9039\n",
      "Epoch [21/25], Train Loss: 853.4091, Eval Loss: 28.9042\n",
      "Epoch [22/25], Train Loss: 853.4342, Eval Loss: 28.9044\n",
      "Epoch [23/25], Train Loss: 853.4587, Eval Loss: 28.9046\n",
      "Epoch [24/25], Train Loss: 853.4827, Eval Loss: 28.9047\n",
      "Epoch [25/25], Train Loss: 853.5056, Eval Loss: 28.9048\n",
      "Epoch [1/25], Train Loss: 1564.6632, Eval Loss: 29.0739\n",
      "Epoch [2/25], Train Loss: 862.5791, Eval Loss: 29.0739\n",
      "Epoch [3/25], Train Loss: 862.6887, Eval Loss: 29.0738\n",
      "Epoch [4/25], Train Loss: 862.6258, Eval Loss: 29.0740\n",
      "Epoch [5/25], Train Loss: 862.5306, Eval Loss: 29.0733\n",
      "Epoch [6/25], Train Loss: 862.6866, Eval Loss: 29.0737\n",
      "Epoch [7/25], Train Loss: 862.6390, Eval Loss: 29.0727\n",
      "Epoch [8/25], Train Loss: 862.5239, Eval Loss: 29.0730\n",
      "Epoch [9/25], Train Loss: 862.5145, Eval Loss: 29.0721\n",
      "Epoch [10/25], Train Loss: 862.7017, Eval Loss: 29.0722\n",
      "Epoch [11/25], Train Loss: 862.6372, Eval Loss: 29.0719\n",
      "Epoch [12/25], Train Loss: 862.7163, Eval Loss: 29.0720\n",
      "Epoch [13/25], Train Loss: 862.7431, Eval Loss: 29.0721\n",
      "Epoch [14/25], Train Loss: 862.5637, Eval Loss: 29.0713\n",
      "Epoch [15/25], Train Loss: 862.5974, Eval Loss: 29.0711\n",
      "Epoch [16/25], Train Loss: 862.6294, Eval Loss: 29.0711\n",
      "Epoch [17/25], Train Loss: 862.6461, Eval Loss: 29.0709\n",
      "Epoch [18/25], Train Loss: 862.5418, Eval Loss: 29.0685\n",
      "Epoch [19/25], Train Loss: 862.5728, Eval Loss: 29.0692\n",
      "Epoch [20/25], Train Loss: 862.6474, Eval Loss: 29.0698\n",
      "Epoch [21/25], Train Loss: 862.6068, Eval Loss: 29.0686\n",
      "Epoch [22/25], Train Loss: 862.5742, Eval Loss: 29.0664\n",
      "Epoch [23/25], Train Loss: 862.6055, Eval Loss: 29.0667\n",
      "Epoch [24/25], Train Loss: 862.5004, Eval Loss: 29.0622\n",
      "Epoch [25/25], Train Loss: 862.6701, Eval Loss: 29.0667\n",
      "Epoch [1/25], Train Loss: 1551.0776, Eval Loss: 29.0740\n",
      "Epoch [2/25], Train Loss: 862.6256, Eval Loss: 29.0739\n",
      "Epoch [3/25], Train Loss: 862.6282, Eval Loss: 29.0736\n",
      "Epoch [4/25], Train Loss: 862.7055, Eval Loss: 29.0735\n",
      "Epoch [5/25], Train Loss: 862.5861, Eval Loss: 29.0734\n",
      "Epoch [6/25], Train Loss: 862.6780, Eval Loss: 29.0733\n",
      "Epoch [7/25], Train Loss: 862.6079, Eval Loss: 29.0728\n",
      "Epoch [8/25], Train Loss: 862.5621, Eval Loss: 29.0727\n",
      "Epoch [9/25], Train Loss: 862.6120, Eval Loss: 29.0719\n",
      "Epoch [10/25], Train Loss: 862.6166, Eval Loss: 29.0713\n",
      "Epoch [11/25], Train Loss: 862.6539, Eval Loss: 29.0717\n",
      "Epoch [12/25], Train Loss: 862.5789, Eval Loss: 29.0707\n",
      "Epoch [13/25], Train Loss: 862.5798, Eval Loss: 29.0693\n",
      "Epoch [14/25], Train Loss: 862.7523, Eval Loss: 29.0695\n",
      "Epoch [15/25], Train Loss: 862.4954, Eval Loss: 29.0689\n",
      "Epoch [16/25], Train Loss: 862.5118, Eval Loss: 29.0681\n",
      "Epoch [17/25], Train Loss: 862.3508, Eval Loss: 29.0665\n",
      "Epoch [18/25], Train Loss: 862.4837, Eval Loss: 29.0652\n",
      "Epoch [19/25], Train Loss: 862.4171, Eval Loss: 29.0648\n",
      "Epoch [20/25], Train Loss: 862.5266, Eval Loss: 29.0615\n",
      "Epoch [21/25], Train Loss: 862.3471, Eval Loss: 29.0559\n",
      "Epoch [22/25], Train Loss: 862.2901, Eval Loss: 29.0526\n",
      "Epoch [23/25], Train Loss: 862.5677, Eval Loss: 29.0527\n",
      "Epoch [24/25], Train Loss: 862.4278, Eval Loss: 29.0365\n",
      "Epoch [25/25], Train Loss: 862.3018, Eval Loss: 29.0274\n",
      "Epoch [1/25], Train Loss: 50338.8171, Eval Loss: 29.3829\n",
      "Epoch [2/25], Train Loss: 977.7561, Eval Loss: 28.8224\n",
      "Epoch [3/25], Train Loss: 1017.9775, Eval Loss: 28.7987\n",
      "Epoch [4/25], Train Loss: 975.0579, Eval Loss: 28.1897\n",
      "Epoch [5/25], Train Loss: 961.6322, Eval Loss: 27.9005\n",
      "Epoch [6/25], Train Loss: 882.2891, Eval Loss: 26.4192\n",
      "Epoch [7/25], Train Loss: 801.5469, Eval Loss: 25.4908\n",
      "Epoch [8/25], Train Loss: 805.9164, Eval Loss: 27.1532\n",
      "Epoch [9/25], Train Loss: 808.8427, Eval Loss: 25.1829\n",
      "Epoch [10/25], Train Loss: 754.4068, Eval Loss: 25.0570\n",
      "Epoch [11/25], Train Loss: 733.0184, Eval Loss: 25.0302\n",
      "Epoch [12/25], Train Loss: 726.0341, Eval Loss: 32.9166\n",
      "Epoch [13/25], Train Loss: 735.4062, Eval Loss: 23.5343\n",
      "Epoch [14/25], Train Loss: 622.7055, Eval Loss: 21.9985\n",
      "Epoch [15/25], Train Loss: 571.8185, Eval Loss: 20.9819\n",
      "Epoch [16/25], Train Loss: 514.4561, Eval Loss: 20.7849\n",
      "Epoch [17/25], Train Loss: 465.6657, Eval Loss: 18.1979\n",
      "Epoch [18/25], Train Loss: 1063.9246, Eval Loss: 24.7485\n",
      "Epoch [19/25], Train Loss: 731.2032, Eval Loss: 20.1539\n",
      "Epoch [20/25], Train Loss: 781.2173, Eval Loss: 24.3119\n",
      "Epoch [21/25], Train Loss: 992.5375, Eval Loss: 28.5480\n",
      "Epoch [22/25], Train Loss: 818.0467, Eval Loss: 23.9973\n",
      "Epoch [23/25], Train Loss: 698.8593, Eval Loss: 20.6955\n",
      "Epoch [24/25], Train Loss: 583.2929, Eval Loss: 22.5299\n",
      "Epoch [25/25], Train Loss: 459.5001, Eval Loss: 20.6359\n",
      "Epoch [1/25], Train Loss: 35517.5744, Eval Loss: 29.1619\n",
      "Epoch [2/25], Train Loss: 1032.2591, Eval Loss: 29.9139\n",
      "Epoch [3/25], Train Loss: 1003.7336, Eval Loss: 30.7239\n",
      "Epoch [4/25], Train Loss: 994.7942, Eval Loss: 28.9283\n",
      "Epoch [5/25], Train Loss: 1047.5787, Eval Loss: 28.5914\n",
      "Epoch [6/25], Train Loss: 1013.9557, Eval Loss: 28.5098\n",
      "Epoch [7/25], Train Loss: 967.8429, Eval Loss: 28.4546\n",
      "Epoch [8/25], Train Loss: 949.0873, Eval Loss: 28.4843\n",
      "Epoch [9/25], Train Loss: 932.0998, Eval Loss: 29.6196\n",
      "Epoch [10/25], Train Loss: 968.1570, Eval Loss: 27.4912\n",
      "Epoch [11/25], Train Loss: 890.3154, Eval Loss: 28.0091\n",
      "Epoch [12/25], Train Loss: 840.0141, Eval Loss: 26.5326\n",
      "Epoch [13/25], Train Loss: 862.2770, Eval Loss: 25.5349\n",
      "Epoch [14/25], Train Loss: 768.1069, Eval Loss: 24.9602\n",
      "Epoch [15/25], Train Loss: 718.2877, Eval Loss: 24.7927\n",
      "Epoch [16/25], Train Loss: 749.3861, Eval Loss: 25.0393\n",
      "Epoch [17/25], Train Loss: 745.8791, Eval Loss: 23.6303\n",
      "Epoch [18/25], Train Loss: 670.2016, Eval Loss: 22.0585\n",
      "Epoch [19/25], Train Loss: 539.4408, Eval Loss: 18.2835\n",
      "Epoch [20/25], Train Loss: 478.9704, Eval Loss: 20.7672\n",
      "Epoch [21/25], Train Loss: 482.0832, Eval Loss: 16.6657\n",
      "Epoch [22/25], Train Loss: 603.1858, Eval Loss: 16.4820\n",
      "Epoch [23/25], Train Loss: 831.2990, Eval Loss: 18.3458\n",
      "Epoch [24/25], Train Loss: 387.7432, Eval Loss: 14.7422\n",
      "Epoch [25/25], Train Loss: 338.9826, Eval Loss: 13.8038\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 2419.3332, Eval Loss: 28.9278\n",
      "Epoch [2/25], Train Loss: 857.7234, Eval Loss: 28.8851\n",
      "Epoch [3/25], Train Loss: 857.1037, Eval Loss: 28.8864\n",
      "Epoch [4/25], Train Loss: 857.4801, Eval Loss: 28.8868\n",
      "Epoch [5/25], Train Loss: 857.7742, Eval Loss: 28.8875\n",
      "Epoch [6/25], Train Loss: 858.0351, Eval Loss: 28.8887\n",
      "Epoch [7/25], Train Loss: 858.2726, Eval Loss: 28.8903\n",
      "Epoch [8/25], Train Loss: 858.4901, Eval Loss: 28.8921\n",
      "Epoch [9/25], Train Loss: 858.6899, Eval Loss: 28.8940\n",
      "Epoch [10/25], Train Loss: 858.8732, Eval Loss: 28.8958\n",
      "Epoch [11/25], Train Loss: 859.0414, Eval Loss: 28.8976\n",
      "Epoch [12/25], Train Loss: 859.1958, Eval Loss: 28.8992\n",
      "Epoch [13/25], Train Loss: 859.3377, Eval Loss: 28.9007\n",
      "Epoch [14/25], Train Loss: 859.4687, Eval Loss: 28.9021\n",
      "Epoch [15/25], Train Loss: 859.5901, Eval Loss: 28.9034\n",
      "Epoch [16/25], Train Loss: 859.7030, Eval Loss: 28.9046\n",
      "Epoch [17/25], Train Loss: 859.8082, Eval Loss: 28.9059\n",
      "Epoch [18/25], Train Loss: 859.9065, Eval Loss: 28.9071\n",
      "Epoch [19/25], Train Loss: 859.9984, Eval Loss: 28.9083\n",
      "Epoch [20/25], Train Loss: 860.0842, Eval Loss: 28.9095\n",
      "Epoch [21/25], Train Loss: 860.1644, Eval Loss: 28.9108\n",
      "Epoch [22/25], Train Loss: 860.2393, Eval Loss: 28.9120\n",
      "Epoch [23/25], Train Loss: 860.3090, Eval Loss: 28.9132\n",
      "Epoch [24/25], Train Loss: 860.3740, Eval Loss: 28.9145\n",
      "Epoch [25/25], Train Loss: 860.4344, Eval Loss: 28.9157\n",
      "Epoch [1/25], Train Loss: 2440.4035, Eval Loss: 28.9296\n",
      "Epoch [2/25], Train Loss: 857.7436, Eval Loss: 28.8853\n",
      "Epoch [3/25], Train Loss: 857.1102, Eval Loss: 28.8863\n",
      "Epoch [4/25], Train Loss: 857.4820, Eval Loss: 28.8866\n",
      "Epoch [5/25], Train Loss: 857.7715, Eval Loss: 28.8872\n",
      "Epoch [6/25], Train Loss: 858.0284, Eval Loss: 28.8883\n",
      "Epoch [7/25], Train Loss: 858.2629, Eval Loss: 28.8899\n",
      "Epoch [8/25], Train Loss: 858.4787, Eval Loss: 28.8916\n",
      "Epoch [9/25], Train Loss: 858.6776, Eval Loss: 28.8935\n",
      "Epoch [10/25], Train Loss: 858.8609, Eval Loss: 28.8954\n",
      "Epoch [11/25], Train Loss: 859.0297, Eval Loss: 28.8972\n",
      "Epoch [12/25], Train Loss: 859.1846, Eval Loss: 28.8989\n",
      "Epoch [13/25], Train Loss: 859.3275, Eval Loss: 28.9004\n",
      "Epoch [14/25], Train Loss: 859.4592, Eval Loss: 28.9018\n",
      "Epoch [15/25], Train Loss: 859.5814, Eval Loss: 28.9031\n",
      "Epoch [16/25], Train Loss: 859.6945, Eval Loss: 28.9044\n",
      "Epoch [17/25], Train Loss: 859.8007, Eval Loss: 28.9056\n",
      "Epoch [18/25], Train Loss: 859.8989, Eval Loss: 28.9068\n",
      "Epoch [19/25], Train Loss: 859.9911, Eval Loss: 28.9081\n",
      "Epoch [20/25], Train Loss: 860.0773, Eval Loss: 28.9093\n",
      "Epoch [21/25], Train Loss: 860.1577, Eval Loss: 28.9105\n",
      "Epoch [22/25], Train Loss: 860.2328, Eval Loss: 28.9118\n",
      "Epoch [23/25], Train Loss: 860.3029, Eval Loss: 28.9130\n",
      "Epoch [24/25], Train Loss: 860.3681, Eval Loss: 28.9142\n",
      "Epoch [25/25], Train Loss: 860.4288, Eval Loss: 28.9155\n",
      "Epoch [1/25], Train Loss: 1369.7731, Eval Loss: 32.2006\n",
      "Epoch [2/25], Train Loss: 1049.9699, Eval Loss: 32.2849\n",
      "Epoch [3/25], Train Loss: 1051.6168, Eval Loss: 32.2628\n",
      "Epoch [4/25], Train Loss: 1050.8673, Eval Loss: 32.5939\n",
      "Epoch [5/25], Train Loss: 1052.2468, Eval Loss: 32.2844\n",
      "Epoch [6/25], Train Loss: 1051.8459, Eval Loss: 32.2866\n",
      "Epoch [7/25], Train Loss: 1051.8342, Eval Loss: 32.2845\n",
      "Epoch [8/25], Train Loss: 1051.4412, Eval Loss: 32.2842\n",
      "Epoch [9/25], Train Loss: 1051.3203, Eval Loss: 32.2844\n",
      "Epoch [10/25], Train Loss: 1051.6994, Eval Loss: 32.2844\n",
      "Epoch [11/25], Train Loss: 1051.7590, Eval Loss: 32.2844\n",
      "Epoch [12/25], Train Loss: 1051.7480, Eval Loss: 32.2838\n",
      "Epoch [13/25], Train Loss: 1051.1061, Eval Loss: 32.2835\n",
      "Epoch [14/25], Train Loss: 1051.7468, Eval Loss: 32.2844\n",
      "Epoch [15/25], Train Loss: 1050.7790, Eval Loss: 32.2845\n",
      "Epoch [16/25], Train Loss: 1051.6427, Eval Loss: 32.2844\n",
      "Epoch [17/25], Train Loss: 1051.1712, Eval Loss: 32.2600\n",
      "Epoch [18/25], Train Loss: 1051.5778, Eval Loss: 32.2770\n",
      "Epoch [19/25], Train Loss: 1051.6477, Eval Loss: 32.2796\n",
      "Epoch [20/25], Train Loss: 1051.2485, Eval Loss: 32.3178\n",
      "Epoch [21/25], Train Loss: 1051.8213, Eval Loss: 32.2844\n",
      "Epoch [22/25], Train Loss: 1051.7483, Eval Loss: 32.2844\n",
      "Epoch [23/25], Train Loss: 1051.5172, Eval Loss: 32.2824\n",
      "Epoch [24/25], Train Loss: 1050.7919, Eval Loss: 32.2730\n",
      "Epoch [25/25], Train Loss: 1051.6212, Eval Loss: 32.2844\n",
      "Epoch [1/25], Train Loss: 1350.4386, Eval Loss: 32.2841\n",
      "Epoch [2/25], Train Loss: 1051.7872, Eval Loss: 32.2844\n",
      "Epoch [3/25], Train Loss: 1051.8814, Eval Loss: 32.2843\n",
      "Epoch [4/25], Train Loss: 1051.7414, Eval Loss: 32.2839\n",
      "Epoch [5/25], Train Loss: 1051.6108, Eval Loss: 32.2845\n",
      "Epoch [6/25], Train Loss: 1051.5626, Eval Loss: 32.2844\n",
      "Epoch [7/25], Train Loss: 1051.7525, Eval Loss: 32.2843\n",
      "Epoch [8/25], Train Loss: 1051.7500, Eval Loss: 32.2844\n",
      "Epoch [9/25], Train Loss: 1051.7792, Eval Loss: 32.2776\n",
      "Epoch [10/25], Train Loss: 1051.6795, Eval Loss: 32.2845\n",
      "Epoch [11/25], Train Loss: 1051.7614, Eval Loss: 32.2847\n",
      "Epoch [12/25], Train Loss: 1051.8158, Eval Loss: 32.2844\n",
      "Epoch [13/25], Train Loss: 1051.7569, Eval Loss: 32.2843\n",
      "Epoch [14/25], Train Loss: 1053.4085, Eval Loss: 32.2844\n",
      "Epoch [15/25], Train Loss: 1051.7570, Eval Loss: 32.2844\n",
      "Epoch [16/25], Train Loss: 1051.7557, Eval Loss: 32.2844\n",
      "Epoch [17/25], Train Loss: 1051.7617, Eval Loss: 32.2844\n",
      "Epoch [18/25], Train Loss: 1051.7542, Eval Loss: 32.2842\n",
      "Epoch [19/25], Train Loss: 1051.7584, Eval Loss: 32.2844\n",
      "Epoch [20/25], Train Loss: 1051.7579, Eval Loss: 32.2844\n",
      "Epoch [21/25], Train Loss: 1051.7580, Eval Loss: 32.2844\n",
      "Epoch [22/25], Train Loss: 1051.7534, Eval Loss: 32.2843\n",
      "Epoch [23/25], Train Loss: 1051.7520, Eval Loss: 32.2844\n",
      "Epoch [24/25], Train Loss: 1052.9377, Eval Loss: 32.2844\n",
      "Epoch [25/25], Train Loss: 1051.7586, Eval Loss: 32.2844\n",
      "Epoch [1/25], Train Loss: 4889.8050, Eval Loss: 35.0366\n",
      "Epoch [2/25], Train Loss: 923.8733, Eval Loss: 31.4735\n",
      "Epoch [3/25], Train Loss: 923.1961, Eval Loss: 31.6618\n",
      "Epoch [4/25], Train Loss: 910.5207, Eval Loss: 31.8610\n",
      "Epoch [5/25], Train Loss: 922.3242, Eval Loss: 31.4563\n",
      "Epoch [6/25], Train Loss: 911.9245, Eval Loss: 31.9368\n",
      "Epoch [7/25], Train Loss: 938.0748, Eval Loss: 32.1041\n",
      "Epoch [8/25], Train Loss: 933.4198, Eval Loss: 32.0265\n",
      "Epoch [9/25], Train Loss: 907.5937, Eval Loss: 33.0448\n",
      "Epoch [10/25], Train Loss: 913.7708, Eval Loss: 32.9933\n",
      "Epoch [11/25], Train Loss: 910.0760, Eval Loss: 34.1665\n",
      "Epoch [12/25], Train Loss: 897.2873, Eval Loss: 31.7861\n",
      "Epoch [13/25], Train Loss: 928.9947, Eval Loss: 34.6916\n",
      "Epoch [14/25], Train Loss: 923.4192, Eval Loss: 33.9501\n",
      "Epoch [15/25], Train Loss: 903.8627, Eval Loss: 33.8751\n",
      "Epoch [16/25], Train Loss: 898.5842, Eval Loss: 32.5384\n",
      "Epoch [17/25], Train Loss: 897.8151, Eval Loss: 33.4389\n",
      "Epoch [18/25], Train Loss: 901.1640, Eval Loss: 35.0226\n",
      "Epoch [19/25], Train Loss: 901.6941, Eval Loss: 34.9344\n",
      "Epoch [20/25], Train Loss: 925.0035, Eval Loss: 34.5206\n",
      "Epoch [21/25], Train Loss: 890.3669, Eval Loss: 36.0637\n",
      "Epoch [22/25], Train Loss: 895.1265, Eval Loss: 33.9671\n",
      "Epoch [23/25], Train Loss: 910.8739, Eval Loss: 34.5232\n",
      "Epoch [24/25], Train Loss: 899.3952, Eval Loss: 35.1837\n",
      "Epoch [25/25], Train Loss: 927.4551, Eval Loss: 35.0312\n",
      "Epoch [1/25], Train Loss: 5032.5252, Eval Loss: 35.1337\n",
      "Epoch [2/25], Train Loss: 928.0682, Eval Loss: 31.5277\n",
      "Epoch [3/25], Train Loss: 941.6837, Eval Loss: 33.3298\n",
      "Epoch [4/25], Train Loss: 926.9527, Eval Loss: 32.4339\n",
      "Epoch [5/25], Train Loss: 926.5934, Eval Loss: 32.2892\n",
      "Epoch [6/25], Train Loss: 918.0866, Eval Loss: 32.2667\n",
      "Epoch [7/25], Train Loss: 903.2176, Eval Loss: 32.4559\n",
      "Epoch [8/25], Train Loss: 918.8545, Eval Loss: 31.9526\n",
      "Epoch [9/25], Train Loss: 920.5537, Eval Loss: 32.9129\n",
      "Epoch [10/25], Train Loss: 927.7894, Eval Loss: 32.3015\n",
      "Epoch [11/25], Train Loss: 933.0778, Eval Loss: 33.4221\n",
      "Epoch [12/25], Train Loss: 932.4659, Eval Loss: 32.7995\n",
      "Epoch [13/25], Train Loss: 927.6504, Eval Loss: 33.3797\n",
      "Epoch [14/25], Train Loss: 906.6176, Eval Loss: 33.4069\n",
      "Epoch [15/25], Train Loss: 904.9197, Eval Loss: 33.9275\n",
      "Epoch [16/25], Train Loss: 908.1926, Eval Loss: 34.5425\n",
      "Epoch [17/25], Train Loss: 911.6578, Eval Loss: 34.0881\n",
      "Epoch [18/25], Train Loss: 920.5967, Eval Loss: 33.3319\n",
      "Epoch [19/25], Train Loss: 902.0326, Eval Loss: 34.3328\n",
      "Epoch [20/25], Train Loss: 916.9411, Eval Loss: 34.9060\n",
      "Epoch [21/25], Train Loss: 892.7701, Eval Loss: 34.4186\n",
      "Epoch [22/25], Train Loss: 917.9882, Eval Loss: 34.5950\n",
      "Epoch [23/25], Train Loss: 894.9396, Eval Loss: 33.9919\n",
      "Epoch [24/25], Train Loss: 887.1454, Eval Loss: 34.2579\n",
      "Epoch [25/25], Train Loss: 895.9391, Eval Loss: 36.0274\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8864.6955, Eval Loss: 89.9451\n",
      "Epoch [2/25], Train Loss: 8146.7889, Eval Loss: 87.2933\n",
      "Epoch [3/25], Train Loss: 7709.4662, Eval Loss: 85.0969\n",
      "Epoch [4/25], Train Loss: 7343.1504, Eval Loss: 83.0810\n",
      "Epoch [5/25], Train Loss: 7010.4007, Eval Loss: 81.1682\n",
      "Epoch [6/25], Train Loss: 6700.3500, Eval Loss: 79.3290\n",
      "Epoch [7/25], Train Loss: 6408.0112, Eval Loss: 77.5498\n",
      "Epoch [8/25], Train Loss: 6131.0717, Eval Loss: 75.8226\n",
      "Epoch [9/25], Train Loss: 5867.8982, Eval Loss: 74.1426\n",
      "Epoch [10/25], Train Loss: 5617.2374, Eval Loss: 72.5065\n",
      "Epoch [11/25], Train Loss: 5378.3400, Eval Loss: 70.9121\n",
      "Epoch [12/25], Train Loss: 5150.4280, Eval Loss: 69.3575\n",
      "Epoch [13/25], Train Loss: 4932.9431, Eval Loss: 67.8416\n",
      "Epoch [14/25], Train Loss: 4725.2994, Eval Loss: 66.3632\n",
      "Epoch [15/25], Train Loss: 4527.0250, Eval Loss: 64.9216\n",
      "Epoch [16/25], Train Loss: 4337.7420, Eval Loss: 63.5159\n",
      "Epoch [17/25], Train Loss: 4157.0040, Eval Loss: 62.1455\n",
      "Epoch [18/25], Train Loss: 3984.4778, Eval Loss: 60.8100\n",
      "Epoch [19/25], Train Loss: 3819.7790, Eval Loss: 59.5089\n",
      "Epoch [20/25], Train Loss: 3662.5684, Eval Loss: 58.2416\n",
      "Epoch [21/25], Train Loss: 3512.5611, Eval Loss: 57.0079\n",
      "Epoch [22/25], Train Loss: 3369.4288, Eval Loss: 55.8073\n",
      "Epoch [23/25], Train Loss: 3232.9024, Eval Loss: 54.6394\n",
      "Epoch [24/25], Train Loss: 3102.7164, Eval Loss: 53.5040\n",
      "Epoch [25/25], Train Loss: 2978.6047, Eval Loss: 52.4008\n",
      "Epoch [1/25], Train Loss: 8886.9978, Eval Loss: 90.0896\n",
      "Epoch [2/25], Train Loss: 8172.9125, Eval Loss: 87.4432\n",
      "Epoch [3/25], Train Loss: 7733.4454, Eval Loss: 85.2245\n",
      "Epoch [4/25], Train Loss: 7363.6802, Eval Loss: 83.1953\n",
      "Epoch [5/25], Train Loss: 7028.6590, Eval Loss: 81.2733\n",
      "Epoch [6/25], Train Loss: 6716.8446, Eval Loss: 79.4267\n",
      "Epoch [7/25], Train Loss: 6423.0565, Eval Loss: 77.6409\n",
      "Epoch [8/25], Train Loss: 6144.8392, Eval Loss: 75.9077\n",
      "Epoch [9/25], Train Loss: 5880.3904, Eval Loss: 74.2220\n",
      "Epoch [10/25], Train Loss: 5628.6712, Eval Loss: 72.5805\n",
      "Epoch [11/25], Train Loss: 5388.7602, Eval Loss: 70.9806\n",
      "Epoch [12/25], Train Loss: 5159.8755, Eval Loss: 69.4208\n",
      "Epoch [13/25], Train Loss: 4941.4156, Eval Loss: 67.8996\n",
      "Epoch [14/25], Train Loss: 4732.8906, Eval Loss: 66.4160\n",
      "Epoch [15/25], Train Loss: 4533.7695, Eval Loss: 64.9690\n",
      "Epoch [16/25], Train Loss: 4343.6479, Eval Loss: 63.5580\n",
      "Epoch [17/25], Train Loss: 4162.1170, Eval Loss: 62.1823\n",
      "Epoch [18/25], Train Loss: 3988.8024, Eval Loss: 60.8414\n",
      "Epoch [19/25], Train Loss: 3823.3471, Eval Loss: 59.5349\n",
      "Epoch [20/25], Train Loss: 3665.4198, Eval Loss: 58.2622\n",
      "Epoch [21/25], Train Loss: 3514.7055, Eval Loss: 57.0229\n",
      "Epoch [22/25], Train Loss: 3370.9122, Eval Loss: 55.8168\n",
      "Epoch [23/25], Train Loss: 3233.7506, Eval Loss: 54.6435\n",
      "Epoch [24/25], Train Loss: 3102.9400, Eval Loss: 53.5025\n",
      "Epoch [25/25], Train Loss: 2978.2371, Eval Loss: 52.3937\n",
      "Epoch [1/25], Train Loss: 6271.9131, Eval Loss: 50.7599\n",
      "Epoch [2/25], Train Loss: 1655.2135, Eval Loss: 31.8704\n",
      "Epoch [3/25], Train Loss: 946.8581, Eval Loss: 29.1635\n",
      "Epoch [4/25], Train Loss: 864.8509, Eval Loss: 28.9022\n",
      "Epoch [5/25], Train Loss: 854.9470, Eval Loss: 28.8945\n",
      "Epoch [6/25], Train Loss: 853.9472, Eval Loss: 28.9013\n",
      "Epoch [7/25], Train Loss: 853.8804, Eval Loss: 28.9047\n",
      "Epoch [8/25], Train Loss: 853.5754, Eval Loss: 28.9058\n",
      "Epoch [9/25], Train Loss: 854.1054, Eval Loss: 28.9064\n",
      "Epoch [10/25], Train Loss: 853.9555, Eval Loss: 28.9065\n",
      "Epoch [11/25], Train Loss: 854.1583, Eval Loss: 28.9065\n",
      "Epoch [12/25], Train Loss: 853.8840, Eval Loss: 28.9067\n",
      "Epoch [13/25], Train Loss: 854.0335, Eval Loss: 28.9064\n",
      "Epoch [14/25], Train Loss: 853.8727, Eval Loss: 28.9068\n",
      "Epoch [15/25], Train Loss: 853.7165, Eval Loss: 28.9064\n",
      "Epoch [16/25], Train Loss: 853.7485, Eval Loss: 28.9065\n",
      "Epoch [17/25], Train Loss: 854.3126, Eval Loss: 28.9064\n",
      "Epoch [18/25], Train Loss: 853.8825, Eval Loss: 28.9064\n",
      "Epoch [19/25], Train Loss: 854.3711, Eval Loss: 28.9063\n",
      "Epoch [20/25], Train Loss: 853.7838, Eval Loss: 28.9063\n",
      "Epoch [21/25], Train Loss: 854.1519, Eval Loss: 28.9061\n",
      "Epoch [22/25], Train Loss: 853.5450, Eval Loss: 28.9064\n",
      "Epoch [23/25], Train Loss: 853.9275, Eval Loss: 28.9063\n",
      "Epoch [24/25], Train Loss: 854.1166, Eval Loss: 28.9061\n",
      "Epoch [25/25], Train Loss: 853.9009, Eval Loss: 28.9064\n",
      "Epoch [1/25], Train Loss: 6200.0596, Eval Loss: 50.1553\n",
      "Epoch [2/25], Train Loss: 1628.1643, Eval Loss: 31.7776\n",
      "Epoch [3/25], Train Loss: 944.2758, Eval Loss: 29.1548\n",
      "Epoch [4/25], Train Loss: 864.4689, Eval Loss: 28.9016\n",
      "Epoch [5/25], Train Loss: 855.1526, Eval Loss: 28.8943\n",
      "Epoch [6/25], Train Loss: 854.0288, Eval Loss: 28.9009\n",
      "Epoch [7/25], Train Loss: 853.9128, Eval Loss: 28.9042\n",
      "Epoch [8/25], Train Loss: 853.6161, Eval Loss: 28.9056\n",
      "Epoch [9/25], Train Loss: 853.6309, Eval Loss: 28.9060\n",
      "Epoch [10/25], Train Loss: 853.6181, Eval Loss: 28.9064\n",
      "Epoch [11/25], Train Loss: 854.1122, Eval Loss: 28.9062\n",
      "Epoch [12/25], Train Loss: 853.9574, Eval Loss: 28.9063\n",
      "Epoch [13/25], Train Loss: 854.0298, Eval Loss: 28.9063\n",
      "Epoch [14/25], Train Loss: 853.5413, Eval Loss: 28.9063\n",
      "Epoch [15/25], Train Loss: 853.6182, Eval Loss: 28.9064\n",
      "Epoch [16/25], Train Loss: 853.6919, Eval Loss: 28.9063\n",
      "Epoch [17/25], Train Loss: 853.8672, Eval Loss: 28.9063\n",
      "Epoch [18/25], Train Loss: 853.7178, Eval Loss: 28.9065\n",
      "Epoch [19/25], Train Loss: 854.0360, Eval Loss: 28.9063\n",
      "Epoch [20/25], Train Loss: 854.2539, Eval Loss: 28.9065\n",
      "Epoch [21/25], Train Loss: 853.8916, Eval Loss: 28.9063\n",
      "Epoch [22/25], Train Loss: 853.9452, Eval Loss: 28.9064\n",
      "Epoch [23/25], Train Loss: 853.5498, Eval Loss: 28.9064\n",
      "Epoch [24/25], Train Loss: 854.0040, Eval Loss: 28.9063\n",
      "Epoch [25/25], Train Loss: 853.9796, Eval Loss: 28.9061\n",
      "Epoch [1/25], Train Loss: 1629.6441, Eval Loss: 29.2911\n",
      "Epoch [2/25], Train Loss: 1074.7014, Eval Loss: 29.3214\n",
      "Epoch [3/25], Train Loss: 1099.3824, Eval Loss: 30.0948\n",
      "Epoch [4/25], Train Loss: 1033.6230, Eval Loss: 31.1335\n",
      "Epoch [5/25], Train Loss: 1057.5504, Eval Loss: 29.2241\n",
      "Epoch [6/25], Train Loss: 1082.3319, Eval Loss: 29.3871\n",
      "Epoch [7/25], Train Loss: 1005.2127, Eval Loss: 29.0165\n",
      "Epoch [8/25], Train Loss: 1026.1049, Eval Loss: 31.9507\n",
      "Epoch [9/25], Train Loss: 1005.8788, Eval Loss: 29.3725\n",
      "Epoch [10/25], Train Loss: 1001.8622, Eval Loss: 29.6083\n",
      "Epoch [11/25], Train Loss: 1012.9056, Eval Loss: 30.2586\n",
      "Epoch [12/25], Train Loss: 1018.4905, Eval Loss: 28.8773\n",
      "Epoch [13/25], Train Loss: 1076.1586, Eval Loss: 31.6413\n",
      "Epoch [14/25], Train Loss: 995.9989, Eval Loss: 29.1240\n",
      "Epoch [15/25], Train Loss: 999.3814, Eval Loss: 33.2081\n",
      "Epoch [16/25], Train Loss: 1008.9329, Eval Loss: 30.1514\n",
      "Epoch [17/25], Train Loss: 1002.0156, Eval Loss: 31.9311\n",
      "Epoch [18/25], Train Loss: 978.1216, Eval Loss: 30.5452\n",
      "Epoch [19/25], Train Loss: 1002.8473, Eval Loss: 29.1190\n",
      "Epoch [20/25], Train Loss: 992.0160, Eval Loss: 29.2788\n",
      "Epoch [21/25], Train Loss: 957.7322, Eval Loss: 30.1817\n",
      "Epoch [22/25], Train Loss: 965.3346, Eval Loss: 30.6817\n",
      "Epoch [23/25], Train Loss: 960.9417, Eval Loss: 28.4232\n",
      "Epoch [24/25], Train Loss: 972.3023, Eval Loss: 29.3839\n",
      "Epoch [25/25], Train Loss: 960.1463, Eval Loss: 29.2390\n",
      "Epoch [1/25], Train Loss: 1707.1861, Eval Loss: 30.2216\n",
      "Epoch [2/25], Train Loss: 1079.3269, Eval Loss: 29.8761\n",
      "Epoch [3/25], Train Loss: 1093.5897, Eval Loss: 31.2880\n",
      "Epoch [4/25], Train Loss: 1047.4468, Eval Loss: 30.2449\n",
      "Epoch [5/25], Train Loss: 1051.9062, Eval Loss: 30.2026\n",
      "Epoch [6/25], Train Loss: 1038.0613, Eval Loss: 29.0778\n",
      "Epoch [7/25], Train Loss: 1110.1610, Eval Loss: 29.0430\n",
      "Epoch [8/25], Train Loss: 1078.5846, Eval Loss: 30.5662\n",
      "Epoch [9/25], Train Loss: 1040.1114, Eval Loss: 29.3256\n",
      "Epoch [10/25], Train Loss: 1030.1742, Eval Loss: 29.7441\n",
      "Epoch [11/25], Train Loss: 1028.4198, Eval Loss: 29.5403\n",
      "Epoch [12/25], Train Loss: 1048.0357, Eval Loss: 29.0656\n",
      "Epoch [13/25], Train Loss: 1005.2776, Eval Loss: 30.5792\n",
      "Epoch [14/25], Train Loss: 1000.9219, Eval Loss: 32.1367\n",
      "Epoch [15/25], Train Loss: 1009.3016, Eval Loss: 29.4713\n",
      "Epoch [16/25], Train Loss: 995.2187, Eval Loss: 29.2853\n",
      "Epoch [17/25], Train Loss: 983.6017, Eval Loss: 29.3623\n",
      "Epoch [18/25], Train Loss: 1073.2854, Eval Loss: 31.2855\n",
      "Epoch [19/25], Train Loss: 1035.2396, Eval Loss: 32.0528\n",
      "Epoch [20/25], Train Loss: 995.9464, Eval Loss: 29.9498\n",
      "Epoch [21/25], Train Loss: 977.0256, Eval Loss: 29.4556\n",
      "Epoch [22/25], Train Loss: 973.0216, Eval Loss: 30.9690\n",
      "Epoch [23/25], Train Loss: 961.7253, Eval Loss: 30.7549\n",
      "Epoch [24/25], Train Loss: 940.7662, Eval Loss: 29.2123\n",
      "Epoch [25/25], Train Loss: 1018.7156, Eval Loss: 33.4833\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 7225.4381, Eval Loss: 73.5960\n",
      "Epoch [2/25], Train Loss: 4592.9899, Eval Loss: 58.9015\n",
      "Epoch [3/25], Train Loss: 3029.4447, Eval Loss: 48.1640\n",
      "Epoch [4/25], Train Loss: 2097.0085, Eval Loss: 40.6596\n",
      "Epoch [5/25], Train Loss: 1548.7668, Eval Loss: 35.7210\n",
      "Epoch [6/25], Train Loss: 1232.5896, Eval Loss: 32.6605\n",
      "Epoch [7/25], Train Loss: 1054.0203, Eval Loss: 30.8626\n",
      "Epoch [8/25], Train Loss: 955.5988, Eval Loss: 29.8611\n",
      "Epoch [9/25], Train Loss: 903.0970, Eval Loss: 29.3359\n",
      "Epoch [10/25], Train Loss: 876.2721, Eval Loss: 29.0793\n",
      "Epoch [11/25], Train Loss: 863.2641, Eval Loss: 28.9642\n",
      "Epoch [12/25], Train Loss: 857.3197, Eval Loss: 28.9181\n",
      "Epoch [13/25], Train Loss: 854.7818, Eval Loss: 28.9025\n",
      "Epoch [14/25], Train Loss: 853.7815, Eval Loss: 28.8991\n",
      "Epoch [15/25], Train Loss: 853.4271, Eval Loss: 28.8996\n",
      "Epoch [16/25], Train Loss: 853.3259, Eval Loss: 28.9009\n",
      "Epoch [17/25], Train Loss: 853.3154, Eval Loss: 28.9022\n",
      "Epoch [18/25], Train Loss: 853.3344, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 853.3604, Eval Loss: 28.9036\n",
      "Epoch [20/25], Train Loss: 853.3876, Eval Loss: 28.9040\n",
      "Epoch [21/25], Train Loss: 853.4137, Eval Loss: 28.9043\n",
      "Epoch [22/25], Train Loss: 853.4389, Eval Loss: 28.9045\n",
      "Epoch [23/25], Train Loss: 853.4632, Eval Loss: 28.9046\n",
      "Epoch [24/25], Train Loss: 853.4881, Eval Loss: 28.9048\n",
      "Epoch [25/25], Train Loss: 853.5104, Eval Loss: 28.9049\n",
      "Epoch [1/25], Train Loss: 7182.0210, Eval Loss: 73.3179\n",
      "Epoch [2/25], Train Loss: 4555.5963, Eval Loss: 58.6303\n",
      "Epoch [3/25], Train Loss: 3000.1878, Eval Loss: 47.9123\n",
      "Epoch [4/25], Train Loss: 2075.3344, Eval Loss: 40.4496\n",
      "Epoch [5/25], Train Loss: 1533.6749, Eval Loss: 35.5623\n",
      "Epoch [6/25], Train Loss: 1222.5968, Eval Loss: 32.5505\n",
      "Epoch [7/25], Train Loss: 1047.7116, Eval Loss: 30.7923\n",
      "Epoch [8/25], Train Loss: 951.8169, Eval Loss: 29.8196\n",
      "Epoch [9/25], Train Loss: 900.9545, Eval Loss: 29.3133\n",
      "Epoch [10/25], Train Loss: 875.1301, Eval Loss: 29.0681\n",
      "Epoch [11/25], Train Loss: 862.6914, Eval Loss: 28.9592\n",
      "Epoch [12/25], Train Loss: 857.0535, Eval Loss: 28.9161\n",
      "Epoch [13/25], Train Loss: 854.6669, Eval Loss: 28.9019\n",
      "Epoch [14/25], Train Loss: 853.7346, Eval Loss: 28.8990\n",
      "Epoch [15/25], Train Loss: 853.4087, Eval Loss: 28.8997\n",
      "Epoch [16/25], Train Loss: 853.3204, Eval Loss: 28.9011\n",
      "Epoch [17/25], Train Loss: 853.3142, Eval Loss: 28.9023\n",
      "Epoch [18/25], Train Loss: 853.3347, Eval Loss: 28.9031\n",
      "Epoch [19/25], Train Loss: 853.3610, Eval Loss: 28.9037\n",
      "Epoch [20/25], Train Loss: 853.3867, Eval Loss: 28.9041\n",
      "Epoch [21/25], Train Loss: 853.4133, Eval Loss: 28.9043\n",
      "Epoch [22/25], Train Loss: 853.4392, Eval Loss: 28.9045\n",
      "Epoch [23/25], Train Loss: 853.4623, Eval Loss: 28.9047\n",
      "Epoch [24/25], Train Loss: 853.4866, Eval Loss: 28.9048\n",
      "Epoch [25/25], Train Loss: 853.5118, Eval Loss: 28.9049\n",
      "Epoch [1/25], Train Loss: 1613.3580, Eval Loss: 29.0705\n",
      "Epoch [2/25], Train Loss: 862.4226, Eval Loss: 29.0678\n",
      "Epoch [3/25], Train Loss: 862.7990, Eval Loss: 29.0693\n",
      "Epoch [4/25], Train Loss: 862.9835, Eval Loss: 29.0691\n",
      "Epoch [5/25], Train Loss: 862.9011, Eval Loss: 29.0637\n",
      "Epoch [6/25], Train Loss: 862.8136, Eval Loss: 29.0690\n",
      "Epoch [7/25], Train Loss: 862.6965, Eval Loss: 29.0683\n",
      "Epoch [8/25], Train Loss: 863.2736, Eval Loss: 29.0646\n",
      "Epoch [9/25], Train Loss: 862.9273, Eval Loss: 29.0663\n",
      "Epoch [10/25], Train Loss: 863.1662, Eval Loss: 29.0739\n",
      "Epoch [11/25], Train Loss: 863.6336, Eval Loss: 29.0716\n",
      "Epoch [12/25], Train Loss: 862.7115, Eval Loss: 29.0731\n",
      "Epoch [13/25], Train Loss: 863.2315, Eval Loss: 29.0725\n",
      "Epoch [14/25], Train Loss: 863.0456, Eval Loss: 29.0716\n",
      "Epoch [15/25], Train Loss: 862.8056, Eval Loss: 29.0746\n",
      "Epoch [16/25], Train Loss: 862.8181, Eval Loss: 29.0719\n",
      "Epoch [17/25], Train Loss: 863.0015, Eval Loss: 29.0724\n",
      "Epoch [18/25], Train Loss: 862.6610, Eval Loss: 29.0717\n",
      "Epoch [19/25], Train Loss: 862.7730, Eval Loss: 29.0718\n",
      "Epoch [20/25], Train Loss: 862.0594, Eval Loss: 29.0638\n",
      "Epoch [21/25], Train Loss: 863.2154, Eval Loss: 29.0713\n",
      "Epoch [22/25], Train Loss: 863.0207, Eval Loss: 29.0721\n",
      "Epoch [23/25], Train Loss: 863.1263, Eval Loss: 29.0707\n",
      "Epoch [24/25], Train Loss: 862.8638, Eval Loss: 29.0683\n",
      "Epoch [25/25], Train Loss: 862.8195, Eval Loss: 29.0725\n",
      "Epoch [1/25], Train Loss: 1622.6352, Eval Loss: 29.0702\n",
      "Epoch [2/25], Train Loss: 863.1229, Eval Loss: 29.0711\n",
      "Epoch [3/25], Train Loss: 862.7433, Eval Loss: 29.0705\n",
      "Epoch [4/25], Train Loss: 862.5686, Eval Loss: 29.0706\n",
      "Epoch [5/25], Train Loss: 862.9881, Eval Loss: 29.0708\n",
      "Epoch [6/25], Train Loss: 862.8402, Eval Loss: 29.0700\n",
      "Epoch [7/25], Train Loss: 863.5817, Eval Loss: 29.0687\n",
      "Epoch [8/25], Train Loss: 862.9006, Eval Loss: 29.0689\n",
      "Epoch [9/25], Train Loss: 862.4701, Eval Loss: 29.0670\n",
      "Epoch [10/25], Train Loss: 862.3380, Eval Loss: 29.0705\n",
      "Epoch [11/25], Train Loss: 862.8753, Eval Loss: 29.0669\n",
      "Epoch [12/25], Train Loss: 862.4429, Eval Loss: 29.0670\n",
      "Epoch [13/25], Train Loss: 863.2107, Eval Loss: 29.0665\n",
      "Epoch [14/25], Train Loss: 863.0084, Eval Loss: 29.0700\n",
      "Epoch [15/25], Train Loss: 862.5377, Eval Loss: 29.0658\n",
      "Epoch [16/25], Train Loss: 863.2617, Eval Loss: 29.0671\n",
      "Epoch [17/25], Train Loss: 863.1105, Eval Loss: 29.0716\n",
      "Epoch [18/25], Train Loss: 862.4566, Eval Loss: 29.0698\n",
      "Epoch [19/25], Train Loss: 862.7177, Eval Loss: 29.0676\n",
      "Epoch [20/25], Train Loss: 863.6506, Eval Loss: 29.0676\n",
      "Epoch [21/25], Train Loss: 863.0818, Eval Loss: 29.0678\n",
      "Epoch [22/25], Train Loss: 862.3275, Eval Loss: 29.0638\n",
      "Epoch [23/25], Train Loss: 862.8979, Eval Loss: 29.0599\n",
      "Epoch [24/25], Train Loss: 863.0110, Eval Loss: 29.0756\n",
      "Epoch [25/25], Train Loss: 864.6802, Eval Loss: 29.0486\n",
      "Epoch [1/25], Train Loss: 3748.8593, Eval Loss: 34.6399\n",
      "Epoch [2/25], Train Loss: 1495.4808, Eval Loss: 31.8990\n",
      "Epoch [3/25], Train Loss: 1349.5130, Eval Loss: 35.7541\n",
      "Epoch [4/25], Train Loss: 1452.3812, Eval Loss: 31.2315\n",
      "Epoch [5/25], Train Loss: 1364.7203, Eval Loss: 39.6032\n",
      "Epoch [6/25], Train Loss: 1449.9783, Eval Loss: 34.8338\n",
      "Epoch [7/25], Train Loss: 1258.5289, Eval Loss: 36.3737\n",
      "Epoch [8/25], Train Loss: 1240.1514, Eval Loss: 32.0163\n",
      "Epoch [9/25], Train Loss: 1161.0065, Eval Loss: 49.8485\n",
      "Epoch [10/25], Train Loss: 1158.4837, Eval Loss: 46.7984\n",
      "Epoch [11/25], Train Loss: 1077.4902, Eval Loss: 49.9841\n",
      "Epoch [12/25], Train Loss: 1057.8625, Eval Loss: 46.4371\n",
      "Epoch [13/25], Train Loss: 1002.4568, Eval Loss: 46.9763\n",
      "Epoch [14/25], Train Loss: 975.1781, Eval Loss: 45.8297\n",
      "Epoch [15/25], Train Loss: 1023.8975, Eval Loss: 45.3600\n",
      "Epoch [16/25], Train Loss: 866.9238, Eval Loss: 46.7807\n",
      "Epoch [17/25], Train Loss: 817.5998, Eval Loss: 44.9199\n",
      "Epoch [18/25], Train Loss: 806.1983, Eval Loss: 46.2681\n",
      "Epoch [19/25], Train Loss: 822.8756, Eval Loss: 43.8275\n",
      "Epoch [20/25], Train Loss: 744.8559, Eval Loss: 43.2084\n",
      "Epoch [21/25], Train Loss: 773.8449, Eval Loss: 40.6179\n",
      "Epoch [22/25], Train Loss: 973.1779, Eval Loss: 44.0384\n",
      "Epoch [23/25], Train Loss: 764.9697, Eval Loss: 41.9083\n",
      "Epoch [24/25], Train Loss: 730.8070, Eval Loss: 41.7741\n",
      "Epoch [25/25], Train Loss: 691.5143, Eval Loss: 41.0931\n",
      "Epoch [1/25], Train Loss: 5239.9405, Eval Loss: 51.5911\n",
      "Epoch [2/25], Train Loss: 1347.5174, Eval Loss: 33.5603\n",
      "Epoch [3/25], Train Loss: 1269.8731, Eval Loss: 29.3096\n",
      "Epoch [4/25], Train Loss: 1265.1012, Eval Loss: 31.7027\n",
      "Epoch [5/25], Train Loss: 1419.5788, Eval Loss: 31.7372\n",
      "Epoch [6/25], Train Loss: 1424.8342, Eval Loss: 30.1344\n",
      "Epoch [7/25], Train Loss: 1576.6532, Eval Loss: 32.6258\n",
      "Epoch [8/25], Train Loss: 1173.1595, Eval Loss: 31.7503\n",
      "Epoch [9/25], Train Loss: 1192.9431, Eval Loss: 34.5429\n",
      "Epoch [10/25], Train Loss: 1092.0970, Eval Loss: 36.4962\n",
      "Epoch [11/25], Train Loss: 1183.7174, Eval Loss: 41.9107\n",
      "Epoch [12/25], Train Loss: 1110.3942, Eval Loss: 37.4466\n",
      "Epoch [13/25], Train Loss: 1200.1874, Eval Loss: 43.8475\n",
      "Epoch [14/25], Train Loss: 1137.5055, Eval Loss: 47.6306\n",
      "Epoch [15/25], Train Loss: 1076.7570, Eval Loss: 48.7085\n",
      "Epoch [16/25], Train Loss: 998.3337, Eval Loss: 40.4698\n",
      "Epoch [17/25], Train Loss: 1008.2625, Eval Loss: 46.9877\n",
      "Epoch [18/25], Train Loss: 921.2150, Eval Loss: 46.7330\n",
      "Epoch [19/25], Train Loss: 960.7246, Eval Loss: 40.4515\n",
      "Epoch [20/25], Train Loss: 945.5288, Eval Loss: 47.6910\n",
      "Epoch [21/25], Train Loss: 851.9220, Eval Loss: 48.7943\n",
      "Epoch [22/25], Train Loss: 824.3830, Eval Loss: 49.8008\n",
      "Epoch [23/25], Train Loss: 750.4960, Eval Loss: 45.0020\n",
      "Epoch [24/25], Train Loss: 778.5042, Eval Loss: 48.4841\n",
      "Epoch [25/25], Train Loss: 744.6024, Eval Loss: 42.6751\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 2427.3754, Eval Loss: 28.9306\n",
      "Epoch [2/25], Train Loss: 857.8273, Eval Loss: 28.8853\n",
      "Epoch [3/25], Train Loss: 857.1370, Eval Loss: 28.8864\n",
      "Epoch [4/25], Train Loss: 857.5100, Eval Loss: 28.8867\n",
      "Epoch [5/25], Train Loss: 857.8016, Eval Loss: 28.8874\n",
      "Epoch [6/25], Train Loss: 858.0672, Eval Loss: 28.8885\n",
      "Epoch [7/25], Train Loss: 858.2939, Eval Loss: 28.8901\n",
      "Epoch [8/25], Train Loss: 858.5093, Eval Loss: 28.8919\n",
      "Epoch [9/25], Train Loss: 858.4177, Eval Loss: 28.9361\n",
      "Epoch [10/25], Train Loss: 859.7439, Eval Loss: 28.9136\n",
      "Epoch [11/25], Train Loss: 858.6563, Eval Loss: 28.9260\n",
      "Epoch [12/25], Train Loss: 859.0852, Eval Loss: 28.8990\n",
      "Epoch [13/25], Train Loss: 858.8568, Eval Loss: 28.8998\n",
      "Epoch [14/25], Train Loss: 860.5248, Eval Loss: 28.8985\n",
      "Epoch [15/25], Train Loss: 859.5447, Eval Loss: 28.9037\n",
      "Epoch [16/25], Train Loss: 859.9431, Eval Loss: 28.8995\n",
      "Epoch [17/25], Train Loss: 859.7031, Eval Loss: 28.9090\n",
      "Epoch [18/25], Train Loss: 859.8556, Eval Loss: 28.9301\n",
      "Epoch [19/25], Train Loss: 859.5720, Eval Loss: 28.9150\n",
      "Epoch [20/25], Train Loss: 860.1205, Eval Loss: 28.9124\n",
      "Epoch [21/25], Train Loss: 860.7956, Eval Loss: 28.9147\n",
      "Epoch [22/25], Train Loss: 860.1868, Eval Loss: 28.9155\n",
      "Epoch [23/25], Train Loss: 861.2179, Eval Loss: 28.9217\n",
      "Epoch [24/25], Train Loss: 888.7466, Eval Loss: 28.9952\n",
      "Epoch [25/25], Train Loss: 861.3087, Eval Loss: 28.9341\n",
      "Epoch [1/25], Train Loss: 2498.9499, Eval Loss: 28.9290\n",
      "Epoch [2/25], Train Loss: 857.4197, Eval Loss: 28.8824\n",
      "Epoch [3/25], Train Loss: 856.9422, Eval Loss: 28.8861\n",
      "Epoch [4/25], Train Loss: 857.4565, Eval Loss: 28.8867\n",
      "Epoch [5/25], Train Loss: 857.7509, Eval Loss: 28.8873\n",
      "Epoch [6/25], Train Loss: 858.0090, Eval Loss: 28.8884\n",
      "Epoch [7/25], Train Loss: 858.2449, Eval Loss: 28.8900\n",
      "Epoch [8/25], Train Loss: 858.4623, Eval Loss: 28.8917\n",
      "Epoch [9/25], Train Loss: 858.6622, Eval Loss: 28.8936\n",
      "Epoch [10/25], Train Loss: 858.8469, Eval Loss: 28.8955\n",
      "Epoch [11/25], Train Loss: 859.0172, Eval Loss: 28.8973\n",
      "Epoch [12/25], Train Loss: 859.1735, Eval Loss: 28.8990\n",
      "Epoch [13/25], Train Loss: 861.5755, Eval Loss: 29.0192\n",
      "Epoch [14/25], Train Loss: 860.9881, Eval Loss: 28.9302\n",
      "Epoch [15/25], Train Loss: 860.2766, Eval Loss: 28.8906\n",
      "Epoch [16/25], Train Loss: 859.7606, Eval Loss: 28.9042\n",
      "Epoch [17/25], Train Loss: 860.1434, Eval Loss: 28.9070\n",
      "Epoch [18/25], Train Loss: 860.5738, Eval Loss: 28.9323\n",
      "Epoch [19/25], Train Loss: 859.9445, Eval Loss: 28.9054\n",
      "Epoch [20/25], Train Loss: 859.7044, Eval Loss: 28.9102\n",
      "Epoch [21/25], Train Loss: 860.3996, Eval Loss: 28.8997\n",
      "Epoch [22/25], Train Loss: 860.1689, Eval Loss: 28.9155\n",
      "Epoch [23/25], Train Loss: 860.3245, Eval Loss: 28.9128\n",
      "Epoch [24/25], Train Loss: 860.0707, Eval Loss: 28.9444\n",
      "Epoch [25/25], Train Loss: 860.3321, Eval Loss: 28.9157\n",
      "Epoch [1/25], Train Loss: 1301.3334, Eval Loss: 31.9049\n",
      "Epoch [2/25], Train Loss: 1035.7853, Eval Loss: 32.0541\n",
      "Epoch [3/25], Train Loss: 1047.7714, Eval Loss: 32.2147\n",
      "Epoch [4/25], Train Loss: 1047.8596, Eval Loss: 31.8864\n",
      "Epoch [5/25], Train Loss: 1042.8220, Eval Loss: 32.3994\n",
      "Epoch [6/25], Train Loss: 1043.1393, Eval Loss: 32.0501\n",
      "Epoch [7/25], Train Loss: 1043.3470, Eval Loss: 32.2024\n",
      "Epoch [8/25], Train Loss: 1048.7790, Eval Loss: 32.3628\n",
      "Epoch [9/25], Train Loss: 1043.8984, Eval Loss: 32.3061\n",
      "Epoch [10/25], Train Loss: 1045.1716, Eval Loss: 32.2366\n",
      "Epoch [11/25], Train Loss: 1049.0899, Eval Loss: 32.2451\n",
      "Epoch [12/25], Train Loss: 1044.5263, Eval Loss: 32.2599\n",
      "Epoch [13/25], Train Loss: 1048.4152, Eval Loss: 32.1162\n",
      "Epoch [14/25], Train Loss: 1050.9135, Eval Loss: 32.2389\n",
      "Epoch [15/25], Train Loss: 1049.7936, Eval Loss: 32.2393\n",
      "Epoch [16/25], Train Loss: 1047.8573, Eval Loss: 32.2765\n",
      "Epoch [17/25], Train Loss: 1048.2921, Eval Loss: 32.2402\n",
      "Epoch [18/25], Train Loss: 1042.5407, Eval Loss: 32.4822\n",
      "Epoch [19/25], Train Loss: 1047.9246, Eval Loss: 32.3083\n",
      "Epoch [20/25], Train Loss: 1049.5153, Eval Loss: 32.1839\n",
      "Epoch [21/25], Train Loss: 1049.4144, Eval Loss: 32.2718\n",
      "Epoch [22/25], Train Loss: 1050.2023, Eval Loss: 32.1915\n",
      "Epoch [23/25], Train Loss: 1052.1039, Eval Loss: 32.2690\n",
      "Epoch [24/25], Train Loss: 1054.2482, Eval Loss: 32.2831\n",
      "Epoch [25/25], Train Loss: 1051.2744, Eval Loss: 32.2763\n",
      "Epoch [1/25], Train Loss: 1377.9165, Eval Loss: 32.2710\n",
      "Epoch [2/25], Train Loss: 1051.4170, Eval Loss: 32.3505\n",
      "Epoch [3/25], Train Loss: 1050.6038, Eval Loss: 32.2052\n",
      "Epoch [4/25], Train Loss: 1049.4098, Eval Loss: 32.2757\n",
      "Epoch [5/25], Train Loss: 1050.0248, Eval Loss: 32.2828\n",
      "Epoch [6/25], Train Loss: 1046.1172, Eval Loss: 32.3391\n",
      "Epoch [7/25], Train Loss: 1048.6108, Eval Loss: 32.3118\n",
      "Epoch [8/25], Train Loss: 1049.2001, Eval Loss: 32.0982\n",
      "Epoch [9/25], Train Loss: 1050.4145, Eval Loss: 32.3568\n",
      "Epoch [10/25], Train Loss: 1050.9091, Eval Loss: 32.1880\n",
      "Epoch [11/25], Train Loss: 1052.2821, Eval Loss: 32.3196\n",
      "Epoch [12/25], Train Loss: 1050.4003, Eval Loss: 32.1021\n",
      "Epoch [13/25], Train Loss: 1047.8510, Eval Loss: 32.2935\n",
      "Epoch [14/25], Train Loss: 1051.4939, Eval Loss: 32.2808\n",
      "Epoch [15/25], Train Loss: 1050.2038, Eval Loss: 32.1708\n",
      "Epoch [16/25], Train Loss: 1050.1449, Eval Loss: 32.2150\n",
      "Epoch [17/25], Train Loss: 1051.2425, Eval Loss: 32.2816\n",
      "Epoch [18/25], Train Loss: 1051.2979, Eval Loss: 32.2857\n",
      "Epoch [19/25], Train Loss: 1051.3803, Eval Loss: 32.2714\n",
      "Epoch [20/25], Train Loss: 1050.9080, Eval Loss: 32.2844\n",
      "Epoch [21/25], Train Loss: 1051.2137, Eval Loss: 32.1781\n",
      "Epoch [22/25], Train Loss: 1051.7406, Eval Loss: 32.2721\n",
      "Epoch [23/25], Train Loss: 1051.1948, Eval Loss: 32.2836\n",
      "Epoch [24/25], Train Loss: 1050.4478, Eval Loss: 32.2628\n",
      "Epoch [25/25], Train Loss: 1049.5181, Eval Loss: 31.9306\n",
      "Epoch [1/25], Train Loss: 9219.8742, Eval Loss: 92.4873\n",
      "Epoch [2/25], Train Loss: 6997.2717, Eval Loss: 57.9630\n",
      "Epoch [3/25], Train Loss: 1404.4262, Eval Loss: 28.8994\n",
      "Epoch [4/25], Train Loss: 855.5804, Eval Loss: 28.9099\n",
      "Epoch [5/25], Train Loss: 855.9823, Eval Loss: 28.9093\n",
      "Epoch [6/25], Train Loss: 855.9661, Eval Loss: 28.9086\n",
      "Epoch [7/25], Train Loss: 855.9556, Eval Loss: 28.9076\n",
      "Epoch [8/25], Train Loss: 855.9378, Eval Loss: 28.9064\n",
      "Epoch [9/25], Train Loss: 855.9126, Eval Loss: 28.9050\n",
      "Epoch [10/25], Train Loss: 855.8809, Eval Loss: 28.9035\n",
      "Epoch [11/25], Train Loss: 855.8415, Eval Loss: 28.9018\n",
      "Epoch [12/25], Train Loss: 855.7973, Eval Loss: 28.9001\n",
      "Epoch [13/25], Train Loss: 855.7458, Eval Loss: 28.8982\n",
      "Epoch [14/25], Train Loss: 855.6792, Eval Loss: 28.8964\n",
      "Epoch [15/25], Train Loss: 855.6189, Eval Loss: 28.8947\n",
      "Epoch [16/25], Train Loss: 855.5512, Eval Loss: 28.8926\n",
      "Epoch [17/25], Train Loss: 855.4751, Eval Loss: 28.8907\n",
      "Epoch [18/25], Train Loss: 855.3997, Eval Loss: 28.8884\n",
      "Epoch [19/25], Train Loss: 855.3022, Eval Loss: 28.8866\n",
      "Epoch [20/25], Train Loss: 855.2233, Eval Loss: 28.8845\n",
      "Epoch [21/25], Train Loss: 855.1306, Eval Loss: 28.8824\n",
      "Epoch [22/25], Train Loss: 855.0357, Eval Loss: 28.8803\n",
      "Epoch [23/25], Train Loss: 854.9321, Eval Loss: 28.8784\n",
      "Epoch [24/25], Train Loss: 854.8413, Eval Loss: 28.8761\n",
      "Epoch [25/25], Train Loss: 854.7393, Eval Loss: 28.8738\n",
      "Epoch [1/25], Train Loss: 9070.1430, Eval Loss: 91.1027\n",
      "Epoch [2/25], Train Loss: 6700.8688, Eval Loss: 56.8825\n",
      "Epoch [3/25], Train Loss: 1360.3083, Eval Loss: 28.9578\n",
      "Epoch [4/25], Train Loss: 855.6498, Eval Loss: 28.8947\n",
      "Epoch [5/25], Train Loss: 855.4279, Eval Loss: 28.8943\n",
      "Epoch [6/25], Train Loss: 855.3716, Eval Loss: 28.8929\n",
      "Epoch [7/25], Train Loss: 855.4061, Eval Loss: 28.8915\n",
      "Epoch [8/25], Train Loss: 855.3506, Eval Loss: 28.8904\n",
      "Epoch [9/25], Train Loss: 855.3054, Eval Loss: 28.8893\n",
      "Epoch [10/25], Train Loss: 855.2587, Eval Loss: 28.8878\n",
      "Epoch [11/25], Train Loss: 855.2189, Eval Loss: 28.8868\n",
      "Epoch [12/25], Train Loss: 855.1630, Eval Loss: 28.8848\n",
      "Epoch [13/25], Train Loss: 855.0955, Eval Loss: 28.8833\n",
      "Epoch [14/25], Train Loss: 855.0195, Eval Loss: 28.8819\n",
      "Epoch [15/25], Train Loss: 854.9725, Eval Loss: 28.8801\n",
      "Epoch [16/25], Train Loss: 854.9003, Eval Loss: 28.8785\n",
      "Epoch [17/25], Train Loss: 854.8256, Eval Loss: 28.8768\n",
      "Epoch [18/25], Train Loss: 854.7490, Eval Loss: 28.8750\n",
      "Epoch [19/25], Train Loss: 854.6677, Eval Loss: 28.8735\n",
      "Epoch [20/25], Train Loss: 854.5917, Eval Loss: 28.8716\n",
      "Epoch [21/25], Train Loss: 854.4895, Eval Loss: 28.8698\n",
      "Epoch [22/25], Train Loss: 854.4168, Eval Loss: 28.8679\n",
      "Epoch [23/25], Train Loss: 854.3241, Eval Loss: 28.8661\n",
      "Epoch [24/25], Train Loss: 854.2320, Eval Loss: 28.8641\n",
      "Epoch [25/25], Train Loss: 854.1392, Eval Loss: 28.8626\n",
      "Epoch [1/25], Train Loss: 18970.7824, Eval Loss: 94.8974\n",
      "Epoch [2/25], Train Loss: 15813.5792, Eval Loss: 94.6933\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 10299.4255, Eval Loss: 94.9199\n",
      "Epoch [2/25], Train Loss: 9248.5114, Eval Loss: 94.0594\n",
      "Epoch [3/25], Train Loss: 40588.3128, Eval Loss: 94.4067\n",
      "Epoch [4/25], Train Loss: 9172.5485, Eval Loss: 94.0556\n",
      "Epoch [5/25], Train Loss: 9105.5772, Eval Loss: 93.7689\n",
      "Epoch [6/25], Train Loss: 9037.8524, Eval Loss: 93.0826\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9277.5730, Eval Loss: 94.2640\n",
      "Epoch [2/25], Train Loss: 9048.0064, Eval Loss: 92.8626\n",
      "Epoch [3/25], Train Loss: 8785.0519, Eval Loss: 91.5365\n",
      "Epoch [4/25], Train Loss: 8560.3455, Eval Loss: 90.4420\n",
      "Epoch [5/25], Train Loss: 8375.4703, Eval Loss: 89.5098\n",
      "Epoch [6/25], Train Loss: 8215.9551, Eval Loss: 88.6774\n",
      "Epoch [7/25], Train Loss: 8071.8972, Eval Loss: 87.9042\n",
      "Epoch [8/25], Train Loss: 7937.5880, Eval Loss: 87.1691\n",
      "Epoch [9/25], Train Loss: 7810.0562, Eval Loss: 86.4609\n",
      "Epoch [10/25], Train Loss: 7687.6327, Eval Loss: 85.7729\n",
      "Epoch [11/25], Train Loss: 7569.2937, Eval Loss: 85.1009\n",
      "Epoch [12/25], Train Loss: 7454.3646, Eval Loss: 84.4420\n",
      "Epoch [13/25], Train Loss: 7342.3751, Eval Loss: 83.7941\n",
      "Epoch [14/25], Train Loss: 7232.9833, Eval Loss: 83.1559\n",
      "Epoch [15/25], Train Loss: 7125.9309, Eval Loss: 82.5262\n",
      "Epoch [16/25], Train Loss: 7021.0178, Eval Loss: 81.9040\n",
      "Epoch [17/25], Train Loss: 6918.0850, Eval Loss: 81.2888\n",
      "Epoch [18/25], Train Loss: 6817.0032, Eval Loss: 80.6799\n",
      "Epoch [19/25], Train Loss: 6717.6655, Eval Loss: 80.0770\n",
      "Epoch [20/25], Train Loss: 6619.9820, Eval Loss: 79.4795\n",
      "Epoch [21/25], Train Loss: 6523.8762, Eval Loss: 78.8873\n",
      "Epoch [22/25], Train Loss: 6429.2821, Eval Loss: 78.3000\n",
      "Epoch [23/25], Train Loss: 6336.1420, Eval Loss: 77.7174\n",
      "Epoch [24/25], Train Loss: 6244.4052, Eval Loss: 77.1393\n",
      "Epoch [25/25], Train Loss: 6154.0267, Eval Loss: 76.5655\n",
      "Epoch [1/25], Train Loss: 9277.8045, Eval Loss: 94.2811\n",
      "Epoch [2/25], Train Loss: 9054.8986, Eval Loss: 92.9168\n",
      "Epoch [3/25], Train Loss: 8797.0616, Eval Loss: 91.6185\n",
      "Epoch [4/25], Train Loss: 8576.0132, Eval Loss: 90.5402\n",
      "Epoch [5/25], Train Loss: 8393.6595, Eval Loss: 89.6213\n",
      "Epoch [6/25], Train Loss: 8234.8578, Eval Loss: 88.7863\n",
      "Epoch [7/25], Train Loss: 8089.7505, Eval Loss: 88.0076\n",
      "Epoch [8/25], Train Loss: 7954.3941, Eval Loss: 87.2682\n",
      "Epoch [9/25], Train Loss: 7826.0475, Eval Loss: 86.5567\n",
      "Epoch [10/25], Train Loss: 7702.9773, Eval Loss: 85.8661\n",
      "Epoch [11/25], Train Loss: 7584.1041, Eval Loss: 85.1920\n",
      "Epoch [12/25], Train Loss: 7468.7187, Eval Loss: 84.5313\n",
      "Epoch [13/25], Train Loss: 7356.3294, Eval Loss: 83.8820\n",
      "Epoch [14/25], Train Loss: 7246.5800, Eval Loss: 83.2424\n",
      "Epoch [15/25], Train Loss: 7139.2032, Eval Loss: 82.6115\n",
      "Epoch [16/25], Train Loss: 7033.9923, Eval Loss: 81.9882\n",
      "Epoch [17/25], Train Loss: 6930.7831, Eval Loss: 81.3720\n",
      "Epoch [18/25], Train Loss: 6829.4429, Eval Loss: 80.7622\n",
      "Epoch [19/25], Train Loss: 6729.8619, Eval Loss: 80.1584\n",
      "Epoch [20/25], Train Loss: 6631.9477, Eval Loss: 79.5602\n",
      "Epoch [21/25], Train Loss: 6535.6223, Eval Loss: 78.9672\n",
      "Epoch [22/25], Train Loss: 6440.8183, Eval Loss: 78.3792\n",
      "Epoch [23/25], Train Loss: 6347.4766, Eval Loss: 77.7960\n",
      "Epoch [24/25], Train Loss: 6255.5458, Eval Loss: 77.2172\n",
      "Epoch [25/25], Train Loss: 6164.9800, Eval Loss: 76.6429\n",
      "Epoch [1/25], Train Loss: 8333.7074, Eval Loss: 79.2943\n",
      "Epoch [2/25], Train Loss: 4960.5313, Eval Loss: 58.9575\n",
      "Epoch [3/25], Train Loss: 2866.2753, Eval Loss: 45.7246\n",
      "Epoch [4/25], Train Loss: 1835.6398, Eval Loss: 37.7946\n",
      "Epoch [5/25], Train Loss: 1332.4103, Eval Loss: 33.3754\n",
      "Epoch [6/25], Train Loss: 1086.8096, Eval Loss: 31.0638\n",
      "Epoch [7/25], Train Loss: 967.0106, Eval Loss: 29.9094\n",
      "Epoch [8/25], Train Loss: 908.6026, Eval Loss: 29.3517\n",
      "Epoch [9/25], Train Loss: 880.1346, Eval Loss: 29.0898\n",
      "Epoch [10/25], Train Loss: 866.2617, Eval Loss: 28.9706\n",
      "Epoch [11/25], Train Loss: 859.5020, Eval Loss: 28.9189\n",
      "Epoch [12/25], Train Loss: 856.2084, Eval Loss: 28.8982\n",
      "Epoch [13/25], Train Loss: 854.6035, Eval Loss: 28.8912\n",
      "Epoch [14/25], Train Loss: 853.8214, Eval Loss: 28.8901\n",
      "Epoch [15/25], Train Loss: 853.4402, Eval Loss: 28.8910\n",
      "Epoch [16/25], Train Loss: 853.2542, Eval Loss: 28.8926\n",
      "Epoch [17/25], Train Loss: 853.1633, Eval Loss: 28.8941\n",
      "Epoch [18/25], Train Loss: 853.1186, Eval Loss: 28.8953\n",
      "Epoch [19/25], Train Loss: 853.0966, Eval Loss: 28.8963\n",
      "Epoch [20/25], Train Loss: 853.0854, Eval Loss: 28.8970\n",
      "Epoch [21/25], Train Loss: 853.0797, Eval Loss: 28.8975\n",
      "Epoch [22/25], Train Loss: 853.0765, Eval Loss: 28.8979\n",
      "Epoch [23/25], Train Loss: 853.0746, Eval Loss: 28.8982\n",
      "Epoch [24/25], Train Loss: 853.0733, Eval Loss: 28.8984\n",
      "Epoch [25/25], Train Loss: 853.0722, Eval Loss: 28.8985\n",
      "Epoch [1/25], Train Loss: 8376.8448, Eval Loss: 79.8873\n",
      "Epoch [2/25], Train Loss: 5034.3085, Eval Loss: 59.3768\n",
      "Epoch [3/25], Train Loss: 2901.2315, Eval Loss: 45.9893\n",
      "Epoch [4/25], Train Loss: 1852.7274, Eval Loss: 37.9517\n",
      "Epoch [5/25], Train Loss: 1340.7803, Eval Loss: 33.4624\n",
      "Epoch [6/25], Train Loss: 1090.9142, Eval Loss: 31.1098\n",
      "Epoch [7/25], Train Loss: 969.0288, Eval Loss: 29.9331\n",
      "Epoch [8/25], Train Loss: 909.6000, Eval Loss: 29.3639\n",
      "Epoch [9/25], Train Loss: 880.6321, Eval Loss: 29.0961\n",
      "Epoch [10/25], Train Loss: 866.5141, Eval Loss: 28.9740\n",
      "Epoch [11/25], Train Loss: 859.6339, Eval Loss: 28.9208\n",
      "Epoch [12/25], Train Loss: 856.2807, Eval Loss: 28.8993\n",
      "Epoch [13/25], Train Loss: 854.6462, Eval Loss: 28.8919\n",
      "Epoch [14/25], Train Loss: 853.8493, Eval Loss: 28.8906\n",
      "Epoch [15/25], Train Loss: 853.4606, Eval Loss: 28.8914\n",
      "Epoch [16/25], Train Loss: 853.2708, Eval Loss: 28.8929\n",
      "Epoch [17/25], Train Loss: 853.1778, Eval Loss: 28.8944\n",
      "Epoch [18/25], Train Loss: 853.1321, Eval Loss: 28.8956\n",
      "Epoch [19/25], Train Loss: 853.1095, Eval Loss: 28.8965\n",
      "Epoch [20/25], Train Loss: 853.0980, Eval Loss: 28.8973\n",
      "Epoch [21/25], Train Loss: 853.0921, Eval Loss: 28.8978\n",
      "Epoch [22/25], Train Loss: 853.0888, Eval Loss: 28.8981\n",
      "Epoch [23/25], Train Loss: 853.0868, Eval Loss: 28.8984\n",
      "Epoch [24/25], Train Loss: 853.0854, Eval Loss: 28.8986\n",
      "Epoch [25/25], Train Loss: 853.0844, Eval Loss: 28.8987\n",
      "Epoch [1/25], Train Loss: 3155.5492, Eval Loss: 29.3852\n",
      "Epoch [2/25], Train Loss: 867.1096, Eval Loss: 29.1827\n",
      "Epoch [3/25], Train Loss: 867.6210, Eval Loss: 29.1669\n",
      "Epoch [4/25], Train Loss: 869.1949, Eval Loss: 29.0910\n",
      "Epoch [5/25], Train Loss: 869.0989, Eval Loss: 29.0181\n",
      "Epoch [6/25], Train Loss: 868.1808, Eval Loss: 28.9657\n",
      "Epoch [7/25], Train Loss: 866.9947, Eval Loss: 28.9213\n",
      "Epoch [8/25], Train Loss: 865.7109, Eval Loss: 28.8862\n",
      "Epoch [9/25], Train Loss: 864.4648, Eval Loss: 28.8533\n",
      "Epoch [10/25], Train Loss: 863.1291, Eval Loss: 28.8277\n",
      "Epoch [11/25], Train Loss: 861.8181, Eval Loss: 28.8021\n",
      "Epoch [12/25], Train Loss: 860.5014, Eval Loss: 28.7764\n",
      "Epoch [13/25], Train Loss: 859.1610, Eval Loss: 28.7515\n",
      "Epoch [14/25], Train Loss: 857.7942, Eval Loss: 28.7255\n",
      "Epoch [15/25], Train Loss: 856.3724, Eval Loss: 28.7001\n",
      "Epoch [16/25], Train Loss: 854.9237, Eval Loss: 28.6726\n",
      "Epoch [17/25], Train Loss: 853.4488, Eval Loss: 28.6443\n",
      "Epoch [18/25], Train Loss: 851.8576, Eval Loss: 28.6145\n",
      "Epoch [19/25], Train Loss: 850.2466, Eval Loss: 28.5838\n",
      "Epoch [20/25], Train Loss: 848.5149, Eval Loss: 28.5526\n",
      "Epoch [21/25], Train Loss: 846.7405, Eval Loss: 28.5167\n",
      "Epoch [22/25], Train Loss: 844.8999, Eval Loss: 28.4851\n",
      "Epoch [23/25], Train Loss: 842.9229, Eval Loss: 28.4422\n",
      "Epoch [24/25], Train Loss: 840.6635, Eval Loss: 28.3993\n",
      "Epoch [25/25], Train Loss: 838.3968, Eval Loss: 28.3543\n",
      "Epoch [1/25], Train Loss: 3039.4477, Eval Loss: 28.9970\n",
      "Epoch [2/25], Train Loss: 866.0565, Eval Loss: 29.1364\n",
      "Epoch [3/25], Train Loss: 868.6082, Eval Loss: 28.9892\n",
      "Epoch [4/25], Train Loss: 868.3466, Eval Loss: 28.9425\n",
      "Epoch [5/25], Train Loss: 867.6888, Eval Loss: 28.9198\n",
      "Epoch [6/25], Train Loss: 866.8687, Eval Loss: 28.9096\n",
      "Epoch [7/25], Train Loss: 866.1049, Eval Loss: 28.9025\n",
      "Epoch [8/25], Train Loss: 865.4465, Eval Loss: 28.8942\n",
      "Epoch [9/25], Train Loss: 864.7592, Eval Loss: 28.8821\n",
      "Epoch [10/25], Train Loss: 863.9680, Eval Loss: 28.8730\n",
      "Epoch [11/25], Train Loss: 863.2282, Eval Loss: 28.8621\n",
      "Epoch [12/25], Train Loss: 862.4164, Eval Loss: 28.8503\n",
      "Epoch [13/25], Train Loss: 861.5759, Eval Loss: 28.8340\n",
      "Epoch [14/25], Train Loss: 860.6193, Eval Loss: 28.8236\n",
      "Epoch [15/25], Train Loss: 859.8100, Eval Loss: 28.8133\n",
      "Epoch [16/25], Train Loss: 858.8425, Eval Loss: 28.7910\n",
      "Epoch [17/25], Train Loss: 857.7983, Eval Loss: 28.7699\n",
      "Epoch [18/25], Train Loss: 856.7056, Eval Loss: 28.7549\n",
      "Epoch [19/25], Train Loss: 855.6801, Eval Loss: 28.7358\n",
      "Epoch [20/25], Train Loss: 854.5678, Eval Loss: 28.7136\n",
      "Epoch [21/25], Train Loss: 853.4027, Eval Loss: 28.6918\n",
      "Epoch [22/25], Train Loss: 852.2227, Eval Loss: 28.6683\n",
      "Epoch [23/25], Train Loss: 851.0102, Eval Loss: 28.6490\n",
      "Epoch [24/25], Train Loss: 849.8454, Eval Loss: 28.6262\n",
      "Epoch [25/25], Train Loss: 848.5276, Eval Loss: 28.6002\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8482.1271, Eval Loss: 86.2134\n",
      "Epoch [2/25], Train Loss: 7130.4931, Eval Loss: 79.5559\n",
      "Epoch [3/25], Train Loss: 6122.0688, Eval Loss: 73.7066\n",
      "Epoch [4/25], Train Loss: 5284.1428, Eval Loss: 68.4099\n",
      "Epoch [5/25], Train Loss: 4575.9223, Eval Loss: 63.5908\n",
      "Epoch [6/25], Train Loss: 3975.2085, Eval Loss: 59.2109\n",
      "Epoch [7/25], Train Loss: 3465.6249, Eval Loss: 55.2432\n",
      "Epoch [8/25], Train Loss: 3033.7884, Eval Loss: 51.6644\n",
      "Epoch [9/25], Train Loss: 2668.3852, Eval Loss: 48.4532\n",
      "Epoch [10/25], Train Loss: 2359.7569, Eval Loss: 45.5893\n",
      "Epoch [11/25], Train Loss: 2099.6353, Eval Loss: 43.0522\n",
      "Epoch [12/25], Train Loss: 1880.9283, Eval Loss: 40.8209\n",
      "Epoch [13/25], Train Loss: 1697.5368, Eval Loss: 38.8735\n",
      "Epoch [14/25], Train Loss: 1544.2024, Eval Loss: 37.1868\n",
      "Epoch [15/25], Train Loss: 1416.3864, Eval Loss: 35.7370\n",
      "Epoch [16/25], Train Loss: 1310.1756, Eval Loss: 34.4998\n",
      "Epoch [17/25], Train Loss: 1222.2052, Eval Loss: 33.4517\n",
      "Epoch [18/25], Train Loss: 1149.5947, Eval Loss: 32.5700\n",
      "Epoch [19/25], Train Loss: 1089.8884, Eval Loss: 31.8337\n",
      "Epoch [20/25], Train Loss: 1041.0002, Eval Loss: 31.2234\n",
      "Epoch [21/25], Train Loss: 1001.1622, Eval Loss: 30.7217\n",
      "Epoch [22/25], Train Loss: 968.8770, Eval Loss: 30.3128\n",
      "Epoch [23/25], Train Loss: 942.8767, Eval Loss: 29.9827\n",
      "Epoch [24/25], Train Loss: 922.0861, Eval Loss: 29.7190\n",
      "Epoch [25/25], Train Loss: 905.5932, Eval Loss: 29.5107\n",
      "Epoch [1/25], Train Loss: 8499.9005, Eval Loss: 86.3267\n",
      "Epoch [2/25], Train Loss: 7149.6431, Eval Loss: 79.6739\n",
      "Epoch [3/25], Train Loss: 6140.3120, Eval Loss: 73.8278\n",
      "Epoch [4/25], Train Loss: 5301.3800, Eval Loss: 68.5332\n",
      "Epoch [5/25], Train Loss: 4592.0223, Eval Loss: 63.7144\n",
      "Epoch [6/25], Train Loss: 3990.0079, Eval Loss: 59.3325\n",
      "Epoch [7/25], Train Loss: 3478.9609, Eval Loss: 55.3600\n",
      "Epoch [8/25], Train Loss: 3045.5345, Eval Loss: 51.7739\n",
      "Epoch [9/25], Train Loss: 2678.4781, Eval Loss: 48.5531\n",
      "Epoch [10/25], Train Loss: 2368.2090, Eval Loss: 45.6777\n",
      "Epoch [11/25], Train Loss: 2106.5319, Eval Loss: 43.1282\n",
      "Epoch [12/25], Train Loss: 1886.4127, Eval Loss: 40.8844\n",
      "Epoch [13/25], Train Loss: 1701.7890, Eval Loss: 38.9249\n",
      "Epoch [14/25], Train Loss: 1547.4178, Eval Loss: 37.2273\n",
      "Epoch [15/25], Train Loss: 1418.7580, Eval Loss: 35.7678\n",
      "Epoch [16/25], Train Loss: 1311.8811, Eval Loss: 34.5227\n",
      "Epoch [17/25], Train Loss: 1223.4001, Eval Loss: 33.4681\n",
      "Epoch [18/25], Train Loss: 1150.4093, Eval Loss: 32.5814\n",
      "Epoch [19/25], Train Loss: 1090.4274, Eval Loss: 31.8413\n",
      "Epoch [20/25], Train Loss: 1041.3453, Eval Loss: 31.2284\n",
      "Epoch [21/25], Train Loss: 1001.3747, Eval Loss: 30.7248\n",
      "Epoch [22/25], Train Loss: 969.0019, Eval Loss: 30.3146\n",
      "Epoch [23/25], Train Loss: 942.9456, Eval Loss: 29.9837\n",
      "Epoch [24/25], Train Loss: 922.1206, Eval Loss: 29.7195\n",
      "Epoch [25/25], Train Loss: 905.6078, Eval Loss: 29.5109\n",
      "Epoch [1/25], Train Loss: 2498.1774, Eval Loss: 29.0149\n",
      "Epoch [2/25], Train Loss: 857.5667, Eval Loss: 28.9105\n",
      "Epoch [3/25], Train Loss: 856.3825, Eval Loss: 28.9110\n",
      "Epoch [4/25], Train Loss: 856.3751, Eval Loss: 28.9109\n",
      "Epoch [5/25], Train Loss: 856.3688, Eval Loss: 28.9108\n",
      "Epoch [6/25], Train Loss: 856.3625, Eval Loss: 28.9107\n",
      "Epoch [7/25], Train Loss: 856.3559, Eval Loss: 28.9105\n",
      "Epoch [8/25], Train Loss: 856.3489, Eval Loss: 28.9104\n",
      "Epoch [9/25], Train Loss: 856.3412, Eval Loss: 28.9102\n",
      "Epoch [10/25], Train Loss: 856.3327, Eval Loss: 28.9101\n",
      "Epoch [11/25], Train Loss: 856.3226, Eval Loss: 28.9099\n",
      "Epoch [12/25], Train Loss: 856.3103, Eval Loss: 28.9096\n",
      "Epoch [13/25], Train Loss: 856.2936, Eval Loss: 28.9091\n",
      "Epoch [14/25], Train Loss: 856.2669, Eval Loss: 28.9082\n",
      "Epoch [15/25], Train Loss: 856.2124, Eval Loss: 28.9029\n",
      "Epoch [16/25], Train Loss: 855.9923, Eval Loss: 28.8964\n",
      "Epoch [17/25], Train Loss: 855.6656, Eval Loss: 28.8926\n",
      "Epoch [18/25], Train Loss: 854.8732, Eval Loss: 28.8535\n",
      "Epoch [19/25], Train Loss: 853.8175, Eval Loss: 28.8176\n",
      "Epoch [20/25], Train Loss: 851.0436, Eval Loss: 28.7461\n",
      "Epoch [21/25], Train Loss: 845.6622, Eval Loss: 28.4832\n",
      "Epoch [22/25], Train Loss: 834.9738, Eval Loss: 28.0625\n",
      "Epoch [23/25], Train Loss: 817.7834, Eval Loss: 28.3619\n",
      "Epoch [24/25], Train Loss: 819.9391, Eval Loss: 27.2873\n",
      "Epoch [25/25], Train Loss: 775.8318, Eval Loss: 26.4057\n",
      "Epoch [1/25], Train Loss: 2466.8242, Eval Loss: 29.0118\n",
      "Epoch [2/25], Train Loss: 857.5434, Eval Loss: 28.9106\n",
      "Epoch [3/25], Train Loss: 856.3862, Eval Loss: 28.9111\n",
      "Epoch [4/25], Train Loss: 856.3789, Eval Loss: 28.9110\n",
      "Epoch [5/25], Train Loss: 856.3728, Eval Loss: 28.9109\n",
      "Epoch [6/25], Train Loss: 856.3665, Eval Loss: 28.9108\n",
      "Epoch [7/25], Train Loss: 856.3599, Eval Loss: 28.9106\n",
      "Epoch [8/25], Train Loss: 856.3528, Eval Loss: 28.9105\n",
      "Epoch [9/25], Train Loss: 856.3450, Eval Loss: 28.9103\n",
      "Epoch [10/25], Train Loss: 856.3360, Eval Loss: 28.9101\n",
      "Epoch [11/25], Train Loss: 856.3252, Eval Loss: 28.9099\n",
      "Epoch [12/25], Train Loss: 856.3111, Eval Loss: 28.9096\n",
      "Epoch [13/25], Train Loss: 856.2898, Eval Loss: 28.9089\n",
      "Epoch [14/25], Train Loss: 856.2455, Eval Loss: 28.9067\n",
      "Epoch [15/25], Train Loss: 856.0679, Eval Loss: 28.8972\n",
      "Epoch [16/25], Train Loss: 855.8899, Eval Loss: 28.8931\n",
      "Epoch [17/25], Train Loss: 854.8459, Eval Loss: 28.8372\n",
      "Epoch [18/25], Train Loss: 853.5399, Eval Loss: 28.8109\n",
      "Epoch [19/25], Train Loss: 848.5183, Eval Loss: 28.6361\n",
      "Epoch [20/25], Train Loss: 841.8193, Eval Loss: 28.3805\n",
      "Epoch [21/25], Train Loss: 825.9871, Eval Loss: 27.8112\n",
      "Epoch [22/25], Train Loss: 802.4876, Eval Loss: 27.2174\n",
      "Epoch [23/25], Train Loss: 782.4116, Eval Loss: 28.3582\n",
      "Epoch [24/25], Train Loss: 785.6157, Eval Loss: 26.3373\n",
      "Epoch [25/25], Train Loss: 734.0053, Eval Loss: 25.4068\n",
      "Epoch [1/25], Train Loss: 1907.5394, Eval Loss: 29.2107\n",
      "Epoch [2/25], Train Loss: 943.2235, Eval Loss: 29.6291\n",
      "Epoch [3/25], Train Loss: 940.0948, Eval Loss: 29.1732\n",
      "Epoch [4/25], Train Loss: 941.2909, Eval Loss: 30.7767\n",
      "Epoch [5/25], Train Loss: 952.4670, Eval Loss: 30.9737\n",
      "Epoch [6/25], Train Loss: 939.8069, Eval Loss: 30.2473\n",
      "Epoch [7/25], Train Loss: 933.8088, Eval Loss: 29.9934\n",
      "Epoch [8/25], Train Loss: 919.3384, Eval Loss: 29.7448\n",
      "Epoch [9/25], Train Loss: 908.6145, Eval Loss: 29.4701\n",
      "Epoch [10/25], Train Loss: 895.6173, Eval Loss: 29.0931\n",
      "Epoch [11/25], Train Loss: 880.9650, Eval Loss: 29.1449\n",
      "Epoch [12/25], Train Loss: 865.7489, Eval Loss: 28.8535\n",
      "Epoch [13/25], Train Loss: 846.7066, Eval Loss: 27.7083\n",
      "Epoch [14/25], Train Loss: 818.4368, Eval Loss: 27.2061\n",
      "Epoch [15/25], Train Loss: 791.7883, Eval Loss: 26.9331\n",
      "Epoch [16/25], Train Loss: 777.0917, Eval Loss: 25.8912\n",
      "Epoch [17/25], Train Loss: 744.7971, Eval Loss: 25.4304\n",
      "Epoch [18/25], Train Loss: 728.5936, Eval Loss: 24.7980\n",
      "Epoch [19/25], Train Loss: 687.4153, Eval Loss: 24.4324\n",
      "Epoch [20/25], Train Loss: 696.1671, Eval Loss: 24.4320\n",
      "Epoch [21/25], Train Loss: 688.4516, Eval Loss: 24.2919\n",
      "Epoch [22/25], Train Loss: 671.8119, Eval Loss: 23.9080\n",
      "Epoch [23/25], Train Loss: 665.4530, Eval Loss: 23.3548\n",
      "Epoch [24/25], Train Loss: 629.0553, Eval Loss: 23.6387\n",
      "Epoch [25/25], Train Loss: 612.7820, Eval Loss: 22.8764\n",
      "Epoch [1/25], Train Loss: 2051.6809, Eval Loss: 29.6309\n",
      "Epoch [2/25], Train Loss: 938.5849, Eval Loss: 30.4200\n",
      "Epoch [3/25], Train Loss: 950.1848, Eval Loss: 29.2748\n",
      "Epoch [4/25], Train Loss: 947.2817, Eval Loss: 29.0580\n",
      "Epoch [5/25], Train Loss: 939.0135, Eval Loss: 29.4406\n",
      "Epoch [6/25], Train Loss: 933.9833, Eval Loss: 29.9278\n",
      "Epoch [7/25], Train Loss: 924.9669, Eval Loss: 29.9120\n",
      "Epoch [8/25], Train Loss: 917.3446, Eval Loss: 30.4496\n",
      "Epoch [9/25], Train Loss: 917.2380, Eval Loss: 29.0217\n",
      "Epoch [10/25], Train Loss: 894.8562, Eval Loss: 28.7062\n",
      "Epoch [11/25], Train Loss: 881.4174, Eval Loss: 28.3805\n",
      "Epoch [12/25], Train Loss: 865.7512, Eval Loss: 28.7159\n",
      "Epoch [13/25], Train Loss: 854.7838, Eval Loss: 27.5264\n",
      "Epoch [14/25], Train Loss: 830.1351, Eval Loss: 27.7700\n",
      "Epoch [15/25], Train Loss: 807.9598, Eval Loss: 26.5243\n",
      "Epoch [16/25], Train Loss: 781.9491, Eval Loss: 25.9649\n",
      "Epoch [17/25], Train Loss: 760.9848, Eval Loss: 25.4728\n",
      "Epoch [18/25], Train Loss: 725.6663, Eval Loss: 24.6126\n",
      "Epoch [19/25], Train Loss: 693.3516, Eval Loss: 23.8510\n",
      "Epoch [20/25], Train Loss: 651.9944, Eval Loss: 23.3405\n",
      "Epoch [21/25], Train Loss: 597.0177, Eval Loss: 22.7521\n",
      "Epoch [22/25], Train Loss: 532.3695, Eval Loss: 19.5588\n",
      "Epoch [23/25], Train Loss: 491.4549, Eval Loss: 18.3635\n",
      "Epoch [24/25], Train Loss: 422.6349, Eval Loss: 17.3269\n",
      "Epoch [25/25], Train Loss: 344.4556, Eval Loss: 16.7222\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 4936.6182, Eval Loss: 44.9809\n",
      "Epoch [2/25], Train Loss: 1410.6771, Eval Loss: 31.0162\n",
      "Epoch [3/25], Train Loss: 909.3515, Eval Loss: 29.0246\n",
      "Epoch [4/25], Train Loss: 857.0749, Eval Loss: 28.9013\n",
      "Epoch [5/25], Train Loss: 854.4225, Eval Loss: 28.9049\n",
      "Epoch [6/25], Train Loss: 854.5959, Eval Loss: 28.9061\n",
      "Epoch [7/25], Train Loss: 854.7533, Eval Loss: 28.9061\n",
      "Epoch [8/25], Train Loss: 854.8792, Eval Loss: 28.9060\n",
      "Epoch [9/25], Train Loss: 854.9900, Eval Loss: 28.9059\n",
      "Epoch [10/25], Train Loss: 855.0899, Eval Loss: 28.9057\n",
      "Epoch [11/25], Train Loss: 855.1807, Eval Loss: 28.9055\n",
      "Epoch [12/25], Train Loss: 855.2638, Eval Loss: 28.9052\n",
      "Epoch [13/25], Train Loss: 855.3403, Eval Loss: 28.9048\n",
      "Epoch [14/25], Train Loss: 855.4108, Eval Loss: 28.9044\n",
      "Epoch [15/25], Train Loss: 855.4761, Eval Loss: 28.9039\n",
      "Epoch [16/25], Train Loss: 855.5367, Eval Loss: 28.9035\n",
      "Epoch [17/25], Train Loss: 855.5930, Eval Loss: 28.9029\n",
      "Epoch [18/25], Train Loss: 855.6455, Eval Loss: 28.9024\n",
      "Epoch [19/25], Train Loss: 855.6944, Eval Loss: 28.9018\n",
      "Epoch [20/25], Train Loss: 855.7400, Eval Loss: 28.9013\n",
      "Epoch [21/25], Train Loss: 855.7827, Eval Loss: 28.9007\n",
      "Epoch [22/25], Train Loss: 855.8225, Eval Loss: 28.9001\n",
      "Epoch [23/25], Train Loss: 855.8598, Eval Loss: 28.8995\n",
      "Epoch [24/25], Train Loss: 855.8946, Eval Loss: 28.8989\n",
      "Epoch [25/25], Train Loss: 855.9271, Eval Loss: 28.8983\n",
      "Epoch [1/25], Train Loss: 4913.9637, Eval Loss: 44.9850\n",
      "Epoch [2/25], Train Loss: 1411.0001, Eval Loss: 31.0116\n",
      "Epoch [3/25], Train Loss: 909.3188, Eval Loss: 29.0242\n",
      "Epoch [4/25], Train Loss: 857.0704, Eval Loss: 28.9010\n",
      "Epoch [5/25], Train Loss: 854.4086, Eval Loss: 28.9046\n",
      "Epoch [6/25], Train Loss: 854.5794, Eval Loss: 28.9059\n",
      "Epoch [7/25], Train Loss: 854.7359, Eval Loss: 28.9061\n",
      "Epoch [8/25], Train Loss: 854.8616, Eval Loss: 28.9061\n",
      "Epoch [9/25], Train Loss: 854.9730, Eval Loss: 28.9060\n",
      "Epoch [10/25], Train Loss: 855.0737, Eval Loss: 28.9059\n",
      "Epoch [11/25], Train Loss: 855.1657, Eval Loss: 28.9056\n",
      "Epoch [12/25], Train Loss: 855.2501, Eval Loss: 28.9054\n",
      "Epoch [13/25], Train Loss: 855.3279, Eval Loss: 28.9050\n",
      "Epoch [14/25], Train Loss: 855.3997, Eval Loss: 28.9046\n",
      "Epoch [15/25], Train Loss: 855.4663, Eval Loss: 28.9042\n",
      "Epoch [16/25], Train Loss: 855.5281, Eval Loss: 28.9037\n",
      "Epoch [17/25], Train Loss: 855.5855, Eval Loss: 28.9031\n",
      "Epoch [18/25], Train Loss: 855.6390, Eval Loss: 28.9026\n",
      "Epoch [19/25], Train Loss: 855.6888, Eval Loss: 28.9020\n",
      "Epoch [20/25], Train Loss: 855.7352, Eval Loss: 28.9014\n",
      "Epoch [21/25], Train Loss: 855.7786, Eval Loss: 28.9008\n",
      "Epoch [22/25], Train Loss: 855.8191, Eval Loss: 28.9002\n",
      "Epoch [23/25], Train Loss: 855.8568, Eval Loss: 28.8996\n",
      "Epoch [24/25], Train Loss: 855.8921, Eval Loss: 28.8990\n",
      "Epoch [25/25], Train Loss: 855.9250, Eval Loss: 28.8984\n",
      "Epoch [1/25], Train Loss: 1208.8004, Eval Loss: 29.9790\n",
      "Epoch [2/25], Train Loss: 886.0268, Eval Loss: 29.9786\n",
      "Epoch [3/25], Train Loss: 885.8193, Eval Loss: 29.9786\n",
      "Epoch [4/25], Train Loss: 886.1817, Eval Loss: 29.9860\n",
      "Epoch [5/25], Train Loss: 885.6520, Eval Loss: 29.9831\n",
      "Epoch [6/25], Train Loss: 885.4581, Eval Loss: 29.9651\n",
      "Epoch [7/25], Train Loss: 885.6036, Eval Loss: 29.9594\n",
      "Epoch [8/25], Train Loss: 885.5550, Eval Loss: 29.8817\n",
      "Epoch [9/25], Train Loss: 880.7115, Eval Loss: 29.9785\n",
      "Epoch [10/25], Train Loss: 885.9692, Eval Loss: 29.9784\n",
      "Epoch [11/25], Train Loss: 886.0982, Eval Loss: 29.9789\n",
      "Epoch [12/25], Train Loss: 885.0540, Eval Loss: 29.9681\n",
      "Epoch [13/25], Train Loss: 885.8080, Eval Loss: 29.9779\n",
      "Epoch [14/25], Train Loss: 885.9478, Eval Loss: 29.9789\n",
      "Epoch [15/25], Train Loss: 886.5986, Eval Loss: 29.9809\n",
      "Epoch [16/25], Train Loss: 886.3511, Eval Loss: 29.9801\n",
      "Epoch [17/25], Train Loss: 885.8911, Eval Loss: 29.9802\n",
      "Epoch [18/25], Train Loss: 885.8788, Eval Loss: 29.9760\n",
      "Epoch [19/25], Train Loss: 882.0265, Eval Loss: 29.9799\n",
      "Epoch [20/25], Train Loss: 885.9760, Eval Loss: 29.9793\n",
      "Epoch [21/25], Train Loss: 886.0484, Eval Loss: 29.9806\n",
      "Epoch [22/25], Train Loss: 886.3584, Eval Loss: 29.9805\n",
      "Epoch [23/25], Train Loss: 886.0111, Eval Loss: 29.9807\n",
      "Epoch [24/25], Train Loss: 885.8983, Eval Loss: 29.9807\n",
      "Epoch [25/25], Train Loss: 885.8942, Eval Loss: 29.9805\n",
      "Epoch [1/25], Train Loss: 1241.4908, Eval Loss: 29.9808\n",
      "Epoch [2/25], Train Loss: 885.8966, Eval Loss: 29.9802\n",
      "Epoch [3/25], Train Loss: 885.9726, Eval Loss: 29.9797\n",
      "Epoch [4/25], Train Loss: 885.8814, Eval Loss: 29.9765\n",
      "Epoch [5/25], Train Loss: 885.6499, Eval Loss: 29.9804\n",
      "Epoch [6/25], Train Loss: 885.8011, Eval Loss: 29.9797\n",
      "Epoch [7/25], Train Loss: 885.9890, Eval Loss: 29.9802\n",
      "Epoch [8/25], Train Loss: 885.8934, Eval Loss: 29.9799\n",
      "Epoch [9/25], Train Loss: 885.9153, Eval Loss: 29.9801\n",
      "Epoch [10/25], Train Loss: 886.2632, Eval Loss: 29.9902\n",
      "Epoch [11/25], Train Loss: 886.2578, Eval Loss: 29.9803\n",
      "Epoch [12/25], Train Loss: 885.9308, Eval Loss: 29.9800\n",
      "Epoch [13/25], Train Loss: 885.9024, Eval Loss: 29.9802\n",
      "Epoch [14/25], Train Loss: 885.8937, Eval Loss: 29.9806\n",
      "Epoch [15/25], Train Loss: 885.8921, Eval Loss: 29.9806\n",
      "Epoch [16/25], Train Loss: 885.8886, Eval Loss: 29.9779\n",
      "Epoch [17/25], Train Loss: 885.7971, Eval Loss: 29.9800\n",
      "Epoch [18/25], Train Loss: 885.5629, Eval Loss: 29.9799\n",
      "Epoch [19/25], Train Loss: 886.0410, Eval Loss: 29.9782\n",
      "Epoch [20/25], Train Loss: 885.9292, Eval Loss: 29.9808\n",
      "Epoch [21/25], Train Loss: 885.8919, Eval Loss: 29.9806\n",
      "Epoch [22/25], Train Loss: 885.8902, Eval Loss: 29.9803\n",
      "Epoch [23/25], Train Loss: 885.8830, Eval Loss: 29.9794\n",
      "Epoch [24/25], Train Loss: 885.4310, Eval Loss: 29.9803\n",
      "Epoch [25/25], Train Loss: 886.0038, Eval Loss: 29.9803\n",
      "Epoch [1/25], Train Loss: 8768.5131, Eval Loss: 83.2554\n",
      "Epoch [2/25], Train Loss: 2802.5336, Eval Loss: 29.0371\n",
      "Epoch [3/25], Train Loss: 858.7529, Eval Loss: 28.8961\n",
      "Epoch [4/25], Train Loss: 855.9327, Eval Loss: 28.9011\n",
      "Epoch [5/25], Train Loss: 856.0955, Eval Loss: 28.9039\n",
      "Epoch [6/25], Train Loss: 856.1683, Eval Loss: 28.9072\n",
      "Epoch [7/25], Train Loss: 856.2049, Eval Loss: 28.9107\n",
      "Epoch [8/25], Train Loss: 856.2117, Eval Loss: 28.9142\n",
      "Epoch [9/25], Train Loss: 856.1949, Eval Loss: 28.9175\n",
      "Epoch [10/25], Train Loss: 856.1605, Eval Loss: 28.9206\n",
      "Epoch [11/25], Train Loss: 856.1198, Eval Loss: 28.9235\n",
      "Epoch [12/25], Train Loss: 856.0457, Eval Loss: 28.9260\n",
      "Epoch [13/25], Train Loss: 855.9669, Eval Loss: 28.9311\n",
      "Epoch [14/25], Train Loss: 855.8661, Eval Loss: 28.9329\n",
      "Epoch [15/25], Train Loss: 855.8131, Eval Loss: 28.9339\n",
      "Epoch [16/25], Train Loss: 855.7257, Eval Loss: 28.9347\n",
      "Epoch [17/25], Train Loss: 855.6269, Eval Loss: 28.9356\n",
      "Epoch [18/25], Train Loss: 855.5502, Eval Loss: 28.9364\n",
      "Epoch [19/25], Train Loss: 855.4251, Eval Loss: 28.9366\n",
      "Epoch [20/25], Train Loss: 855.3401, Eval Loss: 28.9367\n",
      "Epoch [21/25], Train Loss: 855.2362, Eval Loss: 28.9367\n",
      "Epoch [22/25], Train Loss: 855.1633, Eval Loss: 28.9372\n",
      "Epoch [23/25], Train Loss: 854.9817, Eval Loss: 28.9362\n",
      "Epoch [24/25], Train Loss: 854.9179, Eval Loss: 28.9356\n",
      "Epoch [25/25], Train Loss: 854.8090, Eval Loss: 28.9350\n",
      "Epoch [1/25], Train Loss: 8646.7422, Eval Loss: 80.5527\n",
      "Epoch [2/25], Train Loss: 2515.8684, Eval Loss: 29.2136\n",
      "Epoch [3/25], Train Loss: 860.4410, Eval Loss: 28.9000\n",
      "Epoch [4/25], Train Loss: 857.2814, Eval Loss: 28.9033\n",
      "Epoch [5/25], Train Loss: 857.3500, Eval Loss: 28.9073\n",
      "Epoch [6/25], Train Loss: 857.4053, Eval Loss: 28.9121\n",
      "Epoch [7/25], Train Loss: 857.4299, Eval Loss: 28.9168\n",
      "Epoch [8/25], Train Loss: 857.4062, Eval Loss: 28.9217\n",
      "Epoch [9/25], Train Loss: 857.3679, Eval Loss: 28.9264\n",
      "Epoch [10/25], Train Loss: 857.3311, Eval Loss: 28.9296\n",
      "Epoch [11/25], Train Loss: 857.2904, Eval Loss: 28.9331\n",
      "Epoch [12/25], Train Loss: 857.2376, Eval Loss: 28.9358\n",
      "Epoch [13/25], Train Loss: 857.1859, Eval Loss: 28.9396\n",
      "Epoch [14/25], Train Loss: 857.1210, Eval Loss: 28.9406\n",
      "Epoch [15/25], Train Loss: 857.0440, Eval Loss: 28.9445\n",
      "Epoch [16/25], Train Loss: 856.9837, Eval Loss: 28.9446\n",
      "Epoch [17/25], Train Loss: 856.9206, Eval Loss: 28.9451\n",
      "Epoch [18/25], Train Loss: 856.8779, Eval Loss: 28.9524\n",
      "Epoch [19/25], Train Loss: 856.8174, Eval Loss: 28.9465\n",
      "Epoch [20/25], Train Loss: 856.7197, Eval Loss: 28.9469\n",
      "Epoch [21/25], Train Loss: 856.6453, Eval Loss: 28.9472\n",
      "Epoch [22/25], Train Loss: 856.5773, Eval Loss: 28.9473\n",
      "Epoch [23/25], Train Loss: 856.4999, Eval Loss: 28.9474\n",
      "Epoch [24/25], Train Loss: 856.4324, Eval Loss: 28.9472\n",
      "Epoch [25/25], Train Loss: 856.3652, Eval Loss: 28.9465\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9215.2638, Eval Loss: 93.5833\n",
      "Epoch [2/25], Train Loss: 8898.7125, Eval Loss: 92.1023\n",
      "Epoch [3/25], Train Loss: 8669.5330, Eval Loss: 91.0716\n",
      "Epoch [4/25], Train Loss: 8498.6945, Eval Loss: 90.2316\n",
      "Epoch [5/25], Train Loss: 8353.2853, Eval Loss: 89.4729\n",
      "Epoch [6/25], Train Loss: 8219.6457, Eval Loss: 88.7554\n",
      "Epoch [7/25], Train Loss: 8092.9298, Eval Loss: 88.0637\n",
      "Epoch [8/25], Train Loss: 7971.0373, Eval Loss: 87.3900\n",
      "Epoch [9/25], Train Loss: 7852.8595, Eval Loss: 86.7301\n",
      "Epoch [10/25], Train Loss: 7737.7334, Eval Loss: 86.0813\n",
      "Epoch [11/25], Train Loss: 7625.2260, Eval Loss: 85.4418\n",
      "Epoch [12/25], Train Loss: 7515.0374, Eval Loss: 84.8104\n",
      "Epoch [13/25], Train Loss: 7406.9486, Eval Loss: 84.1861\n",
      "Epoch [14/25], Train Loss: 7300.7936, Eval Loss: 83.5681\n",
      "Epoch [15/25], Train Loss: 7196.4425, Eval Loss: 82.9561\n",
      "Epoch [16/25], Train Loss: 7093.7913, Eval Loss: 82.3495\n",
      "Epoch [17/25], Train Loss: 6992.7541, Eval Loss: 81.7480\n",
      "Epoch [18/25], Train Loss: 6893.2590, Eval Loss: 81.1513\n",
      "Epoch [19/25], Train Loss: 6795.2452, Eval Loss: 80.5591\n",
      "Epoch [20/25], Train Loss: 6698.6596, Eval Loss: 79.9713\n",
      "Epoch [21/25], Train Loss: 6603.4563, Eval Loss: 79.3877\n",
      "Epoch [22/25], Train Loss: 6509.5943, Eval Loss: 78.8081\n",
      "Epoch [23/25], Train Loss: 6417.0370, Eval Loss: 78.2325\n",
      "Epoch [24/25], Train Loss: 6325.7519, Eval Loss: 77.6606\n",
      "Epoch [25/25], Train Loss: 6235.7088, Eval Loss: 77.0924\n",
      "Epoch [1/25], Train Loss: 9220.4070, Eval Loss: 93.5545\n",
      "Epoch [2/25], Train Loss: 8888.9438, Eval Loss: 92.0268\n",
      "Epoch [3/25], Train Loss: 8656.8628, Eval Loss: 91.0116\n",
      "Epoch [4/25], Train Loss: 8489.7582, Eval Loss: 90.1856\n",
      "Epoch [5/25], Train Loss: 8346.2902, Eval Loss: 89.4342\n",
      "Epoch [6/25], Train Loss: 8213.7794, Eval Loss: 88.7215\n",
      "Epoch [7/25], Train Loss: 8087.8415, Eval Loss: 88.0332\n",
      "Epoch [8/25], Train Loss: 7966.5309, Eval Loss: 87.3621\n",
      "Epoch [9/25], Train Loss: 7848.8107, Eval Loss: 86.7043\n",
      "Epoch [10/25], Train Loss: 7734.0558, Eval Loss: 86.0573\n",
      "Epoch [11/25], Train Loss: 7621.8576, Eval Loss: 85.4192\n",
      "Epoch [12/25], Train Loss: 7511.9311, Eval Loss: 84.7890\n",
      "Epoch [13/25], Train Loss: 7404.0674, Eval Loss: 84.1657\n",
      "Epoch [14/25], Train Loss: 7298.1084, Eval Loss: 83.5487\n",
      "Epoch [15/25], Train Loss: 7193.9295, Eval Loss: 82.9375\n",
      "Epoch [16/25], Train Loss: 7091.4307, Eval Loss: 82.3316\n",
      "Epoch [17/25], Train Loss: 6990.5296, Eval Loss: 81.7307\n",
      "Epoch [18/25], Train Loss: 6891.1566, Eval Loss: 81.1346\n",
      "Epoch [19/25], Train Loss: 6793.2531, Eval Loss: 80.5429\n",
      "Epoch [20/25], Train Loss: 6696.7674, Eval Loss: 79.9556\n",
      "Epoch [21/25], Train Loss: 6601.6553, Eval Loss: 79.3724\n",
      "Epoch [22/25], Train Loss: 6507.8765, Eval Loss: 78.7932\n",
      "Epoch [23/25], Train Loss: 6415.3956, Eval Loss: 78.2179\n",
      "Epoch [24/25], Train Loss: 6324.1808, Eval Loss: 77.6464\n",
      "Epoch [25/25], Train Loss: 6234.2026, Eval Loss: 77.0785\n",
      "Epoch [1/25], Train Loss: 8003.7606, Eval Loss: 76.3893\n",
      "Epoch [2/25], Train Loss: 4600.0587, Eval Loss: 56.8214\n",
      "Epoch [3/25], Train Loss: 2681.7523, Eval Loss: 44.4096\n",
      "Epoch [4/25], Train Loss: 1745.4177, Eval Loss: 37.0439\n",
      "Epoch [5/25], Train Loss: 1288.3471, Eval Loss: 32.9757\n",
      "Epoch [6/25], Train Loss: 1065.3020, Eval Loss: 30.8622\n",
      "Epoch [7/25], Train Loss: 956.5162, Eval Loss: 29.8116\n",
      "Epoch [8/25], Train Loss: 903.4812, Eval Loss: 29.3057\n",
      "Epoch [9/25], Train Loss: 877.6330, Eval Loss: 29.0689\n",
      "Epoch [10/25], Train Loss: 865.0371, Eval Loss: 28.9616\n",
      "Epoch [11/25], Train Loss: 858.8997, Eval Loss: 28.9153\n",
      "Epoch [12/25], Train Loss: 855.9093, Eval Loss: 28.8969\n",
      "Epoch [13/25], Train Loss: 854.4523, Eval Loss: 28.8910\n",
      "Epoch [14/25], Train Loss: 853.7425, Eval Loss: 28.8902\n",
      "Epoch [15/25], Train Loss: 853.3966, Eval Loss: 28.8912\n",
      "Epoch [16/25], Train Loss: 853.2281, Eval Loss: 28.8928\n",
      "Epoch [17/25], Train Loss: 853.1459, Eval Loss: 28.8942\n",
      "Epoch [18/25], Train Loss: 853.1058, Eval Loss: 28.8954\n",
      "Epoch [19/25], Train Loss: 853.0861, Eval Loss: 28.8964\n",
      "Epoch [20/25], Train Loss: 853.0765, Eval Loss: 28.8970\n",
      "Epoch [21/25], Train Loss: 853.0717, Eval Loss: 28.8976\n",
      "Epoch [22/25], Train Loss: 853.0694, Eval Loss: 28.8979\n",
      "Epoch [23/25], Train Loss: 853.0682, Eval Loss: 28.8982\n",
      "Epoch [24/25], Train Loss: 853.0676, Eval Loss: 28.8984\n",
      "Epoch [25/25], Train Loss: 853.0672, Eval Loss: 28.8985\n",
      "Epoch [1/25], Train Loss: 8007.0253, Eval Loss: 76.5308\n",
      "Epoch [2/25], Train Loss: 4621.8476, Eval Loss: 56.9523\n",
      "Epoch [3/25], Train Loss: 2693.0839, Eval Loss: 44.4889\n",
      "Epoch [4/25], Train Loss: 1750.9609, Eval Loss: 37.0888\n",
      "Epoch [5/25], Train Loss: 1291.0571, Eval Loss: 32.9997\n",
      "Epoch [6/25], Train Loss: 1066.6261, Eval Loss: 30.8743\n",
      "Epoch [7/25], Train Loss: 957.1626, Eval Loss: 29.8175\n",
      "Epoch [8/25], Train Loss: 903.7964, Eval Loss: 29.3086\n",
      "Epoch [9/25], Train Loss: 877.7861, Eval Loss: 29.0702\n",
      "Epoch [10/25], Train Loss: 865.1109, Eval Loss: 28.9621\n",
      "Epoch [11/25], Train Loss: 858.9346, Eval Loss: 28.9155\n",
      "Epoch [12/25], Train Loss: 855.9251, Eval Loss: 28.8970\n",
      "Epoch [13/25], Train Loss: 854.4588, Eval Loss: 28.8909\n",
      "Epoch [14/25], Train Loss: 853.7443, Eval Loss: 28.8901\n",
      "Epoch [15/25], Train Loss: 853.3962, Eval Loss: 28.8912\n",
      "Epoch [16/25], Train Loss: 853.2265, Eval Loss: 28.8927\n",
      "Epoch [17/25], Train Loss: 853.1438, Eval Loss: 28.8941\n",
      "Epoch [18/25], Train Loss: 853.1035, Eval Loss: 28.8953\n",
      "Epoch [19/25], Train Loss: 853.0839, Eval Loss: 28.8963\n",
      "Epoch [20/25], Train Loss: 853.0742, Eval Loss: 28.8970\n",
      "Epoch [21/25], Train Loss: 853.0695, Eval Loss: 28.8975\n",
      "Epoch [22/25], Train Loss: 853.0672, Eval Loss: 28.8978\n",
      "Epoch [23/25], Train Loss: 853.0660, Eval Loss: 28.8981\n",
      "Epoch [24/25], Train Loss: 853.0654, Eval Loss: 28.8983\n",
      "Epoch [25/25], Train Loss: 853.0651, Eval Loss: 28.8984\n",
      "Epoch [1/25], Train Loss: 2846.0345, Eval Loss: 29.5192\n",
      "Epoch [2/25], Train Loss: 874.8170, Eval Loss: 28.9483\n",
      "Epoch [3/25], Train Loss: 871.8202, Eval Loss: 28.9749\n",
      "Epoch [4/25], Train Loss: 872.0196, Eval Loss: 29.0102\n",
      "Epoch [5/25], Train Loss: 872.4028, Eval Loss: 29.0026\n",
      "Epoch [6/25], Train Loss: 872.1486, Eval Loss: 28.9778\n",
      "Epoch [7/25], Train Loss: 871.7053, Eval Loss: 28.9525\n",
      "Epoch [8/25], Train Loss: 871.0372, Eval Loss: 28.9263\n",
      "Epoch [9/25], Train Loss: 870.3286, Eval Loss: 28.9013\n",
      "Epoch [10/25], Train Loss: 869.4231, Eval Loss: 28.8803\n",
      "Epoch [11/25], Train Loss: 868.5052, Eval Loss: 28.8587\n",
      "Epoch [12/25], Train Loss: 867.3974, Eval Loss: 28.8333\n",
      "Epoch [13/25], Train Loss: 866.7383, Eval Loss: 28.8108\n",
      "Epoch [14/25], Train Loss: 865.0554, Eval Loss: 28.7792\n",
      "Epoch [15/25], Train Loss: 863.5723, Eval Loss: 28.7536\n",
      "Epoch [16/25], Train Loss: 861.9654, Eval Loss: 28.7213\n",
      "Epoch [17/25], Train Loss: 860.4017, Eval Loss: 28.6820\n",
      "Epoch [18/25], Train Loss: 858.6866, Eval Loss: 28.6461\n",
      "Epoch [19/25], Train Loss: 856.4975, Eval Loss: 28.6038\n",
      "Epoch [20/25], Train Loss: 854.1780, Eval Loss: 28.5607\n",
      "Epoch [21/25], Train Loss: 851.7884, Eval Loss: 28.5071\n",
      "Epoch [22/25], Train Loss: 849.0798, Eval Loss: 28.4471\n",
      "Epoch [23/25], Train Loss: 846.0694, Eval Loss: 28.3791\n",
      "Epoch [24/25], Train Loss: 843.8895, Eval Loss: 28.2850\n",
      "Epoch [25/25], Train Loss: 839.8869, Eval Loss: 28.2186\n",
      "Epoch [1/25], Train Loss: 2262.0753, Eval Loss: 29.1603\n",
      "Epoch [2/25], Train Loss: 878.9120, Eval Loss: 29.0141\n",
      "Epoch [3/25], Train Loss: 875.4637, Eval Loss: 29.0526\n",
      "Epoch [4/25], Train Loss: 874.8970, Eval Loss: 29.0703\n",
      "Epoch [5/25], Train Loss: 874.9839, Eval Loss: 29.0078\n",
      "Epoch [6/25], Train Loss: 873.9686, Eval Loss: 28.9700\n",
      "Epoch [7/25], Train Loss: 873.1888, Eval Loss: 28.9393\n",
      "Epoch [8/25], Train Loss: 872.3246, Eval Loss: 28.9135\n",
      "Epoch [9/25], Train Loss: 871.3021, Eval Loss: 28.8875\n",
      "Epoch [10/25], Train Loss: 870.1544, Eval Loss: 28.8601\n",
      "Epoch [11/25], Train Loss: 868.7347, Eval Loss: 28.8282\n",
      "Epoch [12/25], Train Loss: 867.1313, Eval Loss: 28.7892\n",
      "Epoch [13/25], Train Loss: 865.3273, Eval Loss: 28.7513\n",
      "Epoch [14/25], Train Loss: 863.2993, Eval Loss: 28.7049\n",
      "Epoch [15/25], Train Loss: 860.9493, Eval Loss: 28.6525\n",
      "Epoch [16/25], Train Loss: 858.2305, Eval Loss: 28.5893\n",
      "Epoch [17/25], Train Loss: 855.0069, Eval Loss: 28.5170\n",
      "Epoch [18/25], Train Loss: 851.1004, Eval Loss: 28.4018\n",
      "Epoch [19/25], Train Loss: 847.3704, Eval Loss: 28.2887\n",
      "Epoch [20/25], Train Loss: 841.3458, Eval Loss: 28.1462\n",
      "Epoch [21/25], Train Loss: 834.4991, Eval Loss: 27.9693\n",
      "Epoch [22/25], Train Loss: 826.7901, Eval Loss: 27.7580\n",
      "Epoch [23/25], Train Loss: 816.5658, Eval Loss: 27.4963\n",
      "Epoch [24/25], Train Loss: 804.1000, Eval Loss: 27.1767\n",
      "Epoch [25/25], Train Loss: 789.9455, Eval Loss: 26.8057\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8452.2539, Eval Loss: 86.5679\n",
      "Epoch [2/25], Train Loss: 7223.5254, Eval Loss: 80.2585\n",
      "Epoch [3/25], Train Loss: 6243.0394, Eval Loss: 74.5430\n",
      "Epoch [4/25], Train Loss: 5409.8771, Eval Loss: 69.3015\n",
      "Epoch [5/25], Train Loss: 4697.4975, Eval Loss: 64.4948\n",
      "Epoch [6/25], Train Loss: 4088.5210, Eval Loss: 60.1004\n",
      "Epoch [7/25], Train Loss: 3568.8544, Eval Loss: 56.1000\n",
      "Epoch [8/25], Train Loss: 3126.3586, Eval Loss: 52.4762\n",
      "Epoch [9/25], Train Loss: 2750.4261, Eval Loss: 49.2115\n",
      "Epoch [10/25], Train Loss: 2431.7906, Eval Loss: 46.2885\n",
      "Epoch [11/25], Train Loss: 2162.3866, Eval Loss: 43.6892\n",
      "Epoch [12/25], Train Loss: 1935.2132, Eval Loss: 41.3944\n",
      "Epoch [13/25], Train Loss: 1744.1977, Eval Loss: 39.3840\n",
      "Epoch [14/25], Train Loss: 1584.0721, Eval Loss: 37.6365\n",
      "Epoch [15/25], Train Loss: 1450.2651, Eval Loss: 36.1291\n",
      "Epoch [16/25], Train Loss: 1338.8158, Eval Loss: 34.8386\n",
      "Epoch [17/25], Train Loss: 1246.3016, Eval Loss: 33.7420\n",
      "Epoch [18/25], Train Loss: 1169.7765, Eval Loss: 32.8168\n",
      "Epoch [19/25], Train Loss: 1106.7166, Eval Loss: 32.0419\n",
      "Epoch [20/25], Train Loss: 1054.9680, Eval Loss: 31.3978\n",
      "Epoch [21/25], Train Loss: 1012.6990, Eval Loss: 30.8666\n",
      "Epoch [22/25], Train Loss: 978.3542, Eval Loss: 30.4322\n",
      "Epoch [23/25], Train Loss: 950.6139, Eval Loss: 30.0802\n",
      "Epoch [24/25], Train Loss: 928.3586, Eval Loss: 29.7978\n",
      "Epoch [25/25], Train Loss: 910.6382, Eval Loss: 29.5737\n",
      "Epoch [1/25], Train Loss: 8463.2530, Eval Loss: 86.6480\n",
      "Epoch [2/25], Train Loss: 7239.0911, Eval Loss: 80.3467\n",
      "Epoch [3/25], Train Loss: 6259.1448, Eval Loss: 74.6420\n",
      "Epoch [4/25], Train Loss: 5426.5444, Eval Loss: 69.4113\n",
      "Epoch [5/25], Train Loss: 4714.5222, Eval Loss: 64.6144\n",
      "Epoch [6/25], Train Loss: 4105.6228, Eval Loss: 60.2282\n",
      "Epoch [7/25], Train Loss: 3585.7273, Eval Loss: 56.2336\n",
      "Epoch [8/25], Train Loss: 3142.7066, Eval Loss: 52.6129\n",
      "Epoch [9/25], Train Loss: 2765.9924, Eval Loss: 49.3486\n",
      "Epoch [10/25], Train Loss: 2446.3759, Eval Loss: 46.4234\n",
      "Epoch [11/25], Train Loss: 2175.8572, Eval Loss: 43.8195\n",
      "Epoch [12/25], Train Loss: 1947.4975, Eval Loss: 41.5183\n",
      "Epoch [13/25], Train Loss: 1755.2772, Eval Loss: 39.5002\n",
      "Epoch [14/25], Train Loss: 1593.9679, Eval Loss: 37.7440\n",
      "Epoch [15/25], Train Loss: 1459.0263, Eval Loss: 36.2274\n",
      "Epoch [16/25], Train Loss: 1346.5093, Eval Loss: 34.9274\n",
      "Epoch [17/25], Train Loss: 1253.0041, Eval Loss: 33.8213\n",
      "Epoch [18/25], Train Loss: 1175.5700, Eval Loss: 32.8868\n",
      "Epoch [19/25], Train Loss: 1111.6848, Eval Loss: 32.1031\n",
      "Epoch [20/25], Train Loss: 1059.1939, Eval Loss: 31.4505\n",
      "Epoch [21/25], Train Loss: 1016.2633, Eval Loss: 30.9115\n",
      "Epoch [22/25], Train Loss: 981.3339, Eval Loss: 30.4700\n",
      "Epoch [23/25], Train Loss: 953.0821, Eval Loss: 30.1117\n",
      "Epoch [24/25], Train Loss: 930.3836, Eval Loss: 29.8236\n",
      "Epoch [25/25], Train Loss: 912.2828, Eval Loss: 29.5946\n",
      "Epoch [1/25], Train Loss: 2449.9514, Eval Loss: 29.0093\n",
      "Epoch [2/25], Train Loss: 857.4929, Eval Loss: 28.9102\n",
      "Epoch [3/25], Train Loss: 856.3641, Eval Loss: 28.9108\n",
      "Epoch [4/25], Train Loss: 856.3620, Eval Loss: 28.9108\n",
      "Epoch [5/25], Train Loss: 856.3612, Eval Loss: 28.9108\n",
      "Epoch [6/25], Train Loss: 856.3603, Eval Loss: 28.9107\n",
      "Epoch [7/25], Train Loss: 856.3595, Eval Loss: 28.9107\n",
      "Epoch [8/25], Train Loss: 856.3586, Eval Loss: 28.9107\n",
      "Epoch [9/25], Train Loss: 856.3578, Eval Loss: 28.9107\n",
      "Epoch [10/25], Train Loss: 856.3569, Eval Loss: 28.9107\n",
      "Epoch [11/25], Train Loss: 856.3560, Eval Loss: 28.9107\n",
      "Epoch [12/25], Train Loss: 856.3551, Eval Loss: 28.9106\n",
      "Epoch [13/25], Train Loss: 856.3542, Eval Loss: 28.9106\n",
      "Epoch [14/25], Train Loss: 856.3533, Eval Loss: 28.9106\n",
      "Epoch [15/25], Train Loss: 856.3523, Eval Loss: 28.9106\n",
      "Epoch [16/25], Train Loss: 856.3513, Eval Loss: 28.9106\n",
      "Epoch [17/25], Train Loss: 856.3502, Eval Loss: 28.9105\n",
      "Epoch [18/25], Train Loss: 856.3491, Eval Loss: 28.9105\n",
      "Epoch [19/25], Train Loss: 856.3479, Eval Loss: 28.9105\n",
      "Epoch [20/25], Train Loss: 856.3466, Eval Loss: 28.9105\n",
      "Epoch [21/25], Train Loss: 856.3453, Eval Loss: 28.9105\n",
      "Epoch [22/25], Train Loss: 856.3438, Eval Loss: 28.9104\n",
      "Epoch [23/25], Train Loss: 856.3422, Eval Loss: 28.9104\n",
      "Epoch [24/25], Train Loss: 856.3405, Eval Loss: 28.9104\n",
      "Epoch [25/25], Train Loss: 856.3386, Eval Loss: 28.9103\n",
      "Epoch [1/25], Train Loss: 2411.8558, Eval Loss: 29.0047\n",
      "Epoch [2/25], Train Loss: 857.4401, Eval Loss: 28.9100\n",
      "Epoch [3/25], Train Loss: 856.3530, Eval Loss: 28.9106\n",
      "Epoch [4/25], Train Loss: 856.3509, Eval Loss: 28.9106\n",
      "Epoch [5/25], Train Loss: 856.3497, Eval Loss: 28.9105\n",
      "Epoch [6/25], Train Loss: 856.3485, Eval Loss: 28.9105\n",
      "Epoch [7/25], Train Loss: 856.3473, Eval Loss: 28.9105\n",
      "Epoch [8/25], Train Loss: 856.3460, Eval Loss: 28.9105\n",
      "Epoch [9/25], Train Loss: 856.3446, Eval Loss: 28.9104\n",
      "Epoch [10/25], Train Loss: 856.3432, Eval Loss: 28.9104\n",
      "Epoch [11/25], Train Loss: 856.3416, Eval Loss: 28.9104\n",
      "Epoch [12/25], Train Loss: 856.3400, Eval Loss: 28.9103\n",
      "Epoch [13/25], Train Loss: 856.3383, Eval Loss: 28.9103\n",
      "Epoch [14/25], Train Loss: 856.3364, Eval Loss: 28.9103\n",
      "Epoch [15/25], Train Loss: 856.3343, Eval Loss: 28.9102\n",
      "Epoch [16/25], Train Loss: 856.3319, Eval Loss: 28.9102\n",
      "Epoch [17/25], Train Loss: 856.3294, Eval Loss: 28.9101\n",
      "Epoch [18/25], Train Loss: 856.3264, Eval Loss: 28.9101\n",
      "Epoch [19/25], Train Loss: 856.3231, Eval Loss: 28.9100\n",
      "Epoch [20/25], Train Loss: 856.3193, Eval Loss: 28.9099\n",
      "Epoch [21/25], Train Loss: 856.3148, Eval Loss: 28.9098\n",
      "Epoch [22/25], Train Loss: 856.3094, Eval Loss: 28.9097\n",
      "Epoch [23/25], Train Loss: 856.3029, Eval Loss: 28.9095\n",
      "Epoch [24/25], Train Loss: 856.2945, Eval Loss: 28.9093\n",
      "Epoch [25/25], Train Loss: 856.2835, Eval Loss: 28.9090\n",
      "Epoch [1/25], Train Loss: 3243.4454, Eval Loss: 29.3518\n",
      "Epoch [2/25], Train Loss: 935.5613, Eval Loss: 29.7359\n",
      "Epoch [3/25], Train Loss: 943.7915, Eval Loss: 29.1219\n",
      "Epoch [4/25], Train Loss: 943.4478, Eval Loss: 29.1431\n",
      "Epoch [5/25], Train Loss: 938.5965, Eval Loss: 29.3904\n",
      "Epoch [6/25], Train Loss: 933.8810, Eval Loss: 29.7561\n",
      "Epoch [7/25], Train Loss: 926.0681, Eval Loss: 30.4416\n",
      "Epoch [8/25], Train Loss: 925.2717, Eval Loss: 30.1768\n",
      "Epoch [9/25], Train Loss: 902.8720, Eval Loss: 29.7612\n",
      "Epoch [10/25], Train Loss: 873.1041, Eval Loss: 28.9245\n",
      "Epoch [11/25], Train Loss: 826.3202, Eval Loss: 26.8345\n",
      "Epoch [12/25], Train Loss: 775.6434, Eval Loss: 25.1784\n",
      "Epoch [13/25], Train Loss: 752.6158, Eval Loss: 24.8876\n",
      "Epoch [14/25], Train Loss: 707.8924, Eval Loss: 24.3107\n",
      "Epoch [15/25], Train Loss: 693.1545, Eval Loss: 24.6131\n",
      "Epoch [16/25], Train Loss: 685.3056, Eval Loss: 24.6873\n",
      "Epoch [17/25], Train Loss: 665.5459, Eval Loss: 24.1064\n",
      "Epoch [18/25], Train Loss: 638.8740, Eval Loss: 23.0075\n",
      "Epoch [19/25], Train Loss: 567.7645, Eval Loss: 20.5784\n",
      "Epoch [20/25], Train Loss: 425.9921, Eval Loss: 17.3450\n",
      "Epoch [21/25], Train Loss: 252.3865, Eval Loss: 13.9930\n",
      "Epoch [22/25], Train Loss: 197.8097, Eval Loss: 13.4253\n",
      "Epoch [23/25], Train Loss: 202.3135, Eval Loss: 16.2889\n",
      "Epoch [24/25], Train Loss: 151.2759, Eval Loss: 12.2409\n",
      "Epoch [25/25], Train Loss: 133.4930, Eval Loss: 10.4589\n",
      "Epoch [1/25], Train Loss: 2862.3774, Eval Loss: 29.1801\n",
      "Epoch [2/25], Train Loss: 958.3332, Eval Loss: 29.8378\n",
      "Epoch [3/25], Train Loss: 960.0517, Eval Loss: 31.4793\n",
      "Epoch [4/25], Train Loss: 969.4030, Eval Loss: 31.6563\n",
      "Epoch [5/25], Train Loss: 964.6016, Eval Loss: 31.2142\n",
      "Epoch [6/25], Train Loss: 952.9590, Eval Loss: 31.1323\n",
      "Epoch [7/25], Train Loss: 949.4647, Eval Loss: 31.0845\n",
      "Epoch [8/25], Train Loss: 939.9935, Eval Loss: 30.8536\n",
      "Epoch [9/25], Train Loss: 927.7148, Eval Loss: 30.5197\n",
      "Epoch [10/25], Train Loss: 912.1056, Eval Loss: 29.9252\n",
      "Epoch [11/25], Train Loss: 896.3571, Eval Loss: 29.2570\n",
      "Epoch [12/25], Train Loss: 861.0038, Eval Loss: 27.8160\n",
      "Epoch [13/25], Train Loss: 825.7506, Eval Loss: 26.3097\n",
      "Epoch [14/25], Train Loss: 805.6583, Eval Loss: 25.5007\n",
      "Epoch [15/25], Train Loss: 781.7942, Eval Loss: 25.1295\n",
      "Epoch [16/25], Train Loss: 749.6121, Eval Loss: 24.9243\n",
      "Epoch [17/25], Train Loss: 731.6391, Eval Loss: 24.6480\n",
      "Epoch [18/25], Train Loss: 716.4779, Eval Loss: 24.6647\n",
      "Epoch [19/25], Train Loss: 709.4042, Eval Loss: 25.1113\n",
      "Epoch [20/25], Train Loss: 690.3333, Eval Loss: 24.1437\n",
      "Epoch [21/25], Train Loss: 679.8585, Eval Loss: 24.4138\n",
      "Epoch [22/25], Train Loss: 649.5854, Eval Loss: 22.6929\n",
      "Epoch [23/25], Train Loss: 629.0280, Eval Loss: 22.6737\n",
      "Epoch [24/25], Train Loss: 576.7125, Eval Loss: 21.8085\n",
      "Epoch [25/25], Train Loss: 549.1249, Eval Loss: 21.0541\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 4986.2580, Eval Loss: 45.4851\n",
      "Epoch [2/25], Train Loss: 1436.8453, Eval Loss: 31.1550\n",
      "Epoch [3/25], Train Loss: 913.9538, Eval Loss: 29.0422\n",
      "Epoch [4/25], Train Loss: 857.4982, Eval Loss: 28.9015\n",
      "Epoch [5/25], Train Loss: 854.3990, Eval Loss: 28.9047\n",
      "Epoch [6/25], Train Loss: 854.5564, Eval Loss: 28.9061\n",
      "Epoch [7/25], Train Loss: 854.7155, Eval Loss: 28.9062\n",
      "Epoch [8/25], Train Loss: 854.8421, Eval Loss: 28.9061\n",
      "Epoch [9/25], Train Loss: 854.9537, Eval Loss: 28.9060\n",
      "Epoch [10/25], Train Loss: 855.0545, Eval Loss: 28.9059\n",
      "Epoch [11/25], Train Loss: 855.1464, Eval Loss: 28.9057\n",
      "Epoch [12/25], Train Loss: 855.2308, Eval Loss: 28.9054\n",
      "Epoch [13/25], Train Loss: 855.3085, Eval Loss: 28.9051\n",
      "Epoch [14/25], Train Loss: 855.3804, Eval Loss: 28.9047\n",
      "Epoch [15/25], Train Loss: 855.4471, Eval Loss: 28.9043\n",
      "Epoch [16/25], Train Loss: 855.5091, Eval Loss: 28.9038\n",
      "Epoch [17/25], Train Loss: 855.5669, Eval Loss: 28.9033\n",
      "Epoch [18/25], Train Loss: 855.6207, Eval Loss: 28.9028\n",
      "Epoch [19/25], Train Loss: 855.6710, Eval Loss: 28.9022\n",
      "Epoch [20/25], Train Loss: 855.7179, Eval Loss: 28.9017\n",
      "Epoch [21/25], Train Loss: 855.7618, Eval Loss: 28.9011\n",
      "Epoch [22/25], Train Loss: 855.8028, Eval Loss: 28.9005\n",
      "Epoch [23/25], Train Loss: 855.8412, Eval Loss: 28.8999\n",
      "Epoch [24/25], Train Loss: 855.8772, Eval Loss: 28.8993\n",
      "Epoch [25/25], Train Loss: 855.9107, Eval Loss: 28.8987\n",
      "Epoch [1/25], Train Loss: 4876.7898, Eval Loss: 44.8611\n",
      "Epoch [2/25], Train Loss: 1403.9908, Eval Loss: 30.9440\n",
      "Epoch [3/25], Train Loss: 907.5006, Eval Loss: 29.0173\n",
      "Epoch [4/25], Train Loss: 856.8950, Eval Loss: 28.9011\n",
      "Epoch [5/25], Train Loss: 854.3833, Eval Loss: 28.9048\n",
      "Epoch [6/25], Train Loss: 854.5589, Eval Loss: 28.9061\n",
      "Epoch [7/25], Train Loss: 854.7158, Eval Loss: 28.9062\n",
      "Epoch [8/25], Train Loss: 854.8423, Eval Loss: 28.9061\n",
      "Epoch [9/25], Train Loss: 854.9543, Eval Loss: 28.9061\n",
      "Epoch [10/25], Train Loss: 855.0558, Eval Loss: 28.9060\n",
      "Epoch [11/25], Train Loss: 855.1485, Eval Loss: 28.9058\n",
      "Epoch [12/25], Train Loss: 855.2337, Eval Loss: 28.9056\n",
      "Epoch [13/25], Train Loss: 855.3122, Eval Loss: 28.9052\n",
      "Epoch [14/25], Train Loss: 855.3849, Eval Loss: 28.9049\n",
      "Epoch [15/25], Train Loss: 855.4524, Eval Loss: 28.9044\n",
      "Epoch [16/25], Train Loss: 855.5150, Eval Loss: 28.9040\n",
      "Epoch [17/25], Train Loss: 855.5734, Eval Loss: 28.9035\n",
      "Epoch [18/25], Train Loss: 855.6277, Eval Loss: 28.9029\n",
      "Epoch [19/25], Train Loss: 855.6784, Eval Loss: 28.9024\n",
      "Epoch [20/25], Train Loss: 855.7256, Eval Loss: 28.9018\n",
      "Epoch [21/25], Train Loss: 855.7698, Eval Loss: 28.9012\n",
      "Epoch [22/25], Train Loss: 855.8110, Eval Loss: 28.9006\n",
      "Epoch [23/25], Train Loss: 855.8495, Eval Loss: 28.9000\n",
      "Epoch [24/25], Train Loss: 855.8855, Eval Loss: 28.8994\n",
      "Epoch [25/25], Train Loss: 855.9190, Eval Loss: 28.8987\n",
      "Epoch [1/25], Train Loss: 1255.2827, Eval Loss: 29.9808\n",
      "Epoch [2/25], Train Loss: 885.6670, Eval Loss: 29.9749\n",
      "Epoch [3/25], Train Loss: 885.6816, Eval Loss: 29.9760\n",
      "Epoch [4/25], Train Loss: 885.7168, Eval Loss: 29.9705\n",
      "Epoch [5/25], Train Loss: 885.7250, Eval Loss: 29.9705\n",
      "Epoch [6/25], Train Loss: 885.6984, Eval Loss: 29.9715\n",
      "Epoch [7/25], Train Loss: 885.7189, Eval Loss: 29.9715\n",
      "Epoch [8/25], Train Loss: 885.6176, Eval Loss: 29.9740\n",
      "Epoch [9/25], Train Loss: 885.6238, Eval Loss: 29.9744\n",
      "Epoch [10/25], Train Loss: 885.6415, Eval Loss: 29.9726\n",
      "Epoch [11/25], Train Loss: 885.6405, Eval Loss: 29.9701\n",
      "Epoch [12/25], Train Loss: 885.6220, Eval Loss: 29.9707\n",
      "Epoch [13/25], Train Loss: 885.6300, Eval Loss: 29.9716\n",
      "Epoch [14/25], Train Loss: 885.6286, Eval Loss: 29.9719\n",
      "Epoch [15/25], Train Loss: 885.6195, Eval Loss: 29.9718\n",
      "Epoch [16/25], Train Loss: 885.6911, Eval Loss: 29.9708\n",
      "Epoch [17/25], Train Loss: 885.6037, Eval Loss: 29.9731\n",
      "Epoch [18/25], Train Loss: 885.6919, Eval Loss: 29.9791\n",
      "Epoch [19/25], Train Loss: 885.7067, Eval Loss: 29.9800\n",
      "Epoch [20/25], Train Loss: 885.8602, Eval Loss: 29.9805\n",
      "Epoch [21/25], Train Loss: 885.7849, Eval Loss: 29.9688\n",
      "Epoch [22/25], Train Loss: 885.7448, Eval Loss: 29.9807\n",
      "Epoch [23/25], Train Loss: 885.8915, Eval Loss: 29.9798\n",
      "Epoch [24/25], Train Loss: 885.9024, Eval Loss: 29.9791\n",
      "Epoch [25/25], Train Loss: 885.8628, Eval Loss: 29.9810\n",
      "Epoch [1/25], Train Loss: 1269.5948, Eval Loss: 29.9812\n",
      "Epoch [2/25], Train Loss: 885.9017, Eval Loss: 29.9812\n",
      "Epoch [3/25], Train Loss: 885.9016, Eval Loss: 29.9812\n",
      "Epoch [4/25], Train Loss: 885.9015, Eval Loss: 29.9812\n",
      "Epoch [5/25], Train Loss: 885.9014, Eval Loss: 29.9811\n",
      "Epoch [6/25], Train Loss: 885.9012, Eval Loss: 29.9811\n",
      "Epoch [7/25], Train Loss: 885.9010, Eval Loss: 29.9811\n",
      "Epoch [8/25], Train Loss: 885.9006, Eval Loss: 29.9811\n",
      "Epoch [9/25], Train Loss: 885.8999, Eval Loss: 29.9811\n",
      "Epoch [10/25], Train Loss: 885.8977, Eval Loss: 29.9809\n",
      "Epoch [11/25], Train Loss: 885.8950, Eval Loss: 29.9808\n",
      "Epoch [12/25], Train Loss: 885.8919, Eval Loss: 29.9802\n",
      "Epoch [13/25], Train Loss: 885.7941, Eval Loss: 29.9745\n",
      "Epoch [14/25], Train Loss: 885.6905, Eval Loss: 29.9698\n",
      "Epoch [15/25], Train Loss: 885.8104, Eval Loss: 29.9761\n",
      "Epoch [16/25], Train Loss: 885.6803, Eval Loss: 29.9707\n",
      "Epoch [17/25], Train Loss: 885.8747, Eval Loss: 29.9809\n",
      "Epoch [18/25], Train Loss: 885.8058, Eval Loss: 29.9771\n",
      "Epoch [19/25], Train Loss: 885.6735, Eval Loss: 29.9874\n",
      "Epoch [20/25], Train Loss: 885.8173, Eval Loss: 29.9806\n",
      "Epoch [21/25], Train Loss: 885.6718, Eval Loss: 29.9816\n",
      "Epoch [22/25], Train Loss: 885.7662, Eval Loss: 29.9689\n",
      "Epoch [23/25], Train Loss: 885.7675, Eval Loss: 29.9810\n",
      "Epoch [24/25], Train Loss: 885.8992, Eval Loss: 29.9809\n",
      "Epoch [25/25], Train Loss: 885.8993, Eval Loss: 29.9810\n",
      "Epoch [1/25], Train Loss: 8311.3444, Eval Loss: 73.0578\n",
      "Epoch [2/25], Train Loss: 1827.8229, Eval Loss: 28.9710\n",
      "Epoch [3/25], Train Loss: 884.0261, Eval Loss: 28.9716\n",
      "Epoch [4/25], Train Loss: 897.1867, Eval Loss: 28.8902\n",
      "Epoch [5/25], Train Loss: 889.7191, Eval Loss: 28.9178\n",
      "Epoch [6/25], Train Loss: 878.4617, Eval Loss: 29.0368\n",
      "Epoch [7/25], Train Loss: 885.1723, Eval Loss: 29.0224\n",
      "Epoch [8/25], Train Loss: 889.3713, Eval Loss: 28.9852\n",
      "Epoch [9/25], Train Loss: 878.3090, Eval Loss: 28.9926\n",
      "Epoch [10/25], Train Loss: 877.9851, Eval Loss: 29.0578\n",
      "Epoch [11/25], Train Loss: 889.9307, Eval Loss: 29.0620\n",
      "Epoch [12/25], Train Loss: 885.2528, Eval Loss: 29.0099\n",
      "Epoch [13/25], Train Loss: 867.8394, Eval Loss: 29.0238\n",
      "Epoch [14/25], Train Loss: 884.8777, Eval Loss: 29.2416\n",
      "Epoch [15/25], Train Loss: 878.1010, Eval Loss: 28.9603\n",
      "Epoch [16/25], Train Loss: 877.5006, Eval Loss: 29.1896\n",
      "Epoch [17/25], Train Loss: 879.8549, Eval Loss: 28.9920\n",
      "Epoch [18/25], Train Loss: 897.7344, Eval Loss: 29.1242\n",
      "Epoch [19/25], Train Loss: 869.5884, Eval Loss: 29.0079\n",
      "Epoch [20/25], Train Loss: 863.5752, Eval Loss: 29.1269\n",
      "Epoch [21/25], Train Loss: 878.9694, Eval Loss: 29.0798\n",
      "Epoch [22/25], Train Loss: 880.5749, Eval Loss: 29.0494\n",
      "Epoch [23/25], Train Loss: 869.7157, Eval Loss: 29.1613\n",
      "Epoch [24/25], Train Loss: 863.7689, Eval Loss: 29.1758\n",
      "Epoch [25/25], Train Loss: 879.6282, Eval Loss: 28.9577\n",
      "Epoch [1/25], Train Loss: 8630.5431, Eval Loss: 80.1137\n",
      "Epoch [2/25], Train Loss: 2313.5988, Eval Loss: 29.2619\n",
      "Epoch [3/25], Train Loss: 894.8042, Eval Loss: 28.9692\n",
      "Epoch [4/25], Train Loss: 879.2590, Eval Loss: 28.9253\n",
      "Epoch [5/25], Train Loss: 873.4439, Eval Loss: 28.8905\n",
      "Epoch [6/25], Train Loss: 878.4543, Eval Loss: 29.0293\n",
      "Epoch [7/25], Train Loss: 876.1617, Eval Loss: 29.0008\n",
      "Epoch [8/25], Train Loss: 882.6006, Eval Loss: 28.9733\n",
      "Epoch [9/25], Train Loss: 882.1330, Eval Loss: 29.0135\n",
      "Epoch [10/25], Train Loss: 885.3196, Eval Loss: 28.9139\n",
      "Epoch [11/25], Train Loss: 893.0013, Eval Loss: 28.9455\n",
      "Epoch [12/25], Train Loss: 876.0361, Eval Loss: 29.1434\n",
      "Epoch [13/25], Train Loss: 876.0930, Eval Loss: 29.0008\n",
      "Epoch [14/25], Train Loss: 869.9336, Eval Loss: 29.1606\n",
      "Epoch [15/25], Train Loss: 892.5196, Eval Loss: 29.0702\n",
      "Epoch [16/25], Train Loss: 878.1610, Eval Loss: 28.9751\n",
      "Epoch [17/25], Train Loss: 876.6440, Eval Loss: 29.0164\n",
      "Epoch [18/25], Train Loss: 874.5608, Eval Loss: 29.1394\n",
      "Epoch [19/25], Train Loss: 869.0025, Eval Loss: 29.0500\n",
      "Epoch [20/25], Train Loss: 877.5345, Eval Loss: 29.0437\n",
      "Epoch [21/25], Train Loss: 873.1967, Eval Loss: 29.2913\n",
      "Epoch [22/25], Train Loss: 879.5101, Eval Loss: 29.3148\n",
      "Epoch [23/25], Train Loss: 869.5260, Eval Loss: 29.1488\n",
      "Epoch [24/25], Train Loss: 874.4615, Eval Loss: 29.0436\n",
      "Epoch [25/25], Train Loss: 866.3146, Eval Loss: 29.3369\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9217.7394, Eval Loss: 93.5404\n",
      "Epoch [2/25], Train Loss: 8899.2804, Eval Loss: 92.0827\n",
      "Epoch [3/25], Train Loss: 8671.3678, Eval Loss: 91.0632\n",
      "Epoch [4/25], Train Loss: 8499.4996, Eval Loss: 90.2213\n",
      "Epoch [5/25], Train Loss: 8353.1146, Eval Loss: 89.4608\n",
      "Epoch [6/25], Train Loss: 8218.6940, Eval Loss: 88.7421\n",
      "Epoch [7/25], Train Loss: 8091.5402, Eval Loss: 88.0493\n",
      "Epoch [8/25], Train Loss: 7969.3211, Eval Loss: 87.3748\n",
      "Epoch [9/25], Train Loss: 7850.8411, Eval Loss: 86.7143\n",
      "Epoch [10/25], Train Loss: 7735.5850, Eval Loss: 86.0650\n",
      "Epoch [11/25], Train Loss: 7622.9346, Eval Loss: 85.4251\n",
      "Epoch [12/25], Train Loss: 7512.6576, Eval Loss: 84.7934\n",
      "Epoch [13/25], Train Loss: 7404.4760, Eval Loss: 84.1688\n",
      "Epoch [14/25], Train Loss: 7298.2672, Eval Loss: 83.5507\n",
      "Epoch [15/25], Train Loss: 7193.9065, Eval Loss: 82.9385\n",
      "Epoch [16/25], Train Loss: 7091.1748, Eval Loss: 82.3318\n",
      "Epoch [17/25], Train Loss: 6990.1327, Eval Loss: 81.7302\n",
      "Epoch [18/25], Train Loss: 6890.6496, Eval Loss: 81.1334\n",
      "Epoch [19/25], Train Loss: 6792.6043, Eval Loss: 80.5413\n",
      "Epoch [20/25], Train Loss: 6696.0259, Eval Loss: 79.9535\n",
      "Epoch [21/25], Train Loss: 6600.8256, Eval Loss: 79.3699\n",
      "Epoch [22/25], Train Loss: 6506.9735, Eval Loss: 78.7904\n",
      "Epoch [23/25], Train Loss: 6414.4435, Eval Loss: 78.2148\n",
      "Epoch [24/25], Train Loss: 6323.1753, Eval Loss: 77.6431\n",
      "Epoch [25/25], Train Loss: 6233.1683, Eval Loss: 77.0750\n",
      "Epoch [1/25], Train Loss: 9194.6138, Eval Loss: 93.3615\n",
      "Epoch [2/25], Train Loss: 8861.9607, Eval Loss: 91.8975\n",
      "Epoch [3/25], Train Loss: 8639.4405, Eval Loss: 90.9151\n",
      "Epoch [4/25], Train Loss: 8472.8011, Eval Loss: 90.0791\n",
      "Epoch [5/25], Train Loss: 8326.4131, Eval Loss: 89.3174\n",
      "Epoch [6/25], Train Loss: 8192.2142, Eval Loss: 88.5989\n",
      "Epoch [7/25], Train Loss: 8065.3652, Eval Loss: 87.9066\n",
      "Epoch [8/25], Train Loss: 7943.3439, Eval Loss: 87.2326\n",
      "Epoch [9/25], Train Loss: 7825.1781, Eval Loss: 86.5723\n",
      "Epoch [10/25], Train Loss: 7710.0952, Eval Loss: 85.9232\n",
      "Epoch [11/25], Train Loss: 7597.6139, Eval Loss: 85.2833\n",
      "Epoch [12/25], Train Loss: 7487.5456, Eval Loss: 84.6514\n",
      "Epoch [13/25], Train Loss: 7379.5149, Eval Loss: 84.0266\n",
      "Epoch [14/25], Train Loss: 7273.4834, Eval Loss: 83.4082\n",
      "Epoch [15/25], Train Loss: 7169.2043, Eval Loss: 82.7957\n",
      "Epoch [16/25], Train Loss: 7066.6280, Eval Loss: 82.1886\n",
      "Epoch [17/25], Train Loss: 6965.6914, Eval Loss: 81.5866\n",
      "Epoch [18/25], Train Loss: 6866.2735, Eval Loss: 80.9893\n",
      "Epoch [19/25], Train Loss: 6768.3332, Eval Loss: 80.3966\n",
      "Epoch [20/25], Train Loss: 6671.8494, Eval Loss: 79.8083\n",
      "Epoch [21/25], Train Loss: 6576.7382, Eval Loss: 79.2242\n",
      "Epoch [22/25], Train Loss: 6482.9621, Eval Loss: 78.6440\n",
      "Epoch [23/25], Train Loss: 6390.5013, Eval Loss: 78.0678\n",
      "Epoch [24/25], Train Loss: 6299.3116, Eval Loss: 77.4954\n",
      "Epoch [25/25], Train Loss: 6209.3453, Eval Loss: 76.9267\n",
      "Epoch [1/25], Train Loss: 8136.2732, Eval Loss: 77.1458\n",
      "Epoch [2/25], Train Loss: 4691.2723, Eval Loss: 57.3136\n",
      "Epoch [3/25], Train Loss: 2726.0852, Eval Loss: 44.7104\n",
      "Epoch [4/25], Train Loss: 1767.1828, Eval Loss: 37.2125\n",
      "Epoch [5/25], Train Loss: 1298.9319, Eval Loss: 33.0629\n",
      "Epoch [6/25], Train Loss: 1070.4787, Eval Loss: 30.9045\n",
      "Epoch [7/25], Train Loss: 959.0043, Eval Loss: 29.8307\n",
      "Epoch [8/25], Train Loss: 904.6859, Eval Loss: 29.3139\n",
      "Epoch [9/25], Train Loss: 878.2417, Eval Loss: 29.0719\n",
      "Epoch [10/25], Train Loss: 865.2960, Eval Loss: 28.9624\n",
      "Epoch [11/25], Train Loss: 859.0305, Eval Loss: 28.9153\n",
      "Epoch [12/25], Train Loss: 856.0043, Eval Loss: 28.8967\n",
      "Epoch [13/25], Train Loss: 854.5195, Eval Loss: 28.8908\n",
      "Epoch [14/25], Train Loss: 853.7253, Eval Loss: 28.8900\n",
      "Epoch [15/25], Train Loss: 853.3641, Eval Loss: 28.8912\n",
      "Epoch [16/25], Train Loss: 853.2263, Eval Loss: 28.8928\n",
      "Epoch [17/25], Train Loss: 853.1930, Eval Loss: 28.8943\n",
      "Epoch [18/25], Train Loss: 853.0967, Eval Loss: 28.8956\n",
      "Epoch [19/25], Train Loss: 853.0940, Eval Loss: 28.8965\n",
      "Epoch [20/25], Train Loss: 853.0513, Eval Loss: 28.8972\n",
      "Epoch [21/25], Train Loss: 853.0144, Eval Loss: 28.8978\n",
      "Epoch [22/25], Train Loss: 853.0925, Eval Loss: 28.8981\n",
      "Epoch [23/25], Train Loss: 853.1034, Eval Loss: 28.8984\n",
      "Epoch [24/25], Train Loss: 853.1046, Eval Loss: 28.8986\n",
      "Epoch [25/25], Train Loss: 853.0651, Eval Loss: 28.8987\n",
      "Epoch [1/25], Train Loss: 8045.8852, Eval Loss: 76.4738\n",
      "Epoch [2/25], Train Loss: 4616.5269, Eval Loss: 56.8839\n",
      "Epoch [3/25], Train Loss: 2689.9219, Eval Loss: 44.4447\n",
      "Epoch [4/25], Train Loss: 1749.1621, Eval Loss: 37.0609\n",
      "Epoch [5/25], Train Loss: 1290.2475, Eval Loss: 32.9820\n",
      "Epoch [6/25], Train Loss: 1066.3584, Eval Loss: 30.8629\n",
      "Epoch [7/25], Train Loss: 956.9799, Eval Loss: 29.8106\n",
      "Epoch [8/25], Train Loss: 903.7437, Eval Loss: 29.3041\n",
      "Epoch [9/25], Train Loss: 877.6937, Eval Loss: 29.0675\n",
      "Epoch [10/25], Train Loss: 865.1140, Eval Loss: 28.9604\n",
      "Epoch [11/25], Train Loss: 858.8873, Eval Loss: 28.9145\n",
      "Epoch [12/25], Train Loss: 855.9019, Eval Loss: 28.8964\n",
      "Epoch [13/25], Train Loss: 854.4588, Eval Loss: 28.8907\n",
      "Epoch [14/25], Train Loss: 853.7637, Eval Loss: 28.8900\n",
      "Epoch [15/25], Train Loss: 853.3870, Eval Loss: 28.8912\n",
      "Epoch [16/25], Train Loss: 853.2489, Eval Loss: 28.8928\n",
      "Epoch [17/25], Train Loss: 853.1286, Eval Loss: 28.8943\n",
      "Epoch [18/25], Train Loss: 853.0793, Eval Loss: 28.8955\n",
      "Epoch [19/25], Train Loss: 853.0771, Eval Loss: 28.8965\n",
      "Epoch [20/25], Train Loss: 853.0446, Eval Loss: 28.8972\n",
      "Epoch [21/25], Train Loss: 853.0774, Eval Loss: 28.8977\n",
      "Epoch [22/25], Train Loss: 853.0859, Eval Loss: 28.8981\n",
      "Epoch [23/25], Train Loss: 853.0428, Eval Loss: 28.8984\n",
      "Epoch [24/25], Train Loss: 853.0803, Eval Loss: 28.8986\n",
      "Epoch [25/25], Train Loss: 853.0228, Eval Loss: 28.8987\n",
      "Epoch [1/25], Train Loss: 2546.7005, Eval Loss: 29.7976\n",
      "Epoch [2/25], Train Loss: 899.1119, Eval Loss: 29.0373\n",
      "Epoch [3/25], Train Loss: 912.3030, Eval Loss: 29.3483\n",
      "Epoch [4/25], Train Loss: 905.4739, Eval Loss: 29.1732\n",
      "Epoch [5/25], Train Loss: 905.0175, Eval Loss: 28.9471\n",
      "Epoch [6/25], Train Loss: 901.2177, Eval Loss: 29.0678\n",
      "Epoch [7/25], Train Loss: 916.5752, Eval Loss: 28.9421\n",
      "Epoch [8/25], Train Loss: 905.6906, Eval Loss: 29.2502\n",
      "Epoch [9/25], Train Loss: 903.4735, Eval Loss: 29.2421\n",
      "Epoch [10/25], Train Loss: 890.7886, Eval Loss: 28.7988\n",
      "Epoch [11/25], Train Loss: 874.7146, Eval Loss: 28.7637\n",
      "Epoch [12/25], Train Loss: 893.3227, Eval Loss: 28.7997\n",
      "Epoch [13/25], Train Loss: 901.6455, Eval Loss: 28.6907\n",
      "Epoch [14/25], Train Loss: 887.4764, Eval Loss: 28.7987\n",
      "Epoch [15/25], Train Loss: 874.4612, Eval Loss: 28.9354\n",
      "Epoch [16/25], Train Loss: 885.1419, Eval Loss: 28.6212\n",
      "Epoch [17/25], Train Loss: 879.7241, Eval Loss: 28.9702\n",
      "Epoch [18/25], Train Loss: 886.7295, Eval Loss: 28.5682\n",
      "Epoch [19/25], Train Loss: 867.7140, Eval Loss: 28.5350\n",
      "Epoch [20/25], Train Loss: 870.7346, Eval Loss: 28.9143\n",
      "Epoch [21/25], Train Loss: 879.4257, Eval Loss: 28.3728\n",
      "Epoch [22/25], Train Loss: 851.2490, Eval Loss: 28.2053\n",
      "Epoch [23/25], Train Loss: 864.4860, Eval Loss: 28.0165\n",
      "Epoch [24/25], Train Loss: 842.7676, Eval Loss: 27.9652\n",
      "Epoch [25/25], Train Loss: 854.5643, Eval Loss: 27.7311\n",
      "Epoch [1/25], Train Loss: 2411.2417, Eval Loss: 29.0485\n",
      "Epoch [2/25], Train Loss: 930.1987, Eval Loss: 29.1838\n",
      "Epoch [3/25], Train Loss: 921.5667, Eval Loss: 29.1600\n",
      "Epoch [4/25], Train Loss: 887.5708, Eval Loss: 28.9652\n",
      "Epoch [5/25], Train Loss: 911.3064, Eval Loss: 29.1811\n",
      "Epoch [6/25], Train Loss: 907.0275, Eval Loss: 28.8774\n",
      "Epoch [7/25], Train Loss: 915.4113, Eval Loss: 29.1730\n",
      "Epoch [8/25], Train Loss: 900.0711, Eval Loss: 28.8804\n",
      "Epoch [9/25], Train Loss: 910.1173, Eval Loss: 29.0138\n",
      "Epoch [10/25], Train Loss: 891.1420, Eval Loss: 28.7821\n",
      "Epoch [11/25], Train Loss: 896.5691, Eval Loss: 29.3596\n",
      "Epoch [12/25], Train Loss: 894.7773, Eval Loss: 28.7606\n",
      "Epoch [13/25], Train Loss: 897.8078, Eval Loss: 29.0160\n",
      "Epoch [14/25], Train Loss: 884.9314, Eval Loss: 29.0005\n",
      "Epoch [15/25], Train Loss: 907.1760, Eval Loss: 28.7301\n",
      "Epoch [16/25], Train Loss: 884.5946, Eval Loss: 29.0402\n",
      "Epoch [17/25], Train Loss: 883.0583, Eval Loss: 28.7675\n",
      "Epoch [18/25], Train Loss: 880.6266, Eval Loss: 28.8634\n",
      "Epoch [19/25], Train Loss: 871.7418, Eval Loss: 28.6457\n",
      "Epoch [20/25], Train Loss: 873.1048, Eval Loss: 28.2549\n",
      "Epoch [21/25], Train Loss: 854.6895, Eval Loss: 28.2460\n",
      "Epoch [22/25], Train Loss: 863.4255, Eval Loss: 28.3845\n",
      "Epoch [23/25], Train Loss: 860.7156, Eval Loss: 28.1621\n",
      "Epoch [24/25], Train Loss: 859.7787, Eval Loss: 27.8183\n",
      "Epoch [25/25], Train Loss: 841.5638, Eval Loss: 28.5960\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8525.9294, Eval Loss: 86.9989\n",
      "Epoch [2/25], Train Loss: 7295.0416, Eval Loss: 80.6628\n",
      "Epoch [3/25], Train Loss: 6306.3614, Eval Loss: 74.9315\n",
      "Epoch [4/25], Train Loss: 5466.7211, Eval Loss: 69.6762\n",
      "Epoch [5/25], Train Loss: 4748.6406, Eval Loss: 64.8557\n",
      "Epoch [6/25], Train Loss: 4134.4720, Eval Loss: 60.4464\n",
      "Epoch [7/25], Train Loss: 3610.0071, Eval Loss: 56.4297\n",
      "Epoch [8/25], Train Loss: 3163.0522, Eval Loss: 52.7878\n",
      "Epoch [9/25], Train Loss: 2782.9847, Eval Loss: 49.5037\n",
      "Epoch [10/25], Train Loss: 2460.5285, Eval Loss: 46.5599\n",
      "Epoch [11/25], Train Loss: 2187.6123, Eval Loss: 43.9388\n",
      "Epoch [12/25], Train Loss: 1957.2370, Eval Loss: 41.6217\n",
      "Epoch [13/25], Train Loss: 1763.3241, Eval Loss: 39.5891\n",
      "Epoch [14/25], Train Loss: 1600.5945, Eval Loss: 37.8196\n",
      "Epoch [15/25], Train Loss: 1464.4656, Eval Loss: 36.2912\n",
      "Epoch [16/25], Train Loss: 1350.9599, Eval Loss: 34.9808\n",
      "Epoch [17/25], Train Loss: 1256.6345, Eval Loss: 33.8656\n",
      "Epoch [18/25], Train Loss: 1178.5239, Eval Loss: 32.9234\n",
      "Epoch [19/25], Train Loss: 1114.0824, Eval Loss: 32.1330\n",
      "Epoch [20/25], Train Loss: 1061.1353, Eval Loss: 31.4750\n",
      "Epoch [21/25], Train Loss: 1017.8312, Eval Loss: 30.9314\n",
      "Epoch [22/25], Train Loss: 982.5964, Eval Loss: 30.4861\n",
      "Epoch [23/25], Train Loss: 954.0955, Eval Loss: 30.1245\n",
      "Epoch [24/25], Train Loss: 931.1933, Eval Loss: 29.8338\n",
      "Epoch [25/25], Train Loss: 912.9262, Eval Loss: 29.6027\n",
      "Epoch [1/25], Train Loss: 8491.4519, Eval Loss: 86.7559\n",
      "Epoch [2/25], Train Loss: 7249.8444, Eval Loss: 80.3902\n",
      "Epoch [3/25], Train Loss: 6262.0339, Eval Loss: 74.6556\n",
      "Epoch [4/25], Train Loss: 5425.6528, Eval Loss: 69.4070\n",
      "Epoch [5/25], Train Loss: 4711.5781, Eval Loss: 64.5989\n",
      "Epoch [6/25], Train Loss: 4101.5993, Eval Loss: 60.2059\n",
      "Epoch [7/25], Train Loss: 3581.2530, Eval Loss: 56.2081\n",
      "Epoch [8/25], Train Loss: 3138.2046, Eval Loss: 52.5868\n",
      "Epoch [9/25], Train Loss: 2761.7351, Eval Loss: 49.3241\n",
      "Epoch [10/25], Train Loss: 2442.5405, Eval Loss: 46.4020\n",
      "Epoch [11/25], Train Loss: 2172.5341, Eval Loss: 43.8020\n",
      "Epoch [12/25], Train Loss: 1944.7159, Eval Loss: 41.5052\n",
      "Epoch [13/25], Train Loss: 1753.0211, Eval Loss: 39.4913\n",
      "Epoch [14/25], Train Loss: 1592.1933, Eval Loss: 37.7388\n",
      "Epoch [15/25], Train Loss: 1457.6717, Eval Loss: 36.2252\n",
      "Epoch [16/25], Train Loss: 1345.5073, Eval Loss: 34.9277\n",
      "Epoch [17/25], Train Loss: 1252.2870, Eval Loss: 33.8232\n",
      "Epoch [18/25], Train Loss: 1175.0763, Eval Loss: 32.8898\n",
      "Epoch [19/25], Train Loss: 1111.3588, Eval Loss: 32.1066\n",
      "Epoch [20/25], Train Loss: 1058.9902, Eval Loss: 31.4543\n",
      "Epoch [21/25], Train Loss: 1016.1457, Eval Loss: 30.9152\n",
      "Epoch [22/25], Train Loss: 981.2730, Eval Loss: 30.4734\n",
      "Epoch [23/25], Train Loss: 953.0576, Eval Loss: 30.1146\n",
      "Epoch [24/25], Train Loss: 930.3802, Eval Loss: 29.8261\n",
      "Epoch [25/25], Train Loss: 912.2908, Eval Loss: 29.5966\n",
      "Epoch [1/25], Train Loss: 2408.0959, Eval Loss: 29.0036\n",
      "Epoch [2/25], Train Loss: 857.5028, Eval Loss: 28.9103\n",
      "Epoch [3/25], Train Loss: 856.3649, Eval Loss: 28.9109\n",
      "Epoch [4/25], Train Loss: 856.3734, Eval Loss: 28.9109\n",
      "Epoch [5/25], Train Loss: 856.3276, Eval Loss: 28.9109\n",
      "Epoch [6/25], Train Loss: 856.3510, Eval Loss: 28.9109\n",
      "Epoch [7/25], Train Loss: 856.3494, Eval Loss: 28.9108\n",
      "Epoch [8/25], Train Loss: 856.3649, Eval Loss: 28.9108\n",
      "Epoch [9/25], Train Loss: 856.3538, Eval Loss: 28.9108\n",
      "Epoch [10/25], Train Loss: 856.3666, Eval Loss: 28.9108\n",
      "Epoch [11/25], Train Loss: 856.3221, Eval Loss: 28.9108\n",
      "Epoch [12/25], Train Loss: 856.3403, Eval Loss: 28.9108\n",
      "Epoch [13/25], Train Loss: 856.4047, Eval Loss: 28.9107\n",
      "Epoch [14/25], Train Loss: 856.3032, Eval Loss: 28.9107\n",
      "Epoch [15/25], Train Loss: 856.3745, Eval Loss: 28.9107\n",
      "Epoch [16/25], Train Loss: 856.3450, Eval Loss: 28.9107\n",
      "Epoch [17/25], Train Loss: 856.3197, Eval Loss: 28.9106\n",
      "Epoch [18/25], Train Loss: 856.3563, Eval Loss: 28.9106\n",
      "Epoch [19/25], Train Loss: 856.3870, Eval Loss: 28.9106\n",
      "Epoch [20/25], Train Loss: 856.4152, Eval Loss: 28.9106\n",
      "Epoch [21/25], Train Loss: 856.3804, Eval Loss: 28.9105\n",
      "Epoch [22/25], Train Loss: 856.3160, Eval Loss: 28.9105\n",
      "Epoch [23/25], Train Loss: 856.3463, Eval Loss: 28.9105\n",
      "Epoch [24/25], Train Loss: 856.4031, Eval Loss: 28.9104\n",
      "Epoch [25/25], Train Loss: 856.3345, Eval Loss: 28.9104\n",
      "Epoch [1/25], Train Loss: 2466.8694, Eval Loss: 29.0092\n",
      "Epoch [2/25], Train Loss: 857.4481, Eval Loss: 28.9102\n",
      "Epoch [3/25], Train Loss: 856.2956, Eval Loss: 28.9108\n",
      "Epoch [4/25], Train Loss: 856.3761, Eval Loss: 28.9108\n",
      "Epoch [5/25], Train Loss: 856.3207, Eval Loss: 28.9108\n",
      "Epoch [6/25], Train Loss: 856.3754, Eval Loss: 28.9108\n",
      "Epoch [7/25], Train Loss: 856.3089, Eval Loss: 28.9108\n",
      "Epoch [8/25], Train Loss: 856.3816, Eval Loss: 28.9107\n",
      "Epoch [9/25], Train Loss: 856.4314, Eval Loss: 28.9107\n",
      "Epoch [10/25], Train Loss: 856.3801, Eval Loss: 28.9107\n",
      "Epoch [11/25], Train Loss: 856.3290, Eval Loss: 28.9107\n",
      "Epoch [12/25], Train Loss: 856.3554, Eval Loss: 28.9106\n",
      "Epoch [13/25], Train Loss: 856.3331, Eval Loss: 28.9106\n",
      "Epoch [14/25], Train Loss: 856.3458, Eval Loss: 28.9105\n",
      "Epoch [15/25], Train Loss: 856.4266, Eval Loss: 28.9105\n",
      "Epoch [16/25], Train Loss: 856.3558, Eval Loss: 28.9104\n",
      "Epoch [17/25], Train Loss: 856.3475, Eval Loss: 28.9104\n",
      "Epoch [18/25], Train Loss: 856.3147, Eval Loss: 28.9103\n",
      "Epoch [19/25], Train Loss: 856.3460, Eval Loss: 28.9103\n",
      "Epoch [20/25], Train Loss: 856.3498, Eval Loss: 28.9102\n",
      "Epoch [21/25], Train Loss: 856.3169, Eval Loss: 28.9100\n",
      "Epoch [22/25], Train Loss: 856.2727, Eval Loss: 28.9097\n",
      "Epoch [23/25], Train Loss: 856.3240, Eval Loss: 28.9087\n",
      "Epoch [24/25], Train Loss: 856.4099, Eval Loss: 28.9089\n",
      "Epoch [25/25], Train Loss: 856.3399, Eval Loss: 28.9084\n",
      "Epoch [1/25], Train Loss: 3299.8366, Eval Loss: 29.4983\n",
      "Epoch [2/25], Train Loss: 1022.9949, Eval Loss: 30.2785\n",
      "Epoch [3/25], Train Loss: 1002.3580, Eval Loss: 29.8844\n",
      "Epoch [4/25], Train Loss: 1040.7874, Eval Loss: 29.0664\n",
      "Epoch [5/25], Train Loss: 1025.2613, Eval Loss: 29.2409\n",
      "Epoch [6/25], Train Loss: 960.5069, Eval Loss: 28.5011\n",
      "Epoch [7/25], Train Loss: 954.5815, Eval Loss: 28.4445\n",
      "Epoch [8/25], Train Loss: 964.4446, Eval Loss: 30.0555\n",
      "Epoch [9/25], Train Loss: 982.6136, Eval Loss: 27.8060\n",
      "Epoch [10/25], Train Loss: 935.5588, Eval Loss: 27.5624\n",
      "Epoch [11/25], Train Loss: 913.4615, Eval Loss: 27.8261\n",
      "Epoch [12/25], Train Loss: 825.0323, Eval Loss: 26.7028\n",
      "Epoch [13/25], Train Loss: 813.7136, Eval Loss: 25.1608\n",
      "Epoch [14/25], Train Loss: 812.4567, Eval Loss: 24.9942\n",
      "Epoch [15/25], Train Loss: 748.4171, Eval Loss: 25.7782\n",
      "Epoch [16/25], Train Loss: 770.9931, Eval Loss: 25.0822\n",
      "Epoch [17/25], Train Loss: 740.2019, Eval Loss: 24.4408\n",
      "Epoch [18/25], Train Loss: 695.0913, Eval Loss: 24.8116\n",
      "Epoch [19/25], Train Loss: 743.8172, Eval Loss: 25.7251\n",
      "Epoch [20/25], Train Loss: 712.6823, Eval Loss: 25.8568\n",
      "Epoch [21/25], Train Loss: 695.2978, Eval Loss: 24.4365\n",
      "Epoch [22/25], Train Loss: 649.5741, Eval Loss: 24.0251\n",
      "Epoch [23/25], Train Loss: 558.1049, Eval Loss: 24.5426\n",
      "Epoch [24/25], Train Loss: 478.7060, Eval Loss: 18.9195\n",
      "Epoch [25/25], Train Loss: 363.6161, Eval Loss: 15.1538\n",
      "Epoch [1/25], Train Loss: 1648.5953, Eval Loss: 31.0490\n",
      "Epoch [2/25], Train Loss: 1006.5201, Eval Loss: 29.5485\n",
      "Epoch [3/25], Train Loss: 1030.3330, Eval Loss: 29.7560\n",
      "Epoch [4/25], Train Loss: 1004.2802, Eval Loss: 30.0647\n",
      "Epoch [5/25], Train Loss: 1066.0770, Eval Loss: 28.5675\n",
      "Epoch [6/25], Train Loss: 1025.4677, Eval Loss: 29.1863\n",
      "Epoch [7/25], Train Loss: 1034.6498, Eval Loss: 28.1317\n",
      "Epoch [8/25], Train Loss: 1006.3577, Eval Loss: 27.8125\n",
      "Epoch [9/25], Train Loss: 996.5461, Eval Loss: 27.2826\n",
      "Epoch [10/25], Train Loss: 909.7739, Eval Loss: 26.4529\n",
      "Epoch [11/25], Train Loss: 876.9730, Eval Loss: 25.8156\n",
      "Epoch [12/25], Train Loss: 830.1334, Eval Loss: 25.7693\n",
      "Epoch [13/25], Train Loss: 778.7165, Eval Loss: 25.3010\n",
      "Epoch [14/25], Train Loss: 745.9089, Eval Loss: 25.0621\n",
      "Epoch [15/25], Train Loss: 845.3677, Eval Loss: 24.7159\n",
      "Epoch [16/25], Train Loss: 743.3741, Eval Loss: 25.1122\n",
      "Epoch [17/25], Train Loss: 758.5837, Eval Loss: 25.2149\n",
      "Epoch [18/25], Train Loss: 700.2670, Eval Loss: 24.3291\n",
      "Epoch [19/25], Train Loss: 683.2755, Eval Loss: 23.4490\n",
      "Epoch [20/25], Train Loss: 620.8909, Eval Loss: 21.0788\n",
      "Epoch [21/25], Train Loss: 552.7976, Eval Loss: 20.3307\n",
      "Epoch [22/25], Train Loss: 484.0948, Eval Loss: 19.9251\n",
      "Epoch [23/25], Train Loss: 357.1259, Eval Loss: 12.7046\n",
      "Epoch [24/25], Train Loss: 232.0300, Eval Loss: 10.4882\n",
      "Epoch [25/25], Train Loss: 195.8696, Eval Loss: 11.3597\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 4889.8838, Eval Loss: 45.0002\n",
      "Epoch [2/25], Train Loss: 1412.9554, Eval Loss: 31.0201\n",
      "Epoch [3/25], Train Loss: 909.7892, Eval Loss: 29.0265\n",
      "Epoch [4/25], Train Loss: 857.1187, Eval Loss: 28.9013\n",
      "Epoch [5/25], Train Loss: 854.3963, Eval Loss: 28.9048\n",
      "Epoch [6/25], Train Loss: 854.5662, Eval Loss: 28.9061\n",
      "Epoch [7/25], Train Loss: 854.7240, Eval Loss: 28.9062\n",
      "Epoch [8/25], Train Loss: 854.8505, Eval Loss: 28.9061\n",
      "Epoch [9/25], Train Loss: 854.9621, Eval Loss: 28.9060\n",
      "Epoch [10/25], Train Loss: 855.0630, Eval Loss: 28.9059\n",
      "Epoch [11/25], Train Loss: 855.1550, Eval Loss: 28.9057\n",
      "Epoch [12/25], Train Loss: 855.2394, Eval Loss: 28.9054\n",
      "Epoch [13/25], Train Loss: 855.3172, Eval Loss: 28.9051\n",
      "Epoch [14/25], Train Loss: 855.3891, Eval Loss: 28.9047\n",
      "Epoch [15/25], Train Loss: 855.4558, Eval Loss: 28.9043\n",
      "Epoch [16/25], Train Loss: 855.5177, Eval Loss: 28.9038\n",
      "Epoch [17/25], Train Loss: 855.5754, Eval Loss: 28.9033\n",
      "Epoch [18/25], Train Loss: 855.6291, Eval Loss: 28.9028\n",
      "Epoch [19/25], Train Loss: 855.6792, Eval Loss: 28.9022\n",
      "Epoch [20/25], Train Loss: 855.7260, Eval Loss: 28.9016\n",
      "Epoch [21/25], Train Loss: 855.7697, Eval Loss: 28.9011\n",
      "Epoch [22/25], Train Loss: 855.8106, Eval Loss: 28.9005\n",
      "Epoch [23/25], Train Loss: 855.8487, Eval Loss: 28.8999\n",
      "Epoch [24/25], Train Loss: 855.8844, Eval Loss: 28.8993\n",
      "Epoch [25/25], Train Loss: 855.9177, Eval Loss: 28.8986\n",
      "Epoch [1/25], Train Loss: 4886.3454, Eval Loss: 45.0024\n",
      "Epoch [2/25], Train Loss: 1414.8426, Eval Loss: 31.0633\n",
      "Epoch [3/25], Train Loss: 910.9640, Eval Loss: 29.0317\n",
      "Epoch [4/25], Train Loss: 857.2486, Eval Loss: 28.9015\n",
      "Epoch [5/25], Train Loss: 854.4181, Eval Loss: 28.9049\n",
      "Epoch [6/25], Train Loss: 854.5855, Eval Loss: 28.9061\n",
      "Epoch [7/25], Train Loss: 854.7440, Eval Loss: 28.9061\n",
      "Epoch [8/25], Train Loss: 854.8703, Eval Loss: 28.9060\n",
      "Epoch [9/25], Train Loss: 854.9812, Eval Loss: 28.9058\n",
      "Epoch [10/25], Train Loss: 855.0811, Eval Loss: 28.9056\n",
      "Epoch [11/25], Train Loss: 855.1718, Eval Loss: 28.9054\n",
      "Epoch [12/25], Train Loss: 855.2548, Eval Loss: 28.9050\n",
      "Epoch [13/25], Train Loss: 855.3311, Eval Loss: 28.9047\n",
      "Epoch [14/25], Train Loss: 855.4016, Eval Loss: 28.9043\n",
      "Epoch [15/25], Train Loss: 855.4669, Eval Loss: 28.9038\n",
      "Epoch [16/25], Train Loss: 855.5275, Eval Loss: 28.9033\n",
      "Epoch [17/25], Train Loss: 855.5838, Eval Loss: 28.9028\n",
      "Epoch [18/25], Train Loss: 855.6363, Eval Loss: 28.9023\n",
      "Epoch [19/25], Train Loss: 855.6854, Eval Loss: 28.9018\n",
      "Epoch [20/25], Train Loss: 855.7312, Eval Loss: 28.9012\n",
      "Epoch [21/25], Train Loss: 855.7740, Eval Loss: 28.9006\n",
      "Epoch [22/25], Train Loss: 855.8141, Eval Loss: 28.9001\n",
      "Epoch [23/25], Train Loss: 855.8515, Eval Loss: 28.8995\n",
      "Epoch [24/25], Train Loss: 855.8866, Eval Loss: 28.8989\n",
      "Epoch [25/25], Train Loss: 855.9194, Eval Loss: 28.8983\n",
      "Epoch [1/25], Train Loss: 1261.3092, Eval Loss: 30.0077\n",
      "Epoch [2/25], Train Loss: 885.4494, Eval Loss: 29.9806\n",
      "Epoch [3/25], Train Loss: 885.6891, Eval Loss: 29.9813\n",
      "Epoch [4/25], Train Loss: 885.9033, Eval Loss: 29.9812\n",
      "Epoch [5/25], Train Loss: 885.9037, Eval Loss: 29.9812\n",
      "Epoch [6/25], Train Loss: 885.9012, Eval Loss: 29.9812\n",
      "Epoch [7/25], Train Loss: 885.9005, Eval Loss: 29.9812\n",
      "Epoch [8/25], Train Loss: 885.8999, Eval Loss: 29.9814\n",
      "Epoch [9/25], Train Loss: 885.9301, Eval Loss: 29.9813\n",
      "Epoch [10/25], Train Loss: 885.9474, Eval Loss: 29.9812\n",
      "Epoch [11/25], Train Loss: 885.8997, Eval Loss: 29.9793\n",
      "Epoch [12/25], Train Loss: 885.6912, Eval Loss: 29.9814\n",
      "Epoch [13/25], Train Loss: 885.9014, Eval Loss: 29.9813\n",
      "Epoch [14/25], Train Loss: 885.7548, Eval Loss: 29.7929\n",
      "Epoch [15/25], Train Loss: 885.0469, Eval Loss: 29.9813\n",
      "Epoch [16/25], Train Loss: 885.8999, Eval Loss: 29.9814\n",
      "Epoch [17/25], Train Loss: 885.9032, Eval Loss: 29.9812\n",
      "Epoch [18/25], Train Loss: 885.9015, Eval Loss: 29.9812\n",
      "Epoch [19/25], Train Loss: 885.9108, Eval Loss: 29.9812\n",
      "Epoch [20/25], Train Loss: 885.9038, Eval Loss: 29.9811\n",
      "Epoch [21/25], Train Loss: 885.9001, Eval Loss: 29.9812\n",
      "Epoch [22/25], Train Loss: 885.8995, Eval Loss: 29.9812\n",
      "Epoch [23/25], Train Loss: 885.8953, Eval Loss: 29.9791\n",
      "Epoch [24/25], Train Loss: 885.8879, Eval Loss: 29.9812\n",
      "Epoch [25/25], Train Loss: 885.8982, Eval Loss: 29.9812\n",
      "Epoch [1/25], Train Loss: 1250.1710, Eval Loss: 29.9822\n",
      "Epoch [2/25], Train Loss: 885.9692, Eval Loss: 29.9811\n",
      "Epoch [3/25], Train Loss: 886.2258, Eval Loss: 29.9811\n",
      "Epoch [4/25], Train Loss: 885.9029, Eval Loss: 29.9811\n",
      "Epoch [5/25], Train Loss: 885.9384, Eval Loss: 29.9811\n",
      "Epoch [6/25], Train Loss: 885.9543, Eval Loss: 29.9810\n",
      "Epoch [7/25], Train Loss: 886.8411, Eval Loss: 29.9810\n",
      "Epoch [8/25], Train Loss: 885.8414, Eval Loss: 29.9812\n",
      "Epoch [9/25], Train Loss: 885.9011, Eval Loss: 29.9812\n",
      "Epoch [10/25], Train Loss: 885.8995, Eval Loss: 29.9812\n",
      "Epoch [11/25], Train Loss: 885.8957, Eval Loss: 29.9813\n",
      "Epoch [12/25], Train Loss: 885.6053, Eval Loss: 29.9813\n",
      "Epoch [13/25], Train Loss: 885.9001, Eval Loss: 29.9812\n",
      "Epoch [14/25], Train Loss: 885.8971, Eval Loss: 29.9811\n",
      "Epoch [15/25], Train Loss: 885.8952, Eval Loss: 29.9809\n",
      "Epoch [16/25], Train Loss: 885.8870, Eval Loss: 29.9809\n",
      "Epoch [17/25], Train Loss: 885.8665, Eval Loss: 29.9803\n",
      "Epoch [18/25], Train Loss: 885.9743, Eval Loss: 29.9813\n",
      "Epoch [19/25], Train Loss: 886.0823, Eval Loss: 29.9812\n",
      "Epoch [20/25], Train Loss: 885.9023, Eval Loss: 29.9812\n",
      "Epoch [21/25], Train Loss: 885.9016, Eval Loss: 29.9813\n",
      "Epoch [22/25], Train Loss: 885.9018, Eval Loss: 29.9812\n",
      "Epoch [23/25], Train Loss: 885.9010, Eval Loss: 29.9813\n",
      "Epoch [24/25], Train Loss: 885.9015, Eval Loss: 29.9812\n",
      "Epoch [25/25], Train Loss: 885.9008, Eval Loss: 29.9812\n",
      "Epoch [1/25], Train Loss: 8704.9843, Eval Loss: 83.7600\n",
      "Epoch [2/25], Train Loss: 2739.6229, Eval Loss: 31.3329\n",
      "Epoch [3/25], Train Loss: 1071.0003, Eval Loss: 31.5532\n",
      "Epoch [4/25], Train Loss: 1060.7461, Eval Loss: 31.3856\n",
      "Epoch [5/25], Train Loss: 1023.9530, Eval Loss: 31.4629\n",
      "Epoch [6/25], Train Loss: 1020.1377, Eval Loss: 31.4918\n",
      "Epoch [7/25], Train Loss: 1015.6672, Eval Loss: 31.8656\n",
      "Epoch [8/25], Train Loss: 1009.7297, Eval Loss: 32.2894\n",
      "Epoch [9/25], Train Loss: 1018.6491, Eval Loss: 31.2586\n",
      "Epoch [10/25], Train Loss: 996.0847, Eval Loss: 32.8286\n",
      "Epoch [11/25], Train Loss: 1021.2067, Eval Loss: 32.2462\n",
      "Epoch [12/25], Train Loss: 978.9323, Eval Loss: 33.2685\n",
      "Epoch [13/25], Train Loss: 948.5946, Eval Loss: 32.6839\n",
      "Epoch [14/25], Train Loss: 985.8011, Eval Loss: 32.6788\n",
      "Epoch [15/25], Train Loss: 974.4786, Eval Loss: 33.0368\n",
      "Epoch [16/25], Train Loss: 949.9175, Eval Loss: 34.0007\n",
      "Epoch [17/25], Train Loss: 962.6882, Eval Loss: 33.1928\n",
      "Epoch [18/25], Train Loss: 983.3057, Eval Loss: 33.8258\n",
      "Epoch [19/25], Train Loss: 957.9429, Eval Loss: 34.4748\n",
      "Epoch [20/25], Train Loss: 971.1667, Eval Loss: 33.9198\n",
      "Epoch [21/25], Train Loss: 973.0462, Eval Loss: 34.8939\n",
      "Epoch [22/25], Train Loss: 953.6053, Eval Loss: 34.1634\n",
      "Epoch [23/25], Train Loss: 965.4520, Eval Loss: 34.9669\n",
      "Epoch [24/25], Train Loss: 953.6917, Eval Loss: 36.2906\n",
      "Epoch [25/25], Train Loss: 951.4215, Eval Loss: 36.1574\n",
      "Epoch [1/25], Train Loss: 8470.9824, Eval Loss: 80.3387\n",
      "Epoch [2/25], Train Loss: 2157.7612, Eval Loss: 32.9712\n",
      "Epoch [3/25], Train Loss: 1009.2182, Eval Loss: 31.7457\n",
      "Epoch [4/25], Train Loss: 1035.4395, Eval Loss: 31.7592\n",
      "Epoch [5/25], Train Loss: 1012.6353, Eval Loss: 32.8375\n",
      "Epoch [6/25], Train Loss: 999.0067, Eval Loss: 31.4425\n",
      "Epoch [7/25], Train Loss: 996.8110, Eval Loss: 32.8066\n",
      "Epoch [8/25], Train Loss: 1005.2948, Eval Loss: 34.3151\n",
      "Epoch [9/25], Train Loss: 963.7545, Eval Loss: 33.4471\n",
      "Epoch [10/25], Train Loss: 957.4392, Eval Loss: 33.8432\n",
      "Epoch [11/25], Train Loss: 978.7781, Eval Loss: 33.7193\n",
      "Epoch [12/25], Train Loss: 948.0953, Eval Loss: 34.7334\n",
      "Epoch [13/25], Train Loss: 963.1768, Eval Loss: 33.7473\n",
      "Epoch [14/25], Train Loss: 957.9230, Eval Loss: 34.0021\n",
      "Epoch [15/25], Train Loss: 975.0270, Eval Loss: 35.7775\n",
      "Epoch [16/25], Train Loss: 948.5698, Eval Loss: 35.4598\n",
      "Epoch [17/25], Train Loss: 963.0786, Eval Loss: 34.8935\n",
      "Epoch [18/25], Train Loss: 953.4806, Eval Loss: 34.6894\n",
      "Epoch [19/25], Train Loss: 935.5730, Eval Loss: 35.4730\n",
      "Epoch [20/25], Train Loss: 923.9601, Eval Loss: 34.8513\n",
      "Epoch [21/25], Train Loss: 976.9931, Eval Loss: 36.2007\n",
      "Epoch [22/25], Train Loss: 937.3238, Eval Loss: 35.1774\n",
      "Epoch [23/25], Train Loss: 952.1821, Eval Loss: 35.1829\n",
      "Epoch [24/25], Train Loss: 960.4321, Eval Loss: 36.6822\n",
      "Epoch [25/25], Train Loss: 940.5687, Eval Loss: 36.5522\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 11848.3173, Eval Loss: 95.0131\n",
      "Epoch [2/25], Train Loss: 9289.3654, Eval Loss: 94.6667\n",
      "Epoch [3/25], Train Loss: 9202.8121, Eval Loss: 93.9078\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9279.0673, Eval Loss: 93.9231\n",
      "Epoch [2/25], Train Loss: 9008.1599, Eval Loss: 92.3550\n",
      "Epoch [3/25], Train Loss: 8743.1645, Eval Loss: 91.1732\n",
      "Epoch [4/25], Train Loss: 8531.8561, Eval Loss: 90.1940\n",
      "Epoch [5/25], Train Loss: 8354.2444, Eval Loss: 89.3330\n",
      "Epoch [6/25], Train Loss: 8200.1639, Eval Loss: 88.5461\n",
      "Epoch [7/25], Train Loss: 8060.6719, Eval Loss: 87.8048\n",
      "Epoch [8/25], Train Loss: 7928.6810, Eval Loss: 87.0934\n",
      "Epoch [9/25], Train Loss: 7804.0780, Eval Loss: 86.4034\n",
      "Epoch [10/25], Train Loss: 7683.6151, Eval Loss: 85.7300\n",
      "Epoch [11/25], Train Loss: 7566.9101, Eval Loss: 85.0700\n",
      "Epoch [12/25], Train Loss: 7453.4256, Eval Loss: 84.4211\n",
      "Epoch [13/25], Train Loss: 7342.5767, Eval Loss: 83.7818\n",
      "Epoch [14/25], Train Loss: 7234.3790, Eval Loss: 83.1510\n",
      "Epoch [15/25], Train Loss: 7128.3463, Eval Loss: 82.5278\n",
      "Epoch [16/25], Train Loss: 7024.1698, Eval Loss: 81.9114\n",
      "Epoch [17/25], Train Loss: 6921.9642, Eval Loss: 81.3013\n",
      "Epoch [18/25], Train Loss: 6821.4889, Eval Loss: 80.6970\n",
      "Epoch [19/25], Train Loss: 6722.7137, Eval Loss: 80.0982\n",
      "Epoch [20/25], Train Loss: 6625.5998, Eval Loss: 79.5046\n",
      "Epoch [21/25], Train Loss: 6529.8278, Eval Loss: 78.9158\n",
      "Epoch [22/25], Train Loss: 6435.7559, Eval Loss: 78.3317\n",
      "Epoch [23/25], Train Loss: 6342.9987, Eval Loss: 77.7521\n",
      "Epoch [24/25], Train Loss: 6251.5832, Eval Loss: 77.1767\n",
      "Epoch [25/25], Train Loss: 6161.5093, Eval Loss: 76.6054\n",
      "Epoch [1/25], Train Loss: 9258.2459, Eval Loss: 93.6825\n",
      "Epoch [2/25], Train Loss: 8965.0480, Eval Loss: 92.0704\n",
      "Epoch [3/25], Train Loss: 8698.4103, Eval Loss: 90.9204\n",
      "Epoch [4/25], Train Loss: 8491.8052, Eval Loss: 89.9916\n",
      "Epoch [5/25], Train Loss: 8321.6994, Eval Loss: 89.1470\n",
      "Epoch [6/25], Train Loss: 8168.2609, Eval Loss: 88.3539\n",
      "Epoch [7/25], Train Loss: 8026.8902, Eval Loss: 87.6104\n",
      "Epoch [8/25], Train Loss: 7895.8307, Eval Loss: 86.8980\n",
      "Epoch [9/25], Train Loss: 7770.6614, Eval Loss: 86.2077\n",
      "Epoch [10/25], Train Loss: 7650.2661, Eval Loss: 85.5338\n",
      "Epoch [11/25], Train Loss: 7533.5590, Eval Loss: 84.8733\n",
      "Epoch [12/25], Train Loss: 7420.3131, Eval Loss: 84.2240\n",
      "Epoch [13/25], Train Loss: 7309.5841, Eval Loss: 83.5843\n",
      "Epoch [14/25], Train Loss: 7201.3519, Eval Loss: 82.9529\n",
      "Epoch [15/25], Train Loss: 7095.3357, Eval Loss: 82.3291\n",
      "Epoch [16/25], Train Loss: 6991.4282, Eval Loss: 81.7121\n",
      "Epoch [17/25], Train Loss: 6889.3289, Eval Loss: 81.1013\n",
      "Epoch [18/25], Train Loss: 6788.9004, Eval Loss: 80.4964\n",
      "Epoch [19/25], Train Loss: 6690.3494, Eval Loss: 79.8969\n",
      "Epoch [20/25], Train Loss: 6593.1884, Eval Loss: 79.3025\n",
      "Epoch [21/25], Train Loss: 6497.6727, Eval Loss: 78.7130\n",
      "Epoch [22/25], Train Loss: 6403.5184, Eval Loss: 78.1281\n",
      "Epoch [23/25], Train Loss: 6310.9166, Eval Loss: 77.5476\n",
      "Epoch [24/25], Train Loss: 6219.6372, Eval Loss: 76.9714\n",
      "Epoch [25/25], Train Loss: 6129.7538, Eval Loss: 76.3994\n",
      "Epoch [1/25], Train Loss: 8292.7726, Eval Loss: 78.6715\n",
      "Epoch [2/25], Train Loss: 4911.3470, Eval Loss: 58.5204\n",
      "Epoch [3/25], Train Loss: 2837.4824, Eval Loss: 45.4516\n",
      "Epoch [4/25], Train Loss: 1820.9803, Eval Loss: 37.6327\n",
      "Epoch [5/25], Train Loss: 1325.1956, Eval Loss: 33.2830\n",
      "Epoch [6/25], Train Loss: 1083.1077, Eval Loss: 31.0120\n",
      "Epoch [7/25], Train Loss: 965.2000, Eval Loss: 29.8807\n",
      "Epoch [8/25], Train Loss: 907.6729, Eval Loss: 29.3359\n",
      "Epoch [9/25], Train Loss: 879.6986, Eval Loss: 29.0810\n",
      "Epoch [10/25], Train Loss: 866.1581, Eval Loss: 28.9659\n",
      "Epoch [11/25], Train Loss: 859.4012, Eval Loss: 28.9164\n",
      "Epoch [12/25], Train Loss: 856.2577, Eval Loss: 28.8971\n",
      "Epoch [13/25], Train Loss: 854.5400, Eval Loss: 28.8910\n",
      "Epoch [14/25], Train Loss: 853.7327, Eval Loss: 28.8904\n",
      "Epoch [15/25], Train Loss: 853.3057, Eval Loss: 28.8917\n",
      "Epoch [16/25], Train Loss: 853.2955, Eval Loss: 28.8935\n",
      "Epoch [17/25], Train Loss: 853.1178, Eval Loss: 28.8951\n",
      "Epoch [18/25], Train Loss: 853.0702, Eval Loss: 28.8965\n",
      "Epoch [19/25], Train Loss: 853.1194, Eval Loss: 28.8975\n",
      "Epoch [20/25], Train Loss: 852.9977, Eval Loss: 28.8983\n",
      "Epoch [21/25], Train Loss: 853.0101, Eval Loss: 28.8989\n",
      "Epoch [22/25], Train Loss: 853.1828, Eval Loss: 28.8993\n",
      "Epoch [23/25], Train Loss: 853.1111, Eval Loss: 28.8995\n",
      "Epoch [24/25], Train Loss: 853.0059, Eval Loss: 28.8998\n",
      "Epoch [25/25], Train Loss: 852.9891, Eval Loss: 28.8999\n",
      "Epoch [1/25], Train Loss: 8339.1197, Eval Loss: 79.1337\n",
      "Epoch [2/25], Train Loss: 4988.7312, Eval Loss: 58.8341\n",
      "Epoch [3/25], Train Loss: 2871.4832, Eval Loss: 45.6441\n",
      "Epoch [4/25], Train Loss: 1837.8647, Eval Loss: 37.7364\n",
      "Epoch [5/25], Train Loss: 1333.2865, Eval Loss: 33.3338\n",
      "Epoch [6/25], Train Loss: 1087.1015, Eval Loss: 31.0339\n",
      "Epoch [7/25], Train Loss: 967.3657, Eval Loss: 29.8888\n",
      "Epoch [8/25], Train Loss: 909.1283, Eval Loss: 29.3372\n",
      "Epoch [9/25], Train Loss: 880.2864, Eval Loss: 29.0801\n",
      "Epoch [10/25], Train Loss: 866.1167, Eval Loss: 28.9643\n",
      "Epoch [11/25], Train Loss: 859.5277, Eval Loss: 28.9151\n",
      "Epoch [12/25], Train Loss: 856.0827, Eval Loss: 28.8961\n",
      "Epoch [13/25], Train Loss: 854.4351, Eval Loss: 28.8904\n",
      "Epoch [14/25], Train Loss: 853.9161, Eval Loss: 28.8900\n",
      "Epoch [15/25], Train Loss: 853.3267, Eval Loss: 28.8916\n",
      "Epoch [16/25], Train Loss: 853.1147, Eval Loss: 28.8936\n",
      "Epoch [17/25], Train Loss: 853.2623, Eval Loss: 28.8954\n",
      "Epoch [18/25], Train Loss: 853.1857, Eval Loss: 28.8969\n",
      "Epoch [19/25], Train Loss: 852.9786, Eval Loss: 28.8980\n",
      "Epoch [20/25], Train Loss: 852.9931, Eval Loss: 28.8988\n",
      "Epoch [21/25], Train Loss: 852.9691, Eval Loss: 28.8994\n",
      "Epoch [22/25], Train Loss: 853.1497, Eval Loss: 28.8998\n",
      "Epoch [23/25], Train Loss: 853.0007, Eval Loss: 28.9002\n",
      "Epoch [24/25], Train Loss: 853.3228, Eval Loss: 28.9004\n",
      "Epoch [25/25], Train Loss: 853.0532, Eval Loss: 28.9005\n",
      "Epoch [1/25], Train Loss: 2449.9897, Eval Loss: 30.7059\n",
      "Epoch [2/25], Train Loss: 1094.2548, Eval Loss: 33.2424\n",
      "Epoch [3/25], Train Loss: 1047.9925, Eval Loss: 36.9481\n",
      "Epoch [4/25], Train Loss: 1008.0611, Eval Loss: 38.4918\n",
      "Epoch [5/25], Train Loss: 1047.1581, Eval Loss: 31.6877\n",
      "Epoch [6/25], Train Loss: 1045.5955, Eval Loss: 37.5483\n",
      "Epoch [7/25], Train Loss: 987.6161, Eval Loss: 38.4313\n",
      "Epoch [8/25], Train Loss: 968.2357, Eval Loss: 36.8936\n",
      "Epoch [9/25], Train Loss: 1038.8203, Eval Loss: 41.4740\n",
      "Epoch [10/25], Train Loss: 1010.5029, Eval Loss: 45.6569\n",
      "Epoch [11/25], Train Loss: 1001.8069, Eval Loss: 49.3159\n",
      "Epoch [12/25], Train Loss: 998.9920, Eval Loss: 48.7451\n",
      "Epoch [13/25], Train Loss: 1008.0449, Eval Loss: 46.9448\n",
      "Epoch [14/25], Train Loss: 984.8455, Eval Loss: 50.0188\n",
      "Epoch [15/25], Train Loss: 994.2348, Eval Loss: 46.5458\n",
      "Epoch [16/25], Train Loss: 974.2643, Eval Loss: 46.0374\n",
      "Epoch [17/25], Train Loss: 1007.5306, Eval Loss: 52.9589\n",
      "Epoch [18/25], Train Loss: 988.0158, Eval Loss: 55.9908\n",
      "Epoch [19/25], Train Loss: 963.7944, Eval Loss: 53.3363\n",
      "Epoch [20/25], Train Loss: 972.4406, Eval Loss: 52.4588\n",
      "Epoch [21/25], Train Loss: 972.4694, Eval Loss: 55.2201\n",
      "Epoch [22/25], Train Loss: 968.1928, Eval Loss: 54.3781\n",
      "Epoch [23/25], Train Loss: 971.7341, Eval Loss: 53.8681\n",
      "Epoch [24/25], Train Loss: 998.7530, Eval Loss: 58.2385\n",
      "Epoch [25/25], Train Loss: 956.9690, Eval Loss: 56.3992\n",
      "Epoch [1/25], Train Loss: 2674.8662, Eval Loss: 33.8148\n",
      "Epoch [2/25], Train Loss: 1057.6224, Eval Loss: 37.4477\n",
      "Epoch [3/25], Train Loss: 1037.6709, Eval Loss: 37.1207\n",
      "Epoch [4/25], Train Loss: 1082.4566, Eval Loss: 36.7760\n",
      "Epoch [5/25], Train Loss: 1024.7651, Eval Loss: 41.4184\n",
      "Epoch [6/25], Train Loss: 1009.4164, Eval Loss: 39.1273\n",
      "Epoch [7/25], Train Loss: 1002.1777, Eval Loss: 39.1461\n",
      "Epoch [8/25], Train Loss: 984.8053, Eval Loss: 40.5344\n",
      "Epoch [9/25], Train Loss: 983.7831, Eval Loss: 41.1336\n",
      "Epoch [10/25], Train Loss: 987.3506, Eval Loss: 46.5501\n",
      "Epoch [11/25], Train Loss: 996.8542, Eval Loss: 44.3335\n",
      "Epoch [12/25], Train Loss: 978.4210, Eval Loss: 44.4071\n",
      "Epoch [13/25], Train Loss: 971.7357, Eval Loss: 45.1794\n",
      "Epoch [14/25], Train Loss: 963.9853, Eval Loss: 44.4533\n",
      "Epoch [15/25], Train Loss: 983.2860, Eval Loss: 48.5802\n",
      "Epoch [16/25], Train Loss: 989.5703, Eval Loss: 51.3336\n",
      "Epoch [17/25], Train Loss: 970.1582, Eval Loss: 52.0200\n",
      "Epoch [18/25], Train Loss: 994.9468, Eval Loss: 52.9110\n",
      "Epoch [19/25], Train Loss: 974.3981, Eval Loss: 49.7985\n",
      "Epoch [20/25], Train Loss: 949.0803, Eval Loss: 50.7323\n",
      "Epoch [21/25], Train Loss: 951.2235, Eval Loss: 51.1300\n",
      "Epoch [22/25], Train Loss: 969.8658, Eval Loss: 55.0113\n",
      "Epoch [23/25], Train Loss: 978.6033, Eval Loss: 51.5910\n",
      "Epoch [24/25], Train Loss: 989.6156, Eval Loss: 53.1220\n",
      "Epoch [25/25], Train Loss: 948.7554, Eval Loss: 54.7986\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8472.9643, Eval Loss: 86.4774\n",
      "Epoch [2/25], Train Loss: 7190.7230, Eval Loss: 79.9714\n",
      "Epoch [3/25], Train Loss: 6191.8617, Eval Loss: 74.1768\n",
      "Epoch [4/25], Train Loss: 5353.8069, Eval Loss: 68.8986\n",
      "Epoch [5/25], Train Loss: 4641.7294, Eval Loss: 64.0781\n",
      "Epoch [6/25], Train Loss: 4035.5924, Eval Loss: 59.6844\n",
      "Epoch [7/25], Train Loss: 3519.9398, Eval Loss: 55.6947\n",
      "Epoch [8/25], Train Loss: 3082.0219, Eval Loss: 52.0886\n",
      "Epoch [9/25], Train Loss: 2710.7712, Eval Loss: 48.8469\n",
      "Epoch [10/25], Train Loss: 2396.7320, Eval Loss: 45.9503\n",
      "Epoch [11/25], Train Loss: 2131.6701, Eval Loss: 43.3796\n",
      "Epoch [12/25], Train Loss: 1908.5298, Eval Loss: 41.1145\n",
      "Epoch [13/25], Train Loss: 1721.1684, Eval Loss: 39.1340\n",
      "Epoch [14/25], Train Loss: 1564.3341, Eval Loss: 37.4156\n",
      "Epoch [15/25], Train Loss: 1433.4445, Eval Loss: 35.9360\n",
      "Epoch [16/25], Train Loss: 1324.5685, Eval Loss: 34.6714\n",
      "Epoch [17/25], Train Loss: 1234.2896, Eval Loss: 33.5984\n",
      "Epoch [18/25], Train Loss: 1159.6989, Eval Loss: 32.6945\n",
      "Epoch [19/25], Train Loss: 1098.3006, Eval Loss: 31.9385\n",
      "Epoch [20/25], Train Loss: 1047.9769, Eval Loss: 31.3111\n",
      "Epoch [21/25], Train Loss: 1006.9264, Eval Loss: 30.7944\n",
      "Epoch [22/25], Train Loss: 973.5976, Eval Loss: 30.3726\n",
      "Epoch [23/25], Train Loss: 946.7290, Eval Loss: 30.0315\n",
      "Epoch [24/25], Train Loss: 925.2033, Eval Loss: 29.7583\n",
      "Epoch [25/25], Train Loss: 908.0982, Eval Loss: 29.5421\n",
      "Epoch [1/25], Train Loss: 8529.9140, Eval Loss: 86.6952\n",
      "Epoch [2/25], Train Loss: 7219.6426, Eval Loss: 80.1063\n",
      "Epoch [3/25], Train Loss: 6209.9933, Eval Loss: 74.2728\n",
      "Epoch [4/25], Train Loss: 5366.2564, Eval Loss: 68.9697\n",
      "Epoch [5/25], Train Loss: 4650.4269, Eval Loss: 64.1316\n",
      "Epoch [6/25], Train Loss: 4041.6889, Eval Loss: 59.7244\n",
      "Epoch [7/25], Train Loss: 3524.1962, Eval Loss: 55.7238\n",
      "Epoch [8/25], Train Loss: 3084.9318, Eval Loss: 52.1088\n",
      "Epoch [9/25], Train Loss: 2712.6383, Eval Loss: 48.8595\n",
      "Epoch [10/25], Train Loss: 2397.8071, Eval Loss: 45.9565\n",
      "Epoch [11/25], Train Loss: 2132.1400, Eval Loss: 43.3803\n",
      "Epoch [12/25], Train Loss: 1908.5284, Eval Loss: 41.1109\n",
      "Epoch [13/25], Train Loss: 1720.8542, Eval Loss: 39.1270\n",
      "Epoch [14/25], Train Loss: 1563.7760, Eval Loss: 37.4062\n",
      "Epoch [15/25], Train Loss: 1432.7503, Eval Loss: 35.9249\n",
      "Epoch [16/25], Train Loss: 1323.7922, Eval Loss: 34.6595\n",
      "Epoch [17/25], Train Loss: 1233.4909, Eval Loss: 33.5863\n",
      "Epoch [18/25], Train Loss: 1158.9107, Eval Loss: 32.6827\n",
      "Epoch [19/25], Train Loss: 1097.5590, Eval Loss: 31.9274\n",
      "Epoch [20/25], Train Loss: 1047.2906, Eval Loss: 31.3009\n",
      "Epoch [21/25], Train Loss: 1006.3052, Eval Loss: 30.7854\n",
      "Epoch [22/25], Train Loss: 973.0604, Eval Loss: 30.3647\n",
      "Epoch [23/25], Train Loss: 946.2705, Eval Loss: 30.0247\n",
      "Epoch [24/25], Train Loss: 924.8204, Eval Loss: 29.7527\n",
      "Epoch [25/25], Train Loss: 907.7730, Eval Loss: 29.5375\n",
      "Epoch [1/25], Train Loss: 2572.9586, Eval Loss: 29.0171\n",
      "Epoch [2/25], Train Loss: 857.5728, Eval Loss: 28.9107\n",
      "Epoch [3/25], Train Loss: 856.3904, Eval Loss: 28.9114\n",
      "Epoch [4/25], Train Loss: 856.2620, Eval Loss: 28.9113\n",
      "Epoch [5/25], Train Loss: 856.4353, Eval Loss: 28.9113\n",
      "Epoch [6/25], Train Loss: 856.3569, Eval Loss: 28.9113\n",
      "Epoch [7/25], Train Loss: 856.2772, Eval Loss: 28.9113\n",
      "Epoch [8/25], Train Loss: 856.4307, Eval Loss: 28.9114\n",
      "Epoch [9/25], Train Loss: 856.1707, Eval Loss: 28.9114\n",
      "Epoch [10/25], Train Loss: 856.6140, Eval Loss: 28.9136\n",
      "Epoch [11/25], Train Loss: 856.4647, Eval Loss: 28.9118\n",
      "Epoch [12/25], Train Loss: 856.4640, Eval Loss: 28.9150\n",
      "Epoch [13/25], Train Loss: 856.3965, Eval Loss: 28.9117\n",
      "Epoch [14/25], Train Loss: 856.2906, Eval Loss: 28.9318\n",
      "Epoch [15/25], Train Loss: 858.2122, Eval Loss: 28.9110\n",
      "Epoch [16/25], Train Loss: 856.5933, Eval Loss: 28.9119\n",
      "Epoch [17/25], Train Loss: 856.4729, Eval Loss: 28.9114\n",
      "Epoch [18/25], Train Loss: 856.3495, Eval Loss: 28.9115\n",
      "Epoch [19/25], Train Loss: 856.0712, Eval Loss: 28.9120\n",
      "Epoch [20/25], Train Loss: 856.4973, Eval Loss: 28.9114\n",
      "Epoch [21/25], Train Loss: 856.1607, Eval Loss: 28.9095\n",
      "Epoch [22/25], Train Loss: 857.2246, Eval Loss: 28.9108\n",
      "Epoch [23/25], Train Loss: 856.5808, Eval Loss: 28.9236\n",
      "Epoch [24/25], Train Loss: 856.5899, Eval Loss: 28.9077\n",
      "Epoch [25/25], Train Loss: 856.6681, Eval Loss: 28.9111\n",
      "Epoch [1/25], Train Loss: 2572.5285, Eval Loss: 29.0143\n",
      "Epoch [2/25], Train Loss: 857.5490, Eval Loss: 28.9106\n",
      "Epoch [3/25], Train Loss: 856.1818, Eval Loss: 28.9116\n",
      "Epoch [4/25], Train Loss: 856.3826, Eval Loss: 28.9115\n",
      "Epoch [5/25], Train Loss: 856.3214, Eval Loss: 28.9116\n",
      "Epoch [6/25], Train Loss: 856.1145, Eval Loss: 28.9115\n",
      "Epoch [7/25], Train Loss: 856.2577, Eval Loss: 28.9116\n",
      "Epoch [8/25], Train Loss: 856.3286, Eval Loss: 28.9117\n",
      "Epoch [9/25], Train Loss: 856.0545, Eval Loss: 28.9115\n",
      "Epoch [10/25], Train Loss: 856.4977, Eval Loss: 28.9118\n",
      "Epoch [11/25], Train Loss: 856.6549, Eval Loss: 28.9125\n",
      "Epoch [12/25], Train Loss: 856.0212, Eval Loss: 28.9057\n",
      "Epoch [13/25], Train Loss: 857.4970, Eval Loss: 28.9123\n",
      "Epoch [14/25], Train Loss: 855.8891, Eval Loss: 28.9118\n",
      "Epoch [15/25], Train Loss: 856.5690, Eval Loss: 28.9099\n",
      "Epoch [16/25], Train Loss: 856.0154, Eval Loss: 28.9088\n",
      "Epoch [17/25], Train Loss: 855.2306, Eval Loss: 28.8972\n",
      "Epoch [18/25], Train Loss: 857.4621, Eval Loss: 28.9102\n",
      "Epoch [19/25], Train Loss: 856.7457, Eval Loss: 28.9026\n",
      "Epoch [20/25], Train Loss: 855.4412, Eval Loss: 28.9045\n",
      "Epoch [21/25], Train Loss: 856.3662, Eval Loss: 28.9070\n",
      "Epoch [22/25], Train Loss: 855.6757, Eval Loss: 28.8732\n",
      "Epoch [23/25], Train Loss: 1273.0730, Eval Loss: 30.2589\n",
      "Epoch [24/25], Train Loss: 874.4139, Eval Loss: 28.9722\n",
      "Epoch [25/25], Train Loss: 856.2257, Eval Loss: 28.9305\n",
      "Epoch [1/25], Train Loss: 5892.9725, Eval Loss: 52.2630\n",
      "Epoch [2/25], Train Loss: 1405.5682, Eval Loss: 50.2394\n",
      "Epoch [3/25], Train Loss: 1195.4826, Eval Loss: 44.1703\n",
      "Epoch [4/25], Train Loss: 1297.4592, Eval Loss: 55.4428\n",
      "Epoch [5/25], Train Loss: 1284.3883, Eval Loss: 55.8188\n",
      "Epoch [6/25], Train Loss: 1209.6527, Eval Loss: 58.4751\n",
      "Epoch [7/25], Train Loss: 1182.8503, Eval Loss: 61.3858\n",
      "Epoch [8/25], Train Loss: 1328.2100, Eval Loss: 50.0987\n",
      "Epoch [9/25], Train Loss: 1126.9198, Eval Loss: 56.8502\n",
      "Epoch [10/25], Train Loss: 1155.7518, Eval Loss: 61.2465\n",
      "Epoch [11/25], Train Loss: 1182.0109, Eval Loss: 62.7548\n",
      "Epoch [12/25], Train Loss: 1127.8167, Eval Loss: 61.1781\n",
      "Epoch [13/25], Train Loss: 1069.5265, Eval Loss: 58.2109\n",
      "Epoch [14/25], Train Loss: 1099.3292, Eval Loss: 61.7954\n",
      "Epoch [15/25], Train Loss: 1092.9255, Eval Loss: 60.6102\n",
      "Epoch [16/25], Train Loss: 1117.9784, Eval Loss: 60.1391\n",
      "Epoch [17/25], Train Loss: 1085.3616, Eval Loss: 58.8727\n",
      "Epoch [18/25], Train Loss: 1099.7247, Eval Loss: 64.0915\n",
      "Epoch [19/25], Train Loss: 1037.7530, Eval Loss: 64.0923\n",
      "Epoch [20/25], Train Loss: 1020.1281, Eval Loss: 68.5446\n",
      "Epoch [21/25], Train Loss: 1017.7348, Eval Loss: 62.8585\n",
      "Epoch [22/25], Train Loss: 926.0294, Eval Loss: 64.8084\n",
      "Epoch [23/25], Train Loss: 907.5768, Eval Loss: 61.8671\n",
      "Epoch [24/25], Train Loss: 875.6018, Eval Loss: 61.2853\n",
      "Epoch [25/25], Train Loss: 851.1770, Eval Loss: 61.5835\n",
      "Epoch [1/25], Train Loss: 5158.5391, Eval Loss: 32.7682\n",
      "Epoch [2/25], Train Loss: 1320.3208, Eval Loss: 35.4473\n",
      "Epoch [3/25], Train Loss: 1302.3092, Eval Loss: 36.4178\n",
      "Epoch [4/25], Train Loss: 1336.5899, Eval Loss: 46.1297\n",
      "Epoch [5/25], Train Loss: 1186.0879, Eval Loss: 33.3612\n",
      "Epoch [6/25], Train Loss: 1199.6593, Eval Loss: 43.0404\n",
      "Epoch [7/25], Train Loss: 1210.4924, Eval Loss: 40.1236\n",
      "Epoch [8/25], Train Loss: 1170.1419, Eval Loss: 46.0506\n",
      "Epoch [9/25], Train Loss: 1109.6389, Eval Loss: 47.9144\n",
      "Epoch [10/25], Train Loss: 1126.2295, Eval Loss: 49.5359\n",
      "Epoch [11/25], Train Loss: 1292.8031, Eval Loss: 55.3665\n",
      "Epoch [12/25], Train Loss: 1182.5642, Eval Loss: 50.1760\n",
      "Epoch [13/25], Train Loss: 1123.2150, Eval Loss: 54.3012\n",
      "Epoch [14/25], Train Loss: 1099.5196, Eval Loss: 53.0990\n",
      "Epoch [15/25], Train Loss: 1027.4926, Eval Loss: 50.5583\n",
      "Epoch [16/25], Train Loss: 1068.2316, Eval Loss: 49.7750\n",
      "Epoch [17/25], Train Loss: 1035.2365, Eval Loss: 54.9858\n",
      "Epoch [18/25], Train Loss: 1069.3672, Eval Loss: 54.3702\n",
      "Epoch [19/25], Train Loss: 1017.8555, Eval Loss: 54.3007\n",
      "Epoch [20/25], Train Loss: 1040.9770, Eval Loss: 55.0101\n",
      "Epoch [21/25], Train Loss: 988.9911, Eval Loss: 52.6946\n",
      "Epoch [22/25], Train Loss: 1031.3602, Eval Loss: 61.0086\n",
      "Epoch [23/25], Train Loss: 947.7030, Eval Loss: 52.3573\n",
      "Epoch [24/25], Train Loss: 923.6159, Eval Loss: 50.3914\n",
      "Epoch [25/25], Train Loss: 948.2429, Eval Loss: 56.6119\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 4974.2203, Eval Loss: 45.2250\n",
      "Epoch [2/25], Train Loss: 1417.7785, Eval Loss: 31.0128\n",
      "Epoch [3/25], Train Loss: 909.3194, Eval Loss: 29.0235\n",
      "Epoch [4/25], Train Loss: 857.0290, Eval Loss: 28.9012\n",
      "Epoch [5/25], Train Loss: 854.3801, Eval Loss: 28.9048\n",
      "Epoch [6/25], Train Loss: 855.0022, Eval Loss: 28.8901\n",
      "Epoch [7/25], Train Loss: 880.9586, Eval Loss: 28.9331\n",
      "Epoch [8/25], Train Loss: 857.0717, Eval Loss: 28.8962\n",
      "Epoch [9/25], Train Loss: 860.8413, Eval Loss: 28.9687\n",
      "Epoch [10/25], Train Loss: 858.3869, Eval Loss: 28.9171\n",
      "Epoch [11/25], Train Loss: 856.5090, Eval Loss: 28.8874\n",
      "Epoch [12/25], Train Loss: 854.7772, Eval Loss: 28.9019\n",
      "Epoch [13/25], Train Loss: 855.8414, Eval Loss: 28.9224\n",
      "Epoch [14/25], Train Loss: 856.6600, Eval Loss: 28.9967\n",
      "Epoch [15/25], Train Loss: 855.7026, Eval Loss: 28.9108\n",
      "Epoch [16/25], Train Loss: 855.3251, Eval Loss: 28.9052\n",
      "Epoch [17/25], Train Loss: 856.6700, Eval Loss: 28.9044\n",
      "Epoch [18/25], Train Loss: 856.2038, Eval Loss: 28.9030\n",
      "Epoch [19/25], Train Loss: 856.5729, Eval Loss: 28.9052\n",
      "Epoch [20/25], Train Loss: 855.6899, Eval Loss: 28.9010\n",
      "Epoch [21/25], Train Loss: 856.2446, Eval Loss: 28.9009\n",
      "Epoch [22/25], Train Loss: 856.1037, Eval Loss: 28.9012\n",
      "Epoch [23/25], Train Loss: 854.3602, Eval Loss: 28.8880\n",
      "Epoch [24/25], Train Loss: 856.2455, Eval Loss: 28.9001\n",
      "Epoch [25/25], Train Loss: 856.8010, Eval Loss: 28.8897\n",
      "Epoch [1/25], Train Loss: 4939.6746, Eval Loss: 45.1607\n",
      "Epoch [2/25], Train Loss: 1418.9843, Eval Loss: 31.0498\n",
      "Epoch [3/25], Train Loss: 918.8155, Eval Loss: 29.3198\n",
      "Epoch [4/25], Train Loss: 866.6066, Eval Loss: 28.9077\n",
      "Epoch [5/25], Train Loss: 856.4476, Eval Loss: 28.8942\n",
      "Epoch [6/25], Train Loss: 855.8200, Eval Loss: 28.9032\n",
      "Epoch [7/25], Train Loss: 854.6853, Eval Loss: 28.9059\n",
      "Epoch [8/25], Train Loss: 854.8723, Eval Loss: 28.9061\n",
      "Epoch [9/25], Train Loss: 854.9642, Eval Loss: 28.9060\n",
      "Epoch [10/25], Train Loss: 855.0624, Eval Loss: 28.9058\n",
      "Epoch [11/25], Train Loss: 855.1630, Eval Loss: 28.9056\n",
      "Epoch [12/25], Train Loss: 855.2393, Eval Loss: 28.9053\n",
      "Epoch [13/25], Train Loss: 855.3182, Eval Loss: 28.9050\n",
      "Epoch [14/25], Train Loss: 855.3878, Eval Loss: 28.9046\n",
      "Epoch [15/25], Train Loss: 855.4563, Eval Loss: 28.9041\n",
      "Epoch [16/25], Train Loss: 855.5401, Eval Loss: 28.9037\n",
      "Epoch [17/25], Train Loss: 855.6108, Eval Loss: 28.9031\n",
      "Epoch [18/25], Train Loss: 855.6285, Eval Loss: 28.9026\n",
      "Epoch [19/25], Train Loss: 855.7217, Eval Loss: 28.9022\n",
      "Epoch [20/25], Train Loss: 855.7246, Eval Loss: 28.9015\n",
      "Epoch [21/25], Train Loss: 856.7129, Eval Loss: 28.9037\n",
      "Epoch [22/25], Train Loss: 855.7464, Eval Loss: 28.9002\n",
      "Epoch [23/25], Train Loss: 855.7950, Eval Loss: 28.9009\n",
      "Epoch [24/25], Train Loss: 855.8965, Eval Loss: 28.8992\n",
      "Epoch [25/25], Train Loss: 855.9165, Eval Loss: 28.8985\n",
      "Epoch [1/25], Train Loss: 1248.3651, Eval Loss: 29.9856\n",
      "Epoch [2/25], Train Loss: 886.1562, Eval Loss: 29.9748\n",
      "Epoch [3/25], Train Loss: 885.5534, Eval Loss: 29.9854\n",
      "Epoch [4/25], Train Loss: 885.9565, Eval Loss: 29.9457\n",
      "Epoch [5/25], Train Loss: 886.2275, Eval Loss: 29.9933\n",
      "Epoch [6/25], Train Loss: 885.6877, Eval Loss: 30.0319\n",
      "Epoch [7/25], Train Loss: 886.2571, Eval Loss: 29.9815\n",
      "Epoch [8/25], Train Loss: 886.0802, Eval Loss: 29.9819\n",
      "Epoch [9/25], Train Loss: 886.1567, Eval Loss: 29.9904\n",
      "Epoch [10/25], Train Loss: 885.4900, Eval Loss: 29.9710\n",
      "Epoch [11/25], Train Loss: 885.6850, Eval Loss: 30.0367\n",
      "Epoch [12/25], Train Loss: 886.6400, Eval Loss: 29.9816\n",
      "Epoch [13/25], Train Loss: 885.7324, Eval Loss: 29.9694\n",
      "Epoch [14/25], Train Loss: 885.8500, Eval Loss: 29.9038\n",
      "Epoch [15/25], Train Loss: 885.6581, Eval Loss: 29.9514\n",
      "Epoch [16/25], Train Loss: 885.3419, Eval Loss: 29.8806\n",
      "Epoch [17/25], Train Loss: 886.0894, Eval Loss: 29.9811\n",
      "Epoch [18/25], Train Loss: 884.9327, Eval Loss: 29.9824\n",
      "Epoch [19/25], Train Loss: 886.2221, Eval Loss: 29.9768\n",
      "Epoch [20/25], Train Loss: 885.9158, Eval Loss: 29.9812\n",
      "Epoch [21/25], Train Loss: 885.9356, Eval Loss: 29.9812\n",
      "Epoch [22/25], Train Loss: 886.0421, Eval Loss: 29.9811\n",
      "Epoch [23/25], Train Loss: 886.3542, Eval Loss: 29.9838\n",
      "Epoch [24/25], Train Loss: 886.0082, Eval Loss: 29.9812\n",
      "Epoch [25/25], Train Loss: 885.7735, Eval Loss: 29.9904\n",
      "Epoch [1/25], Train Loss: 1209.7333, Eval Loss: 29.9808\n",
      "Epoch [2/25], Train Loss: 885.0456, Eval Loss: 29.9542\n",
      "Epoch [3/25], Train Loss: 885.5882, Eval Loss: 29.9816\n",
      "Epoch [4/25], Train Loss: 885.3743, Eval Loss: 29.9010\n",
      "Epoch [5/25], Train Loss: 885.1016, Eval Loss: 30.0196\n",
      "Epoch [6/25], Train Loss: 886.4808, Eval Loss: 29.9262\n",
      "Epoch [7/25], Train Loss: 886.5829, Eval Loss: 30.0025\n",
      "Epoch [8/25], Train Loss: 886.5983, Eval Loss: 30.0259\n",
      "Epoch [9/25], Train Loss: 885.9415, Eval Loss: 29.9944\n",
      "Epoch [10/25], Train Loss: 885.9231, Eval Loss: 29.9814\n",
      "Epoch [11/25], Train Loss: 886.2671, Eval Loss: 29.9993\n",
      "Epoch [12/25], Train Loss: 886.3422, Eval Loss: 29.9812\n",
      "Epoch [13/25], Train Loss: 885.8408, Eval Loss: 29.9772\n",
      "Epoch [14/25], Train Loss: 885.9783, Eval Loss: 29.9812\n",
      "Epoch [15/25], Train Loss: 887.2706, Eval Loss: 29.9952\n",
      "Epoch [16/25], Train Loss: 887.2300, Eval Loss: 29.9824\n",
      "Epoch [17/25], Train Loss: 886.0391, Eval Loss: 29.9803\n",
      "Epoch [18/25], Train Loss: 886.7439, Eval Loss: 29.9813\n",
      "Epoch [19/25], Train Loss: 885.9408, Eval Loss: 29.9812\n",
      "Epoch [20/25], Train Loss: 885.9959, Eval Loss: 29.9812\n",
      "Epoch [21/25], Train Loss: 885.9123, Eval Loss: 29.9814\n",
      "Epoch [22/25], Train Loss: 886.2618, Eval Loss: 29.9813\n",
      "Epoch [23/25], Train Loss: 885.9136, Eval Loss: 29.9815\n",
      "Epoch [24/25], Train Loss: 886.0677, Eval Loss: 29.9812\n",
      "Epoch [25/25], Train Loss: 885.8823, Eval Loss: 29.9814\n",
      "Epoch [1/25], Train Loss: 9346.8347, Eval Loss: 94.3892\n",
      "Epoch [2/25], Train Loss: 8907.7359, Eval Loss: 90.3496\n",
      "Epoch [3/25], Train Loss: 7278.3969, Eval Loss: 72.3192\n",
      "Epoch [4/25], Train Loss: 3041.5381, Eval Loss: 33.1525\n",
      "Epoch [5/25], Train Loss: 907.9480, Eval Loss: 28.9094\n",
      "Epoch [6/25], Train Loss: 854.8849, Eval Loss: 28.9089\n",
      "Epoch [7/25], Train Loss: 855.1563, Eval Loss: 28.9071\n",
      "Epoch [8/25], Train Loss: 855.1433, Eval Loss: 28.9054\n",
      "Epoch [9/25], Train Loss: 855.1241, Eval Loss: 28.9038\n",
      "Epoch [10/25], Train Loss: 855.1018, Eval Loss: 28.9020\n",
      "Epoch [11/25], Train Loss: 855.0697, Eval Loss: 28.9004\n",
      "Epoch [12/25], Train Loss: 855.0304, Eval Loss: 28.8983\n",
      "Epoch [13/25], Train Loss: 855.0089, Eval Loss: 28.8969\n",
      "Epoch [14/25], Train Loss: 854.9580, Eval Loss: 28.8955\n",
      "Epoch [15/25], Train Loss: 854.9094, Eval Loss: 28.8938\n",
      "Epoch [16/25], Train Loss: 854.8549, Eval Loss: 28.8923\n",
      "Epoch [17/25], Train Loss: 854.7990, Eval Loss: 28.8907\n",
      "Epoch [18/25], Train Loss: 854.7416, Eval Loss: 28.8891\n",
      "Epoch [19/25], Train Loss: 854.6782, Eval Loss: 28.8876\n",
      "Epoch [20/25], Train Loss: 854.6152, Eval Loss: 28.8860\n",
      "Epoch [21/25], Train Loss: 854.5480, Eval Loss: 28.8845\n",
      "Epoch [22/25], Train Loss: 854.4820, Eval Loss: 28.8828\n",
      "Epoch [23/25], Train Loss: 854.4116, Eval Loss: 28.8812\n",
      "Epoch [24/25], Train Loss: 854.3407, Eval Loss: 28.8797\n",
      "Epoch [25/25], Train Loss: 854.2687, Eval Loss: 28.8780\n",
      "Epoch [1/25], Train Loss: 9182.1009, Eval Loss: 92.6467\n",
      "Epoch [2/25], Train Loss: 8104.8949, Eval Loss: 81.4763\n",
      "Epoch [3/25], Train Loss: 4842.2618, Eval Loss: 49.3706\n",
      "Epoch [4/25], Train Loss: 1544.3643, Eval Loss: 30.7342\n",
      "Epoch [5/25], Train Loss: 891.1136, Eval Loss: 28.9293\n",
      "Epoch [6/25], Train Loss: 855.0541, Eval Loss: 28.9082\n",
      "Epoch [7/25], Train Loss: 855.0050, Eval Loss: 28.9083\n",
      "Epoch [8/25], Train Loss: 855.0822, Eval Loss: 28.9068\n",
      "Epoch [9/25], Train Loss: 855.0808, Eval Loss: 28.9053\n",
      "Epoch [10/25], Train Loss: 855.0557, Eval Loss: 28.9038\n",
      "Epoch [11/25], Train Loss: 855.0281, Eval Loss: 28.9024\n",
      "Epoch [12/25], Train Loss: 854.9919, Eval Loss: 28.9011\n",
      "Epoch [13/25], Train Loss: 854.9572, Eval Loss: 28.8999\n",
      "Epoch [14/25], Train Loss: 854.9166, Eval Loss: 28.8986\n",
      "Epoch [15/25], Train Loss: 854.8729, Eval Loss: 28.8974\n",
      "Epoch [16/25], Train Loss: 854.8266, Eval Loss: 28.8962\n",
      "Epoch [17/25], Train Loss: 854.7780, Eval Loss: 28.8950\n",
      "Epoch [18/25], Train Loss: 854.7272, Eval Loss: 28.8937\n",
      "Epoch [19/25], Train Loss: 854.6744, Eval Loss: 28.8925\n",
      "Epoch [20/25], Train Loss: 854.6198, Eval Loss: 28.8912\n",
      "Epoch [21/25], Train Loss: 854.5634, Eval Loss: 28.8900\n",
      "Epoch [22/25], Train Loss: 854.5053, Eval Loss: 28.8887\n",
      "Epoch [23/25], Train Loss: 854.4455, Eval Loss: 28.8873\n",
      "Epoch [24/25], Train Loss: 854.3859, Eval Loss: 28.8860\n",
      "Epoch [25/25], Train Loss: 854.3206, Eval Loss: 28.8846\n",
      "Epoch [1/25], Train Loss: 9493.5010, Eval Loss: 94.9256\n",
      "Epoch [2/25], Train Loss: 9255.4800, Eval Loss: 94.2869\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9993.3215, Eval Loss: 94.9076\n",
      "Epoch [2/25], Train Loss: 27665.0158, Eval Loss: 94.7066\n",
      "Epoch [3/25], Train Loss: 9220.3780, Eval Loss: 94.1875\n",
      "Epoch [4/25], Train Loss: 9022.1892, Eval Loss: 93.1383\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9309.4130, Eval Loss: 94.7415\n",
      "Epoch [2/25], Train Loss: 9219.9654, Eval Loss: 94.2003\n",
      "Epoch [3/25], Train Loss: 9104.8846, Eval Loss: 93.5530\n",
      "Epoch [4/25], Train Loss: 8980.5949, Eval Loss: 92.9034\n",
      "Epoch [5/25], Train Loss: 8861.7849, Eval Loss: 92.2986\n",
      "Epoch [6/25], Train Loss: 8754.1070, Eval Loss: 91.7548\n",
      "Epoch [7/25], Train Loss: 8657.8378, Eval Loss: 91.2621\n",
      "Epoch [8/25], Train Loss: 8570.0530, Eval Loss: 90.8042\n",
      "Epoch [9/25], Train Loss: 8488.0728, Eval Loss: 90.3710\n",
      "Epoch [10/25], Train Loss: 8410.5926, Eval Loss: 89.9584\n",
      "Epoch [11/25], Train Loss: 8336.9342, Eval Loss: 89.5629\n",
      "Epoch [12/25], Train Loss: 8266.3203, Eval Loss: 89.1807\n",
      "Epoch [13/25], Train Loss: 8198.2516, Eval Loss: 88.8097\n",
      "Epoch [14/25], Train Loss: 8132.2363, Eval Loss: 88.4475\n",
      "Epoch [15/25], Train Loss: 8067.9185, Eval Loss: 88.0925\n",
      "Epoch [16/25], Train Loss: 8005.0389, Eval Loss: 87.7436\n",
      "Epoch [17/25], Train Loss: 7943.4031, Eval Loss: 87.3999\n",
      "Epoch [18/25], Train Loss: 7882.8608, Eval Loss: 87.0606\n",
      "Epoch [19/25], Train Loss: 7823.2894, Eval Loss: 86.7253\n",
      "Epoch [20/25], Train Loss: 7764.5900, Eval Loss: 86.3934\n",
      "Epoch [21/25], Train Loss: 7706.6824, Eval Loss: 86.0646\n",
      "Epoch [22/25], Train Loss: 7649.5009, Eval Loss: 85.7385\n",
      "Epoch [23/25], Train Loss: 7592.9903, Eval Loss: 85.4150\n",
      "Epoch [24/25], Train Loss: 7537.1047, Eval Loss: 85.0937\n",
      "Epoch [25/25], Train Loss: 7481.8044, Eval Loss: 84.7746\n",
      "Epoch [1/25], Train Loss: 9346.8456, Eval Loss: 94.9600\n",
      "Epoch [2/25], Train Loss: 9266.9242, Eval Loss: 94.4615\n",
      "Epoch [3/25], Train Loss: 9156.5672, Eval Loss: 93.8190\n",
      "Epoch [4/25], Train Loss: 9027.6873, Eval Loss: 93.1201\n",
      "Epoch [5/25], Train Loss: 8897.2184, Eval Loss: 92.4491\n",
      "Epoch [6/25], Train Loss: 8778.1015, Eval Loss: 91.8526\n",
      "Epoch [7/25], Train Loss: 8673.7529, Eval Loss: 91.3261\n",
      "Epoch [8/25], Train Loss: 8581.1015, Eval Loss: 90.8493\n",
      "Epoch [9/25], Train Loss: 8496.5899, Eval Loss: 90.4070\n",
      "Epoch [10/25], Train Loss: 8417.9028, Eval Loss: 89.9898\n",
      "Epoch [11/25], Train Loss: 8343.5554, Eval Loss: 89.5914\n",
      "Epoch [12/25], Train Loss: 8272.5282, Eval Loss: 89.2074\n",
      "Epoch [13/25], Train Loss: 8204.1065, Eval Loss: 88.8347\n",
      "Epoch [14/25], Train Loss: 8137.7893, Eval Loss: 88.4710\n",
      "Epoch [15/25], Train Loss: 8073.2124, Eval Loss: 88.1147\n",
      "Epoch [16/25], Train Loss: 8010.1079, Eval Loss: 87.7647\n",
      "Epoch [17/25], Train Loss: 7948.2733, Eval Loss: 87.4200\n",
      "Epoch [18/25], Train Loss: 7887.5517, Eval Loss: 87.0798\n",
      "Epoch [19/25], Train Loss: 7827.8197, Eval Loss: 86.7437\n",
      "Epoch [20/25], Train Loss: 7768.9773, Eval Loss: 86.4111\n",
      "Epoch [21/25], Train Loss: 7710.9435, Eval Loss: 86.0817\n",
      "Epoch [22/25], Train Loss: 7653.6511, Eval Loss: 85.7551\n",
      "Epoch [23/25], Train Loss: 7597.0437, Eval Loss: 85.4311\n",
      "Epoch [24/25], Train Loss: 7541.0739, Eval Loss: 85.1094\n",
      "Epoch [25/25], Train Loss: 7485.7009, Eval Loss: 84.7900\n",
      "Epoch [1/25], Train Loss: 8803.2182, Eval Loss: 87.1060\n",
      "Epoch [2/25], Train Loss: 6784.7691, Eval Loss: 74.4613\n",
      "Epoch [3/25], Train Loss: 4995.6806, Eval Loss: 63.9080\n",
      "Epoch [4/25], Train Loss: 3738.6249, Eval Loss: 55.4309\n",
      "Epoch [5/25], Train Loss: 2862.9381, Eval Loss: 48.7153\n",
      "Epoch [6/25], Train Loss: 2252.9014, Eval Loss: 43.4819\n",
      "Epoch [7/25], Train Loss: 1827.9114, Eval Loss: 39.4777\n",
      "Epoch [8/25], Train Loss: 1531.8490, Eval Loss: 36.4717\n",
      "Epoch [9/25], Train Loss: 1325.6233, Eval Loss: 34.2555\n",
      "Epoch [10/25], Train Loss: 1181.9946, Eval Loss: 32.6480\n",
      "Epoch [11/25], Train Loss: 1081.9781, Eval Loss: 31.4979\n",
      "Epoch [12/25], Train Loss: 1012.3417, Eval Loss: 30.6846\n",
      "Epoch [13/25], Train Loss: 963.8637, Eval Loss: 30.1149\n",
      "Epoch [14/25], Train Loss: 930.1189, Eval Loss: 29.7190\n",
      "Epoch [15/25], Train Loss: 906.6316, Eval Loss: 29.4460\n",
      "Epoch [16/25], Train Loss: 890.2849, Eval Loss: 29.2589\n",
      "Epoch [17/25], Train Loss: 878.9085, Eval Loss: 29.1317\n",
      "Epoch [18/25], Train Loss: 870.9914, Eval Loss: 29.0459\n",
      "Epoch [19/25], Train Loss: 865.4817, Eval Loss: 28.9886\n",
      "Epoch [20/25], Train Loss: 861.6476, Eval Loss: 28.9507\n",
      "Epoch [21/25], Train Loss: 858.9794, Eval Loss: 28.9261\n",
      "Epoch [22/25], Train Loss: 857.1227, Eval Loss: 28.9104\n",
      "Epoch [23/25], Train Loss: 855.8307, Eval Loss: 28.9007\n",
      "Epoch [24/25], Train Loss: 854.9315, Eval Loss: 28.8949\n",
      "Epoch [25/25], Train Loss: 854.3058, Eval Loss: 28.8918\n",
      "Epoch [1/25], Train Loss: 8805.4495, Eval Loss: 87.3662\n",
      "Epoch [2/25], Train Loss: 6888.6193, Eval Loss: 75.3477\n",
      "Epoch [3/25], Train Loss: 5123.1401, Eval Loss: 64.7293\n",
      "Epoch [4/25], Train Loss: 3831.1700, Eval Loss: 56.0857\n",
      "Epoch [5/25], Train Loss: 2927.4692, Eval Loss: 49.2283\n",
      "Epoch [6/25], Train Loss: 2297.8823, Eval Loss: 43.8765\n",
      "Epoch [7/25], Train Loss: 1859.2695, Eval Loss: 39.7756\n",
      "Epoch [8/25], Train Loss: 1553.7116, Eval Loss: 36.6924\n",
      "Epoch [9/25], Train Loss: 1340.8672, Eval Loss: 34.4162\n",
      "Epoch [10/25], Train Loss: 1192.6246, Eval Loss: 32.7631\n",
      "Epoch [11/25], Train Loss: 1089.3921, Eval Loss: 31.5794\n",
      "Epoch [12/25], Train Loss: 1017.5139, Eval Loss: 30.7417\n",
      "Epoch [13/25], Train Loss: 967.4736, Eval Loss: 30.1544\n",
      "Epoch [14/25], Train Loss: 932.6401, Eval Loss: 29.7462\n",
      "Epoch [15/25], Train Loss: 908.3940, Eval Loss: 29.4645\n",
      "Epoch [16/25], Train Loss: 891.5185, Eval Loss: 29.2715\n",
      "Epoch [17/25], Train Loss: 879.7732, Eval Loss: 29.1401\n",
      "Epoch [18/25], Train Loss: 871.5990, Eval Loss: 29.0515\n",
      "Epoch [19/25], Train Loss: 865.9100, Eval Loss: 28.9922\n",
      "Epoch [20/25], Train Loss: 861.9507, Eval Loss: 28.9530\n",
      "Epoch [21/25], Train Loss: 859.1952, Eval Loss: 28.9276\n",
      "Epoch [22/25], Train Loss: 857.2775, Eval Loss: 28.9113\n",
      "Epoch [23/25], Train Loss: 855.9427, Eval Loss: 28.9012\n",
      "Epoch [24/25], Train Loss: 855.0137, Eval Loss: 28.8953\n",
      "Epoch [25/25], Train Loss: 854.3671, Eval Loss: 28.8920\n",
      "Epoch [1/25], Train Loss: 3984.3512, Eval Loss: 29.1507\n",
      "Epoch [2/25], Train Loss: 861.2140, Eval Loss: 29.0977\n",
      "Epoch [3/25], Train Loss: 858.6811, Eval Loss: 29.1040\n",
      "Epoch [4/25], Train Loss: 859.1038, Eval Loss: 29.1133\n",
      "Epoch [5/25], Train Loss: 859.3226, Eval Loss: 29.1182\n",
      "Epoch [6/25], Train Loss: 859.3648, Eval Loss: 29.1189\n",
      "Epoch [7/25], Train Loss: 859.2575, Eval Loss: 29.1157\n",
      "Epoch [8/25], Train Loss: 859.0245, Eval Loss: 29.1091\n",
      "Epoch [9/25], Train Loss: 858.6853, Eval Loss: 29.0998\n",
      "Epoch [10/25], Train Loss: 858.2545, Eval Loss: 29.0886\n",
      "Epoch [11/25], Train Loss: 857.7338, Eval Loss: 29.0769\n",
      "Epoch [12/25], Train Loss: 857.1251, Eval Loss: 29.0614\n",
      "Epoch [13/25], Train Loss: 856.5031, Eval Loss: 29.0454\n",
      "Epoch [14/25], Train Loss: 855.8350, Eval Loss: 29.0284\n",
      "Epoch [15/25], Train Loss: 855.1218, Eval Loss: 29.0105\n",
      "Epoch [16/25], Train Loss: 854.3680, Eval Loss: 28.9918\n",
      "Epoch [17/25], Train Loss: 853.5769, Eval Loss: 28.9724\n",
      "Epoch [18/25], Train Loss: 852.7492, Eval Loss: 28.9523\n",
      "Epoch [19/25], Train Loss: 851.8876, Eval Loss: 28.9316\n",
      "Epoch [20/25], Train Loss: 850.9931, Eval Loss: 28.9102\n",
      "Epoch [21/25], Train Loss: 850.0664, Eval Loss: 28.8882\n",
      "Epoch [22/25], Train Loss: 849.1073, Eval Loss: 28.8655\n",
      "Epoch [23/25], Train Loss: 848.1686, Eval Loss: 28.8424\n",
      "Epoch [24/25], Train Loss: 847.1015, Eval Loss: 28.8184\n",
      "Epoch [25/25], Train Loss: 846.0429, Eval Loss: 28.7936\n",
      "Epoch [1/25], Train Loss: 4207.6638, Eval Loss: 29.1039\n",
      "Epoch [2/25], Train Loss: 862.1346, Eval Loss: 29.0963\n",
      "Epoch [3/25], Train Loss: 859.6721, Eval Loss: 29.1207\n",
      "Epoch [4/25], Train Loss: 860.2463, Eval Loss: 29.1329\n",
      "Epoch [5/25], Train Loss: 860.5402, Eval Loss: 29.1392\n",
      "Epoch [6/25], Train Loss: 860.5304, Eval Loss: 29.1350\n",
      "Epoch [7/25], Train Loss: 860.3374, Eval Loss: 29.1279\n",
      "Epoch [8/25], Train Loss: 860.0128, Eval Loss: 29.1127\n",
      "Epoch [9/25], Train Loss: 859.7180, Eval Loss: 29.1051\n",
      "Epoch [10/25], Train Loss: 859.0194, Eval Loss: 29.0890\n",
      "Epoch [11/25], Train Loss: 858.3726, Eval Loss: 29.0643\n",
      "Epoch [12/25], Train Loss: 857.6680, Eval Loss: 29.0536\n",
      "Epoch [13/25], Train Loss: 856.9202, Eval Loss: 29.0335\n",
      "Epoch [14/25], Train Loss: 856.0855, Eval Loss: 29.0153\n",
      "Epoch [15/25], Train Loss: 855.2397, Eval Loss: 28.9956\n",
      "Epoch [16/25], Train Loss: 854.3926, Eval Loss: 28.9768\n",
      "Epoch [17/25], Train Loss: 853.4584, Eval Loss: 28.9548\n",
      "Epoch [18/25], Train Loss: 852.5075, Eval Loss: 28.9320\n",
      "Epoch [19/25], Train Loss: 851.4908, Eval Loss: 28.9110\n",
      "Epoch [20/25], Train Loss: 850.3178, Eval Loss: 28.8867\n",
      "Epoch [21/25], Train Loss: 849.2248, Eval Loss: 28.8644\n",
      "Epoch [22/25], Train Loss: 848.1175, Eval Loss: 28.8405\n",
      "Epoch [23/25], Train Loss: 846.9110, Eval Loss: 28.8110\n",
      "Epoch [24/25], Train Loss: 845.7691, Eval Loss: 28.7764\n",
      "Epoch [25/25], Train Loss: 844.5458, Eval Loss: 28.7582\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8937.6516, Eval Loss: 90.4403\n",
      "Epoch [2/25], Train Loss: 8096.7709, Eval Loss: 86.4964\n",
      "Epoch [3/25], Train Loss: 7461.3846, Eval Loss: 83.1099\n",
      "Epoch [4/25], Train Loss: 6911.2332, Eval Loss: 79.9669\n",
      "Epoch [5/25], Train Loss: 6414.1778, Eval Loss: 76.9943\n",
      "Epoch [6/25], Train Loss: 5959.3082, Eval Loss: 74.1628\n",
      "Epoch [7/25], Train Loss: 5540.8213, Eval Loss: 71.4577\n",
      "Epoch [8/25], Train Loss: 5154.8537, Eval Loss: 68.8701\n",
      "Epoch [9/25], Train Loss: 4798.4662, Eval Loss: 66.3941\n",
      "Epoch [10/25], Train Loss: 4469.2367, Eval Loss: 64.0253\n",
      "Epoch [11/25], Train Loss: 4165.0693, Eval Loss: 61.7602\n",
      "Epoch [12/25], Train Loss: 3884.0964, Eval Loss: 59.5958\n",
      "Epoch [13/25], Train Loss: 3624.6233, Eval Loss: 57.5296\n",
      "Epoch [14/25], Train Loss: 3385.0962, Eval Loss: 55.5592\n",
      "Epoch [15/25], Train Loss: 3164.0824, Eval Loss: 53.6823\n",
      "Epoch [16/25], Train Loss: 2960.2562, Eval Loss: 51.8968\n",
      "Epoch [17/25], Train Loss: 2772.3899, Eval Loss: 50.2008\n",
      "Epoch [18/25], Train Loss: 2599.3445, Eval Loss: 48.5922\n",
      "Epoch [19/25], Train Loss: 2440.0635, Eval Loss: 47.0692\n",
      "Epoch [20/25], Train Loss: 2293.5665, Eval Loss: 45.6300\n",
      "Epoch [21/25], Train Loss: 2158.9421, Eval Loss: 44.2725\n",
      "Epoch [22/25], Train Loss: 2035.3429, Eval Loss: 42.9950\n",
      "Epoch [23/25], Train Loss: 1921.9788, Eval Loss: 41.7952\n",
      "Epoch [24/25], Train Loss: 1818.1120, Eval Loss: 40.6712\n",
      "Epoch [25/25], Train Loss: 1723.0527, Eval Loss: 39.6206\n",
      "Epoch [1/25], Train Loss: 8924.8154, Eval Loss: 90.3928\n",
      "Epoch [2/25], Train Loss: 8093.7630, Eval Loss: 86.4883\n",
      "Epoch [3/25], Train Loss: 7462.4969, Eval Loss: 83.1148\n",
      "Epoch [4/25], Train Loss: 6913.9490, Eval Loss: 79.9783\n",
      "Epoch [5/25], Train Loss: 6417.6585, Eval Loss: 77.0090\n",
      "Epoch [6/25], Train Loss: 5963.1307, Eval Loss: 74.1791\n",
      "Epoch [7/25], Train Loss: 5544.7526, Eval Loss: 71.4744\n",
      "Epoch [8/25], Train Loss: 5158.7613, Eval Loss: 68.8866\n",
      "Epoch [9/25], Train Loss: 4802.2780, Eval Loss: 66.4099\n",
      "Epoch [10/25], Train Loss: 4472.9205, Eval Loss: 64.0402\n",
      "Epoch [11/25], Train Loss: 4168.6195, Eval Loss: 61.7742\n",
      "Epoch [12/25], Train Loss: 3887.5252, Eval Loss: 59.6090\n",
      "Epoch [13/25], Train Loss: 3627.9545, Eval Loss: 57.5422\n",
      "Epoch [14/25], Train Loss: 3388.3602, Eval Loss: 55.5715\n",
      "Epoch [15/25], Train Loss: 3167.3113, Eval Loss: 53.6946\n",
      "Epoch [16/25], Train Loss: 2963.4814, Eval Loss: 51.9094\n",
      "Epoch [17/25], Train Loss: 2775.6381, Eval Loss: 50.2140\n",
      "Epoch [18/25], Train Loss: 2602.6373, Eval Loss: 48.6064\n",
      "Epoch [19/25], Train Loss: 2443.4156, Eval Loss: 47.0847\n",
      "Epoch [20/25], Train Loss: 2296.9850, Eval Loss: 45.6469\n",
      "Epoch [21/25], Train Loss: 2162.4270, Eval Loss: 44.2911\n",
      "Epoch [22/25], Train Loss: 2038.8870, Eval Loss: 43.0152\n",
      "Epoch [23/25], Train Loss: 1925.5694, Eval Loss: 41.8172\n",
      "Epoch [24/25], Train Loss: 1821.7317, Eval Loss: 40.6949\n",
      "Epoch [25/25], Train Loss: 1726.6808, Eval Loss: 39.6458\n",
      "Epoch [1/25], Train Loss: 3652.4450, Eval Loss: 32.7503\n",
      "Epoch [2/25], Train Loss: 929.6186, Eval Loss: 28.9629\n",
      "Epoch [3/25], Train Loss: 856.5988, Eval Loss: 28.8965\n",
      "Epoch [4/25], Train Loss: 854.7254, Eval Loss: 28.9005\n",
      "Epoch [5/25], Train Loss: 854.6737, Eval Loss: 28.9015\n",
      "Epoch [6/25], Train Loss: 854.6695, Eval Loss: 28.9016\n",
      "Epoch [7/25], Train Loss: 854.6666, Eval Loss: 28.9016\n",
      "Epoch [8/25], Train Loss: 854.6638, Eval Loss: 28.9015\n",
      "Epoch [9/25], Train Loss: 854.6609, Eval Loss: 28.9015\n",
      "Epoch [10/25], Train Loss: 854.6580, Eval Loss: 28.9014\n",
      "Epoch [11/25], Train Loss: 854.6549, Eval Loss: 28.9014\n",
      "Epoch [12/25], Train Loss: 854.6518, Eval Loss: 28.9013\n",
      "Epoch [13/25], Train Loss: 854.6484, Eval Loss: 28.9013\n",
      "Epoch [14/25], Train Loss: 854.6449, Eval Loss: 28.9012\n",
      "Epoch [15/25], Train Loss: 854.6411, Eval Loss: 28.9011\n",
      "Epoch [16/25], Train Loss: 854.6369, Eval Loss: 28.9010\n",
      "Epoch [17/25], Train Loss: 854.6323, Eval Loss: 28.9009\n",
      "Epoch [18/25], Train Loss: 854.6270, Eval Loss: 28.9008\n",
      "Epoch [19/25], Train Loss: 854.6209, Eval Loss: 28.9007\n",
      "Epoch [20/25], Train Loss: 854.6136, Eval Loss: 28.9005\n",
      "Epoch [21/25], Train Loss: 854.6047, Eval Loss: 28.9003\n",
      "Epoch [22/25], Train Loss: 854.5929, Eval Loss: 28.9001\n",
      "Epoch [23/25], Train Loss: 854.5762, Eval Loss: 28.8996\n",
      "Epoch [24/25], Train Loss: 854.5486, Eval Loss: 28.8988\n",
      "Epoch [25/25], Train Loss: 854.4848, Eval Loss: 28.8958\n",
      "Epoch [1/25], Train Loss: 3782.6962, Eval Loss: 32.9941\n",
      "Epoch [2/25], Train Loss: 934.4469, Eval Loss: 28.9682\n",
      "Epoch [3/25], Train Loss: 856.7115, Eval Loss: 28.8962\n",
      "Epoch [4/25], Train Loss: 854.7215, Eval Loss: 28.9003\n",
      "Epoch [5/25], Train Loss: 854.6673, Eval Loss: 28.9013\n",
      "Epoch [6/25], Train Loss: 854.6625, Eval Loss: 28.9014\n",
      "Epoch [7/25], Train Loss: 854.6590, Eval Loss: 28.9014\n",
      "Epoch [8/25], Train Loss: 854.6555, Eval Loss: 28.9013\n",
      "Epoch [9/25], Train Loss: 854.6518, Eval Loss: 28.9013\n",
      "Epoch [10/25], Train Loss: 854.6480, Eval Loss: 28.9012\n",
      "Epoch [11/25], Train Loss: 854.6438, Eval Loss: 28.9011\n",
      "Epoch [12/25], Train Loss: 854.6392, Eval Loss: 28.9010\n",
      "Epoch [13/25], Train Loss: 854.6341, Eval Loss: 28.9009\n",
      "Epoch [14/25], Train Loss: 854.6282, Eval Loss: 28.9008\n",
      "Epoch [15/25], Train Loss: 854.6210, Eval Loss: 28.9006\n",
      "Epoch [16/25], Train Loss: 854.6118, Eval Loss: 28.9004\n",
      "Epoch [17/25], Train Loss: 854.5990, Eval Loss: 28.9001\n",
      "Epoch [18/25], Train Loss: 854.5782, Eval Loss: 28.8995\n",
      "Epoch [19/25], Train Loss: 854.5301, Eval Loss: 28.8973\n",
      "Epoch [20/25], Train Loss: 854.1978, Eval Loss: 28.8325\n",
      "Epoch [21/25], Train Loss: 852.8303, Eval Loss: 28.7875\n",
      "Epoch [22/25], Train Loss: 847.6487, Eval Loss: 28.5450\n",
      "Epoch [23/25], Train Loss: 840.0887, Eval Loss: 28.3005\n",
      "Epoch [24/25], Train Loss: 827.4850, Eval Loss: 28.0148\n",
      "Epoch [25/25], Train Loss: 810.8933, Eval Loss: 27.7830\n",
      "Epoch [1/25], Train Loss: 1524.3966, Eval Loss: 29.3892\n",
      "Epoch [2/25], Train Loss: 942.6730, Eval Loss: 29.3682\n",
      "Epoch [3/25], Train Loss: 925.9021, Eval Loss: 29.0260\n",
      "Epoch [4/25], Train Loss: 920.3111, Eval Loss: 28.8201\n",
      "Epoch [5/25], Train Loss: 913.2108, Eval Loss: 28.8465\n",
      "Epoch [6/25], Train Loss: 904.4432, Eval Loss: 28.7619\n",
      "Epoch [7/25], Train Loss: 896.2557, Eval Loss: 28.6641\n",
      "Epoch [8/25], Train Loss: 887.8287, Eval Loss: 28.5371\n",
      "Epoch [9/25], Train Loss: 878.7989, Eval Loss: 28.3635\n",
      "Epoch [10/25], Train Loss: 865.9320, Eval Loss: 28.0394\n",
      "Epoch [11/25], Train Loss: 859.5357, Eval Loss: 27.8506\n",
      "Epoch [12/25], Train Loss: 847.6487, Eval Loss: 27.5475\n",
      "Epoch [13/25], Train Loss: 835.3722, Eval Loss: 27.2225\n",
      "Epoch [14/25], Train Loss: 819.1887, Eval Loss: 26.8576\n",
      "Epoch [15/25], Train Loss: 806.7373, Eval Loss: 26.5019\n",
      "Epoch [16/25], Train Loss: 787.2713, Eval Loss: 26.3610\n",
      "Epoch [17/25], Train Loss: 763.6583, Eval Loss: 25.6239\n",
      "Epoch [18/25], Train Loss: 744.5097, Eval Loss: 25.2776\n",
      "Epoch [19/25], Train Loss: 710.6000, Eval Loss: 24.6417\n",
      "Epoch [20/25], Train Loss: 689.8062, Eval Loss: 24.4723\n",
      "Epoch [21/25], Train Loss: 689.4898, Eval Loss: 24.0522\n",
      "Epoch [22/25], Train Loss: 663.2967, Eval Loss: 24.1113\n",
      "Epoch [23/25], Train Loss: 642.1697, Eval Loss: 23.0842\n",
      "Epoch [24/25], Train Loss: 649.0108, Eval Loss: 22.3061\n",
      "Epoch [25/25], Train Loss: 572.4711, Eval Loss: 22.1356\n",
      "Epoch [1/25], Train Loss: 1545.4473, Eval Loss: 29.5426\n",
      "Epoch [2/25], Train Loss: 936.9316, Eval Loss: 29.5121\n",
      "Epoch [3/25], Train Loss: 926.4293, Eval Loss: 29.3012\n",
      "Epoch [4/25], Train Loss: 920.7066, Eval Loss: 29.2884\n",
      "Epoch [5/25], Train Loss: 913.8042, Eval Loss: 28.9633\n",
      "Epoch [6/25], Train Loss: 908.0486, Eval Loss: 29.0831\n",
      "Epoch [7/25], Train Loss: 906.0700, Eval Loss: 28.9137\n",
      "Epoch [8/25], Train Loss: 901.0173, Eval Loss: 28.6969\n",
      "Epoch [9/25], Train Loss: 894.4556, Eval Loss: 28.4721\n",
      "Epoch [10/25], Train Loss: 883.5951, Eval Loss: 28.8866\n",
      "Epoch [11/25], Train Loss: 872.5171, Eval Loss: 28.1518\n",
      "Epoch [12/25], Train Loss: 865.7992, Eval Loss: 28.6108\n",
      "Epoch [13/25], Train Loss: 851.0587, Eval Loss: 27.8588\n",
      "Epoch [14/25], Train Loss: 844.5954, Eval Loss: 27.9391\n",
      "Epoch [15/25], Train Loss: 828.4441, Eval Loss: 27.3951\n",
      "Epoch [16/25], Train Loss: 816.7590, Eval Loss: 27.1377\n",
      "Epoch [17/25], Train Loss: 799.0560, Eval Loss: 26.8205\n",
      "Epoch [18/25], Train Loss: 779.5374, Eval Loss: 26.6823\n",
      "Epoch [19/25], Train Loss: 756.9243, Eval Loss: 25.5617\n",
      "Epoch [20/25], Train Loss: 743.9906, Eval Loss: 25.2528\n",
      "Epoch [21/25], Train Loss: 719.2469, Eval Loss: 24.5934\n",
      "Epoch [22/25], Train Loss: 702.4882, Eval Loss: 24.1224\n",
      "Epoch [23/25], Train Loss: 686.6798, Eval Loss: 23.7396\n",
      "Epoch [24/25], Train Loss: 661.5103, Eval Loss: 23.5496\n",
      "Epoch [25/25], Train Loss: 637.3944, Eval Loss: 22.8688\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 6601.8129, Eval Loss: 64.6172\n",
      "Epoch [2/25], Train Loss: 3178.9892, Eval Loss: 45.8258\n",
      "Epoch [3/25], Train Loss: 1749.0051, Eval Loss: 35.8919\n",
      "Epoch [4/25], Train Loss: 1178.1999, Eval Loss: 31.4161\n",
      "Epoch [5/25], Train Loss: 961.8096, Eval Loss: 29.6698\n",
      "Epoch [6/25], Train Loss: 885.6103, Eval Loss: 29.0893\n",
      "Epoch [7/25], Train Loss: 861.7085, Eval Loss: 28.9329\n",
      "Epoch [8/25], Train Loss: 855.2795, Eval Loss: 28.9027\n",
      "Epoch [9/25], Train Loss: 853.8674, Eval Loss: 28.9012\n",
      "Epoch [10/25], Train Loss: 853.6634, Eval Loss: 28.9034\n",
      "Epoch [11/25], Train Loss: 853.6929, Eval Loss: 28.9049\n",
      "Epoch [12/25], Train Loss: 853.7519, Eval Loss: 28.9057\n",
      "Epoch [13/25], Train Loss: 853.8084, Eval Loss: 28.9060\n",
      "Epoch [14/25], Train Loss: 853.8604, Eval Loss: 28.9062\n",
      "Epoch [15/25], Train Loss: 853.9089, Eval Loss: 28.9063\n",
      "Epoch [16/25], Train Loss: 853.9549, Eval Loss: 28.9063\n",
      "Epoch [17/25], Train Loss: 853.9987, Eval Loss: 28.9064\n",
      "Epoch [18/25], Train Loss: 854.0405, Eval Loss: 28.9064\n",
      "Epoch [19/25], Train Loss: 854.0804, Eval Loss: 28.9064\n",
      "Epoch [20/25], Train Loss: 854.1185, Eval Loss: 28.9064\n",
      "Epoch [21/25], Train Loss: 854.1548, Eval Loss: 28.9064\n",
      "Epoch [22/25], Train Loss: 854.1895, Eval Loss: 28.9064\n",
      "Epoch [23/25], Train Loss: 854.2227, Eval Loss: 28.9064\n",
      "Epoch [24/25], Train Loss: 854.2544, Eval Loss: 28.9064\n",
      "Epoch [25/25], Train Loss: 854.2847, Eval Loss: 28.9064\n",
      "Epoch [1/25], Train Loss: 6643.9732, Eval Loss: 64.8149\n",
      "Epoch [2/25], Train Loss: 3197.8767, Eval Loss: 45.9547\n",
      "Epoch [3/25], Train Loss: 1757.8901, Eval Loss: 35.9636\n",
      "Epoch [4/25], Train Loss: 1182.1098, Eval Loss: 31.4498\n",
      "Epoch [5/25], Train Loss: 963.4081, Eval Loss: 29.6832\n",
      "Epoch [6/25], Train Loss: 886.1968, Eval Loss: 29.0937\n",
      "Epoch [7/25], Train Loss: 861.8962, Eval Loss: 28.9340\n",
      "Epoch [8/25], Train Loss: 855.3312, Eval Loss: 28.9028\n",
      "Epoch [9/25], Train Loss: 853.8796, Eval Loss: 28.9011\n",
      "Epoch [10/25], Train Loss: 853.6657, Eval Loss: 28.9033\n",
      "Epoch [11/25], Train Loss: 853.6931, Eval Loss: 28.9048\n",
      "Epoch [12/25], Train Loss: 853.7518, Eval Loss: 28.9056\n",
      "Epoch [13/25], Train Loss: 853.8081, Eval Loss: 28.9059\n",
      "Epoch [14/25], Train Loss: 853.8599, Eval Loss: 28.9061\n",
      "Epoch [15/25], Train Loss: 853.9084, Eval Loss: 28.9062\n",
      "Epoch [16/25], Train Loss: 853.9542, Eval Loss: 28.9062\n",
      "Epoch [17/25], Train Loss: 853.9979, Eval Loss: 28.9062\n",
      "Epoch [18/25], Train Loss: 854.0395, Eval Loss: 28.9062\n",
      "Epoch [19/25], Train Loss: 854.0793, Eval Loss: 28.9063\n",
      "Epoch [20/25], Train Loss: 854.1172, Eval Loss: 28.9063\n",
      "Epoch [21/25], Train Loss: 854.1535, Eval Loss: 28.9063\n",
      "Epoch [22/25], Train Loss: 854.1881, Eval Loss: 28.9063\n",
      "Epoch [23/25], Train Loss: 854.2211, Eval Loss: 28.9063\n",
      "Epoch [24/25], Train Loss: 854.2527, Eval Loss: 28.9063\n",
      "Epoch [25/25], Train Loss: 854.2830, Eval Loss: 28.9063\n",
      "Epoch [1/25], Train Loss: 1309.2203, Eval Loss: 29.3530\n",
      "Epoch [2/25], Train Loss: 869.2888, Eval Loss: 29.3533\n",
      "Epoch [3/25], Train Loss: 869.4171, Eval Loss: 29.3246\n",
      "Epoch [4/25], Train Loss: 869.2728, Eval Loss: 29.2209\n",
      "Epoch [5/25], Train Loss: 869.4197, Eval Loss: 29.3531\n",
      "Epoch [6/25], Train Loss: 869.3661, Eval Loss: 29.3534\n",
      "Epoch [7/25], Train Loss: 869.4449, Eval Loss: 29.3522\n",
      "Epoch [8/25], Train Loss: 869.3424, Eval Loss: 29.3532\n",
      "Epoch [9/25], Train Loss: 869.3425, Eval Loss: 29.3517\n",
      "Epoch [10/25], Train Loss: 869.9061, Eval Loss: 29.3972\n",
      "Epoch [11/25], Train Loss: 870.2979, Eval Loss: 29.3469\n",
      "Epoch [12/25], Train Loss: 868.7061, Eval Loss: 29.3545\n",
      "Epoch [13/25], Train Loss: 870.5358, Eval Loss: 29.4119\n",
      "Epoch [14/25], Train Loss: 869.1941, Eval Loss: 29.3554\n",
      "Epoch [15/25], Train Loss: 869.4235, Eval Loss: 29.3502\n",
      "Epoch [16/25], Train Loss: 869.3298, Eval Loss: 29.3529\n",
      "Epoch [17/25], Train Loss: 870.2222, Eval Loss: 29.3503\n",
      "Epoch [18/25], Train Loss: 869.3439, Eval Loss: 29.3537\n",
      "Epoch [19/25], Train Loss: 869.3434, Eval Loss: 29.3536\n",
      "Epoch [20/25], Train Loss: 869.8243, Eval Loss: 29.4091\n",
      "Epoch [21/25], Train Loss: 869.4661, Eval Loss: 29.3521\n",
      "Epoch [22/25], Train Loss: 869.3431, Eval Loss: 29.3535\n",
      "Epoch [23/25], Train Loss: 869.3586, Eval Loss: 29.3536\n",
      "Epoch [24/25], Train Loss: 869.3364, Eval Loss: 29.3530\n",
      "Epoch [25/25], Train Loss: 869.3927, Eval Loss: 29.3602\n",
      "Epoch [1/25], Train Loss: 1277.8949, Eval Loss: 29.3538\n",
      "Epoch [2/25], Train Loss: 869.3667, Eval Loss: 29.3537\n",
      "Epoch [3/25], Train Loss: 869.3571, Eval Loss: 29.3535\n",
      "Epoch [4/25], Train Loss: 869.3449, Eval Loss: 29.3530\n",
      "Epoch [5/25], Train Loss: 871.1756, Eval Loss: 29.3180\n",
      "Epoch [6/25], Train Loss: 869.7847, Eval Loss: 29.3526\n",
      "Epoch [7/25], Train Loss: 869.4724, Eval Loss: 29.3524\n",
      "Epoch [8/25], Train Loss: 869.8163, Eval Loss: 29.3428\n",
      "Epoch [9/25], Train Loss: 871.6154, Eval Loss: 29.2808\n",
      "Epoch [10/25], Train Loss: 871.3421, Eval Loss: 29.4335\n",
      "Epoch [11/25], Train Loss: 869.1964, Eval Loss: 29.3524\n",
      "Epoch [12/25], Train Loss: 869.1119, Eval Loss: 29.3535\n",
      "Epoch [13/25], Train Loss: 868.3683, Eval Loss: 29.3675\n",
      "Epoch [14/25], Train Loss: 868.4362, Eval Loss: 29.3529\n",
      "Epoch [15/25], Train Loss: 871.0024, Eval Loss: 29.4450\n",
      "Epoch [16/25], Train Loss: 869.4063, Eval Loss: 29.3513\n",
      "Epoch [17/25], Train Loss: 869.4435, Eval Loss: 29.3524\n",
      "Epoch [18/25], Train Loss: 870.9325, Eval Loss: 29.4413\n",
      "Epoch [19/25], Train Loss: 866.8180, Eval Loss: 28.9822\n",
      "Epoch [20/25], Train Loss: 869.0914, Eval Loss: 29.3538\n",
      "Epoch [21/25], Train Loss: 869.3456, Eval Loss: 29.3535\n",
      "Epoch [22/25], Train Loss: 869.3629, Eval Loss: 29.3539\n",
      "Epoch [23/25], Train Loss: 869.3517, Eval Loss: 29.3539\n",
      "Epoch [24/25], Train Loss: 869.3499, Eval Loss: 29.3538\n",
      "Epoch [25/25], Train Loss: 869.3465, Eval Loss: 29.3536\n",
      "Epoch [1/25], Train Loss: 9155.4677, Eval Loss: 92.5472\n",
      "Epoch [2/25], Train Loss: 7831.2911, Eval Loss: 75.0554\n",
      "Epoch [3/25], Train Loss: 2893.8443, Eval Loss: 31.0335\n",
      "Epoch [4/25], Train Loss: 873.5699, Eval Loss: 28.9079\n",
      "Epoch [5/25], Train Loss: 855.6001, Eval Loss: 28.8988\n",
      "Epoch [6/25], Train Loss: 855.5434, Eval Loss: 28.8978\n",
      "Epoch [7/25], Train Loss: 855.5275, Eval Loss: 28.8969\n",
      "Epoch [8/25], Train Loss: 855.5112, Eval Loss: 28.8960\n",
      "Epoch [9/25], Train Loss: 855.4838, Eval Loss: 28.8950\n",
      "Epoch [10/25], Train Loss: 855.4711, Eval Loss: 28.8940\n",
      "Epoch [11/25], Train Loss: 855.4487, Eval Loss: 28.8930\n",
      "Epoch [12/25], Train Loss: 855.4245, Eval Loss: 28.8919\n",
      "Epoch [13/25], Train Loss: 855.3866, Eval Loss: 28.8908\n",
      "Epoch [14/25], Train Loss: 855.3618, Eval Loss: 28.8897\n",
      "Epoch [15/25], Train Loss: 855.3350, Eval Loss: 28.8886\n",
      "Epoch [16/25], Train Loss: 855.3001, Eval Loss: 28.8874\n",
      "Epoch [17/25], Train Loss: 855.2605, Eval Loss: 28.8862\n",
      "Epoch [18/25], Train Loss: 855.2287, Eval Loss: 28.8851\n",
      "Epoch [19/25], Train Loss: 855.1847, Eval Loss: 28.8839\n",
      "Epoch [20/25], Train Loss: 855.1439, Eval Loss: 28.8827\n",
      "Epoch [21/25], Train Loss: 855.0971, Eval Loss: 28.8814\n",
      "Epoch [22/25], Train Loss: 855.0546, Eval Loss: 28.8800\n",
      "Epoch [23/25], Train Loss: 855.0032, Eval Loss: 28.8789\n",
      "Epoch [24/25], Train Loss: 854.9520, Eval Loss: 28.8777\n",
      "Epoch [25/25], Train Loss: 854.9139, Eval Loss: 28.8765\n",
      "Epoch [1/25], Train Loss: 9135.8964, Eval Loss: 91.6612\n",
      "Epoch [2/25], Train Loss: 6633.4609, Eval Loss: 54.4841\n",
      "Epoch [3/25], Train Loss: 1279.5196, Eval Loss: 28.9216\n",
      "Epoch [4/25], Train Loss: 855.4761, Eval Loss: 28.9001\n",
      "Epoch [5/25], Train Loss: 855.4292, Eval Loss: 28.9003\n",
      "Epoch [6/25], Train Loss: 855.4809, Eval Loss: 28.8998\n",
      "Epoch [7/25], Train Loss: 855.5143, Eval Loss: 28.8992\n",
      "Epoch [8/25], Train Loss: 855.5419, Eval Loss: 28.8986\n",
      "Epoch [9/25], Train Loss: 855.5601, Eval Loss: 28.8977\n",
      "Epoch [10/25], Train Loss: 855.5805, Eval Loss: 28.8970\n",
      "Epoch [11/25], Train Loss: 855.5907, Eval Loss: 28.8961\n",
      "Epoch [12/25], Train Loss: 855.5921, Eval Loss: 28.8953\n",
      "Epoch [13/25], Train Loss: 855.5071, Eval Loss: 28.8922\n",
      "Epoch [14/25], Train Loss: 855.5728, Eval Loss: 28.8923\n",
      "Epoch [15/25], Train Loss: 855.5721, Eval Loss: 28.8924\n",
      "Epoch [16/25], Train Loss: 855.5638, Eval Loss: 28.8912\n",
      "Epoch [17/25], Train Loss: 855.5344, Eval Loss: 28.8907\n",
      "Epoch [18/25], Train Loss: 855.5220, Eval Loss: 28.8899\n",
      "Epoch [19/25], Train Loss: 855.4999, Eval Loss: 28.8892\n",
      "Epoch [20/25], Train Loss: 855.4757, Eval Loss: 28.8885\n",
      "Epoch [21/25], Train Loss: 855.4149, Eval Loss: 28.8865\n",
      "Epoch [22/25], Train Loss: 855.3674, Eval Loss: 28.8857\n",
      "Epoch [23/25], Train Loss: 855.3381, Eval Loss: 28.8850\n",
      "Epoch [24/25], Train Loss: 855.3067, Eval Loss: 28.8843\n",
      "Epoch [25/25], Train Loss: 855.2737, Eval Loss: 28.8835\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 19320.1981, Eval Loss: 94.9404\n",
      "Epoch [2/25], Train Loss: 9275.3671, Eval Loss: 94.6003\n",
      "Epoch [3/25], Train Loss: 9200.3866, Eval Loss: 94.0978\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9280.8917, Eval Loss: 94.4220\n",
      "Epoch [2/25], Train Loss: 9127.6845, Eval Loss: 93.5758\n",
      "Epoch [3/25], Train Loss: 8977.0714, Eval Loss: 92.8642\n",
      "Epoch [4/25], Train Loss: 8859.1000, Eval Loss: 92.3109\n",
      "Epoch [5/25], Train Loss: 8764.3004, Eval Loss: 91.8422\n",
      "Epoch [6/25], Train Loss: 8681.6560, Eval Loss: 91.4195\n",
      "Epoch [7/25], Train Loss: 8606.1265, Eval Loss: 91.0251\n",
      "Epoch [8/25], Train Loss: 8535.1107, Eval Loss: 90.6487\n",
      "Epoch [9/25], Train Loss: 8467.1420, Eval Loss: 90.2847\n",
      "Epoch [10/25], Train Loss: 8401.3885, Eval Loss: 89.9299\n",
      "Epoch [11/25], Train Loss: 8337.3452, Eval Loss: 89.5820\n",
      "Epoch [12/25], Train Loss: 8274.6838, Eval Loss: 89.2398\n",
      "Epoch [13/25], Train Loss: 8213.1749, Eval Loss: 88.9021\n",
      "Epoch [14/25], Train Loss: 8152.6535, Eval Loss: 88.5683\n",
      "Epoch [15/25], Train Loss: 8092.9958, Eval Loss: 88.2378\n",
      "Epoch [16/25], Train Loss: 8034.1078, Eval Loss: 87.9101\n",
      "Epoch [17/25], Train Loss: 7975.9161, Eval Loss: 87.5850\n",
      "Epoch [18/25], Train Loss: 7918.3617, Eval Loss: 87.2622\n",
      "Epoch [19/25], Train Loss: 7861.3974, Eval Loss: 86.9414\n",
      "Epoch [20/25], Train Loss: 7804.9841, Eval Loss: 86.6225\n",
      "Epoch [21/25], Train Loss: 7749.0891, Eval Loss: 86.3053\n",
      "Epoch [22/25], Train Loss: 7693.6846, Eval Loss: 85.9897\n",
      "Epoch [23/25], Train Loss: 7638.7467, Eval Loss: 85.6756\n",
      "Epoch [24/25], Train Loss: 7584.2550, Eval Loss: 85.3629\n",
      "Epoch [25/25], Train Loss: 7530.1916, Eval Loss: 85.0514\n",
      "Epoch [1/25], Train Loss: 9303.1457, Eval Loss: 94.5738\n",
      "Epoch [2/25], Train Loss: 9156.2795, Eval Loss: 93.7247\n",
      "Epoch [3/25], Train Loss: 9001.9015, Eval Loss: 92.9836\n",
      "Epoch [4/25], Train Loss: 8876.4962, Eval Loss: 92.3935\n",
      "Epoch [5/25], Train Loss: 8776.4207, Eval Loss: 91.9070\n",
      "Epoch [6/25], Train Loss: 8691.3688, Eval Loss: 91.4758\n",
      "Epoch [7/25], Train Loss: 8614.4792, Eval Loss: 91.0756\n",
      "Epoch [8/25], Train Loss: 8542.4761, Eval Loss: 90.6948\n",
      "Epoch [9/25], Train Loss: 8473.7243, Eval Loss: 90.3272\n",
      "Epoch [10/25], Train Loss: 8407.3195, Eval Loss: 89.9693\n",
      "Epoch [11/25], Train Loss: 8342.7146, Eval Loss: 89.6187\n",
      "Epoch [12/25], Train Loss: 8279.5550, Eval Loss: 89.2740\n",
      "Epoch [13/25], Train Loss: 8217.5975, Eval Loss: 88.9341\n",
      "Epoch [14/25], Train Loss: 8156.6678, Eval Loss: 88.5982\n",
      "Epoch [15/25], Train Loss: 8096.6368, Eval Loss: 88.2658\n",
      "Epoch [16/25], Train Loss: 8037.4058, Eval Loss: 87.9364\n",
      "Epoch [17/25], Train Loss: 7978.8973, Eval Loss: 87.6097\n",
      "Epoch [18/25], Train Loss: 7921.0495, Eval Loss: 87.2854\n",
      "Epoch [19/25], Train Loss: 7863.8123, Eval Loss: 86.9632\n",
      "Epoch [20/25], Train Loss: 7807.1441, Eval Loss: 86.6430\n",
      "Epoch [21/25], Train Loss: 7751.0098, Eval Loss: 86.3245\n",
      "Epoch [22/25], Train Loss: 7695.3800, Eval Loss: 86.0077\n",
      "Epoch [23/25], Train Loss: 7640.2295, Eval Loss: 85.6925\n",
      "Epoch [24/25], Train Loss: 7585.5362, Eval Loss: 85.3787\n",
      "Epoch [25/25], Train Loss: 7531.2813, Eval Loss: 85.0663\n",
      "Epoch [1/25], Train Loss: 8727.2472, Eval Loss: 86.2118\n",
      "Epoch [2/25], Train Loss: 6619.8062, Eval Loss: 73.4714\n",
      "Epoch [3/25], Train Loss: 4869.3408, Eval Loss: 63.1017\n",
      "Epoch [4/25], Train Loss: 3650.2948, Eval Loss: 54.7868\n",
      "Epoch [5/25], Train Loss: 2801.3438, Eval Loss: 48.2090\n",
      "Epoch [6/25], Train Loss: 2209.9672, Eval Loss: 43.0908\n",
      "Epoch [7/25], Train Loss: 1797.9885, Eval Loss: 39.1813\n",
      "Epoch [8/25], Train Loss: 1510.9961, Eval Loss: 36.2511\n",
      "Epoch [9/25], Train Loss: 1311.0918, Eval Loss: 34.0940\n",
      "Epoch [10/25], Train Loss: 1171.8685, Eval Loss: 32.5314\n",
      "Epoch [11/25], Train Loss: 1074.9214, Eval Loss: 31.4148\n",
      "Epoch [12/25], Train Loss: 1007.4230, Eval Loss: 30.6259\n",
      "Epoch [13/25], Train Loss: 960.4340, Eval Loss: 30.0738\n",
      "Epoch [14/25], Train Loss: 927.7261, Eval Loss: 29.6904\n",
      "Epoch [15/25], Train Loss: 904.9608, Eval Loss: 29.4261\n",
      "Epoch [16/25], Train Loss: 889.1167, Eval Loss: 29.2452\n",
      "Epoch [17/25], Train Loss: 878.0901, Eval Loss: 29.1223\n",
      "Epoch [18/25], Train Loss: 870.4165, Eval Loss: 29.0394\n",
      "Epoch [19/25], Train Loss: 865.0765, Eval Loss: 28.9841\n",
      "Epoch [20/25], Train Loss: 861.3605, Eval Loss: 28.9476\n",
      "Epoch [21/25], Train Loss: 858.7746, Eval Loss: 28.9240\n",
      "Epoch [22/25], Train Loss: 856.9751, Eval Loss: 28.9089\n",
      "Epoch [23/25], Train Loss: 855.7230, Eval Loss: 28.8997\n",
      "Epoch [24/25], Train Loss: 854.8517, Eval Loss: 28.8942\n",
      "Epoch [25/25], Train Loss: 854.2454, Eval Loss: 28.8913\n",
      "Epoch [1/25], Train Loss: 8722.3788, Eval Loss: 86.2372\n",
      "Epoch [2/25], Train Loss: 6634.1228, Eval Loss: 73.5815\n",
      "Epoch [3/25], Train Loss: 4882.2188, Eval Loss: 63.1932\n",
      "Epoch [4/25], Train Loss: 3659.3294, Eval Loss: 54.8621\n",
      "Epoch [5/25], Train Loss: 2807.6761, Eval Loss: 48.2701\n",
      "Epoch [6/25], Train Loss: 2214.4047, Eval Loss: 43.1396\n",
      "Epoch [7/25], Train Loss: 1801.0988, Eval Loss: 39.2195\n",
      "Epoch [8/25], Train Loss: 1513.1773, Eval Loss: 36.2804\n",
      "Epoch [9/25], Train Loss: 1312.6228, Eval Loss: 34.1162\n",
      "Epoch [10/25], Train Loss: 1172.9440, Eval Loss: 32.5480\n",
      "Epoch [11/25], Train Loss: 1075.6778, Eval Loss: 31.4271\n",
      "Epoch [12/25], Train Loss: 1007.9557, Eval Loss: 30.6349\n",
      "Epoch [13/25], Train Loss: 960.8096, Eval Loss: 30.0803\n",
      "Epoch [14/25], Train Loss: 927.9910, Eval Loss: 29.6952\n",
      "Epoch [15/25], Train Loss: 905.1480, Eval Loss: 29.4296\n",
      "Epoch [16/25], Train Loss: 889.2491, Eval Loss: 29.2478\n",
      "Epoch [17/25], Train Loss: 878.1836, Eval Loss: 29.1242\n",
      "Epoch [18/25], Train Loss: 870.4825, Eval Loss: 29.0408\n",
      "Epoch [19/25], Train Loss: 865.1229, Eval Loss: 28.9851\n",
      "Epoch [20/25], Train Loss: 861.3927, Eval Loss: 28.9484\n",
      "Epoch [21/25], Train Loss: 858.7967, Eval Loss: 28.9245\n",
      "Epoch [22/25], Train Loss: 856.9900, Eval Loss: 28.9093\n",
      "Epoch [23/25], Train Loss: 855.7325, Eval Loss: 28.8999\n",
      "Epoch [24/25], Train Loss: 854.8574, Eval Loss: 28.8944\n",
      "Epoch [25/25], Train Loss: 854.2483, Eval Loss: 28.8914\n",
      "Epoch [1/25], Train Loss: 3128.9158, Eval Loss: 29.4361\n",
      "Epoch [2/25], Train Loss: 864.5490, Eval Loss: 29.1919\n",
      "Epoch [3/25], Train Loss: 865.7227, Eval Loss: 29.1907\n",
      "Epoch [4/25], Train Loss: 867.5398, Eval Loss: 29.1201\n",
      "Epoch [5/25], Train Loss: 868.0276, Eval Loss: 29.0460\n",
      "Epoch [6/25], Train Loss: 867.5236, Eval Loss: 28.9921\n",
      "Epoch [7/25], Train Loss: 866.6809, Eval Loss: 28.9560\n",
      "Epoch [8/25], Train Loss: 865.6436, Eval Loss: 28.9218\n",
      "Epoch [9/25], Train Loss: 864.6298, Eval Loss: 28.9014\n",
      "Epoch [10/25], Train Loss: 863.6061, Eval Loss: 28.8757\n",
      "Epoch [11/25], Train Loss: 862.5718, Eval Loss: 28.8568\n",
      "Epoch [12/25], Train Loss: 861.3882, Eval Loss: 28.8328\n",
      "Epoch [13/25], Train Loss: 860.2565, Eval Loss: 28.8139\n",
      "Epoch [14/25], Train Loss: 858.9599, Eval Loss: 28.7894\n",
      "Epoch [15/25], Train Loss: 857.5209, Eval Loss: 28.7637\n",
      "Epoch [16/25], Train Loss: 856.0770, Eval Loss: 28.7354\n",
      "Epoch [17/25], Train Loss: 854.5325, Eval Loss: 28.7045\n",
      "Epoch [18/25], Train Loss: 852.8234, Eval Loss: 28.6715\n",
      "Epoch [19/25], Train Loss: 850.9605, Eval Loss: 28.6344\n",
      "Epoch [20/25], Train Loss: 848.8896, Eval Loss: 28.5942\n",
      "Epoch [21/25], Train Loss: 846.6165, Eval Loss: 28.5488\n",
      "Epoch [22/25], Train Loss: 844.0754, Eval Loss: 28.4996\n",
      "Epoch [23/25], Train Loss: 841.2209, Eval Loss: 28.4430\n",
      "Epoch [24/25], Train Loss: 838.0888, Eval Loss: 28.3800\n",
      "Epoch [25/25], Train Loss: 834.5678, Eval Loss: 28.3097\n",
      "Epoch [1/25], Train Loss: 3495.8491, Eval Loss: 29.3319\n",
      "Epoch [2/25], Train Loss: 868.6241, Eval Loss: 29.1638\n",
      "Epoch [3/25], Train Loss: 867.7692, Eval Loss: 29.1152\n",
      "Epoch [4/25], Train Loss: 869.0591, Eval Loss: 29.0419\n",
      "Epoch [5/25], Train Loss: 868.9780, Eval Loss: 29.0054\n",
      "Epoch [6/25], Train Loss: 868.4559, Eval Loss: 28.9801\n",
      "Epoch [7/25], Train Loss: 867.9721, Eval Loss: 28.9608\n",
      "Epoch [8/25], Train Loss: 867.2592, Eval Loss: 28.9440\n",
      "Epoch [9/25], Train Loss: 866.5568, Eval Loss: 28.9291\n",
      "Epoch [10/25], Train Loss: 865.8050, Eval Loss: 28.9091\n",
      "Epoch [11/25], Train Loss: 865.0846, Eval Loss: 28.8972\n",
      "Epoch [12/25], Train Loss: 864.5045, Eval Loss: 28.8831\n",
      "Epoch [13/25], Train Loss: 863.8940, Eval Loss: 28.8729\n",
      "Epoch [14/25], Train Loss: 863.3111, Eval Loss: 28.8616\n",
      "Epoch [15/25], Train Loss: 862.6926, Eval Loss: 28.8501\n",
      "Epoch [16/25], Train Loss: 862.0550, Eval Loss: 28.8377\n",
      "Epoch [17/25], Train Loss: 861.3894, Eval Loss: 28.8244\n",
      "Epoch [18/25], Train Loss: 860.6968, Eval Loss: 28.8101\n",
      "Epoch [19/25], Train Loss: 859.9350, Eval Loss: 28.7948\n",
      "Epoch [20/25], Train Loss: 859.1968, Eval Loss: 28.7796\n",
      "Epoch [21/25], Train Loss: 858.3702, Eval Loss: 28.7626\n",
      "Epoch [22/25], Train Loss: 857.5192, Eval Loss: 28.7459\n",
      "Epoch [23/25], Train Loss: 856.6012, Eval Loss: 28.7279\n",
      "Epoch [24/25], Train Loss: 855.6295, Eval Loss: 28.7082\n",
      "Epoch [25/25], Train Loss: 854.5137, Eval Loss: 28.6867\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8816.1558, Eval Loss: 90.0727\n",
      "Epoch [2/25], Train Loss: 8079.2699, Eval Loss: 86.6000\n",
      "Epoch [3/25], Train Loss: 7495.2670, Eval Loss: 83.3992\n",
      "Epoch [4/25], Train Loss: 6967.1078, Eval Loss: 80.3606\n",
      "Epoch [5/25], Train Loss: 6481.3736, Eval Loss: 77.4532\n",
      "Epoch [6/25], Train Loss: 6032.3218, Eval Loss: 74.6640\n",
      "Epoch [7/25], Train Loss: 5616.3840, Eval Loss: 71.9858\n",
      "Epoch [8/25], Train Loss: 5230.8813, Eval Loss: 69.4144\n",
      "Epoch [9/25], Train Loss: 4873.5882, Eval Loss: 66.9467\n",
      "Epoch [10/25], Train Loss: 4542.5478, Eval Loss: 64.5804\n",
      "Epoch [11/25], Train Loss: 4235.9844, Eval Loss: 62.3134\n",
      "Epoch [12/25], Train Loss: 3952.2582, Eval Loss: 60.1440\n",
      "Epoch [13/25], Train Loss: 3689.8383, Eval Loss: 58.0703\n",
      "Epoch [14/25], Train Loss: 3447.2895, Eval Loss: 56.0907\n",
      "Epoch [15/25], Train Loss: 3223.2624, Eval Loss: 54.2035\n",
      "Epoch [16/25], Train Loss: 3016.4878, Eval Loss: 52.4069\n",
      "Epoch [17/25], Train Loss: 2825.7730, Eval Loss: 50.6992\n",
      "Epoch [18/25], Train Loss: 2649.9981, Eval Loss: 49.0787\n",
      "Epoch [19/25], Train Loss: 2488.1134, Eval Loss: 47.5436\n",
      "Epoch [20/25], Train Loss: 2339.1365, Eval Loss: 46.0919\n",
      "Epoch [21/25], Train Loss: 2202.1485, Eval Loss: 44.7218\n",
      "Epoch [22/25], Train Loss: 2076.2908, Eval Loss: 43.4313\n",
      "Epoch [23/25], Train Loss: 1960.7615, Eval Loss: 42.2183\n",
      "Epoch [24/25], Train Loss: 1854.8114, Eval Loss: 41.0805\n",
      "Epoch [25/25], Train Loss: 1757.7403, Eval Loss: 40.0156\n",
      "Epoch [1/25], Train Loss: 8865.6763, Eval Loss: 90.4299\n",
      "Epoch [2/25], Train Loss: 8140.5805, Eval Loss: 86.9179\n",
      "Epoch [3/25], Train Loss: 7550.1751, Eval Loss: 83.7022\n",
      "Epoch [4/25], Train Loss: 7018.2153, Eval Loss: 80.6552\n",
      "Epoch [5/25], Train Loss: 6529.6007, Eval Loss: 77.7423\n",
      "Epoch [6/25], Train Loss: 6078.1319, Eval Loss: 74.9488\n",
      "Epoch [7/25], Train Loss: 5660.0450, Eval Loss: 72.2671\n",
      "Epoch [8/25], Train Loss: 5272.5583, Eval Loss: 69.6925\n",
      "Epoch [9/25], Train Loss: 4913.3842, Eval Loss: 67.2214\n",
      "Epoch [10/25], Train Loss: 4580.5260, Eval Loss: 64.8514\n",
      "Epoch [11/25], Train Loss: 4272.1824, Eval Loss: 62.5803\n",
      "Epoch [12/25], Train Loss: 3986.6953, Eval Loss: 60.4061\n",
      "Epoch [13/25], Train Loss: 3722.5243, Eval Loss: 58.3270\n",
      "Epoch [14/25], Train Loss: 3478.2282, Eval Loss: 56.3411\n",
      "Epoch [15/25], Train Loss: 3252.4568, Eval Loss: 54.4468\n",
      "Epoch [16/25], Train Loss: 3043.9430, Eval Loss: 52.6423\n",
      "Epoch [17/25], Train Loss: 2851.4991, Eval Loss: 50.9259\n",
      "Epoch [18/25], Train Loss: 2674.0129, Eval Loss: 49.2959\n",
      "Epoch [19/25], Train Loss: 2510.4431, Eval Loss: 47.7506\n",
      "Epoch [20/25], Train Loss: 2359.8170, Eval Loss: 46.2882\n",
      "Epoch [21/25], Train Loss: 2221.2253, Eval Loss: 44.9069\n",
      "Epoch [22/25], Train Loss: 2093.8191, Eval Loss: 43.6049\n",
      "Epoch [23/25], Train Loss: 1976.8048, Eval Loss: 42.3803\n",
      "Epoch [24/25], Train Loss: 1869.4406, Eval Loss: 41.2309\n",
      "Epoch [25/25], Train Loss: 1771.0326, Eval Loss: 40.1545\n",
      "Epoch [1/25], Train Loss: 3585.7999, Eval Loss: 32.6152\n",
      "Epoch [2/25], Train Loss: 926.8644, Eval Loss: 28.9597\n",
      "Epoch [3/25], Train Loss: 856.5021, Eval Loss: 28.8963\n",
      "Epoch [4/25], Train Loss: 854.7048, Eval Loss: 28.9003\n",
      "Epoch [5/25], Train Loss: 854.6585, Eval Loss: 28.9013\n",
      "Epoch [6/25], Train Loss: 854.6569, Eval Loss: 28.9014\n",
      "Epoch [7/25], Train Loss: 854.6564, Eval Loss: 28.9014\n",
      "Epoch [8/25], Train Loss: 854.6559, Eval Loss: 28.9014\n",
      "Epoch [9/25], Train Loss: 854.6555, Eval Loss: 28.9014\n",
      "Epoch [10/25], Train Loss: 854.6550, Eval Loss: 28.9014\n",
      "Epoch [11/25], Train Loss: 854.6545, Eval Loss: 28.9014\n",
      "Epoch [12/25], Train Loss: 854.6541, Eval Loss: 28.9014\n",
      "Epoch [13/25], Train Loss: 854.6536, Eval Loss: 28.9014\n",
      "Epoch [14/25], Train Loss: 854.6531, Eval Loss: 28.9014\n",
      "Epoch [15/25], Train Loss: 854.6527, Eval Loss: 28.9014\n",
      "Epoch [16/25], Train Loss: 854.6521, Eval Loss: 28.9014\n",
      "Epoch [17/25], Train Loss: 854.6516, Eval Loss: 28.9014\n",
      "Epoch [18/25], Train Loss: 854.6511, Eval Loss: 28.9013\n",
      "Epoch [19/25], Train Loss: 854.6506, Eval Loss: 28.9013\n",
      "Epoch [20/25], Train Loss: 854.6501, Eval Loss: 28.9013\n",
      "Epoch [21/25], Train Loss: 854.6495, Eval Loss: 28.9013\n",
      "Epoch [22/25], Train Loss: 854.6489, Eval Loss: 28.9013\n",
      "Epoch [23/25], Train Loss: 854.6483, Eval Loss: 28.9013\n",
      "Epoch [24/25], Train Loss: 854.6476, Eval Loss: 28.9013\n",
      "Epoch [25/25], Train Loss: 854.6470, Eval Loss: 28.9013\n",
      "Epoch [1/25], Train Loss: 3623.5617, Eval Loss: 32.6798\n",
      "Epoch [2/25], Train Loss: 928.2303, Eval Loss: 28.9609\n",
      "Epoch [3/25], Train Loss: 856.5475, Eval Loss: 28.8961\n",
      "Epoch [4/25], Train Loss: 854.7070, Eval Loss: 28.9002\n",
      "Epoch [5/25], Train Loss: 854.6581, Eval Loss: 28.9012\n",
      "Epoch [6/25], Train Loss: 854.6563, Eval Loss: 28.9014\n",
      "Epoch [7/25], Train Loss: 854.6558, Eval Loss: 28.9014\n",
      "Epoch [8/25], Train Loss: 854.6554, Eval Loss: 28.9014\n",
      "Epoch [9/25], Train Loss: 854.6550, Eval Loss: 28.9014\n",
      "Epoch [10/25], Train Loss: 854.6546, Eval Loss: 28.9014\n",
      "Epoch [11/25], Train Loss: 854.6542, Eval Loss: 28.9014\n",
      "Epoch [12/25], Train Loss: 854.6537, Eval Loss: 28.9013\n",
      "Epoch [13/25], Train Loss: 854.6533, Eval Loss: 28.9013\n",
      "Epoch [14/25], Train Loss: 854.6529, Eval Loss: 28.9013\n",
      "Epoch [15/25], Train Loss: 854.6525, Eval Loss: 28.9013\n",
      "Epoch [16/25], Train Loss: 854.6521, Eval Loss: 28.9013\n",
      "Epoch [17/25], Train Loss: 854.6516, Eval Loss: 28.9013\n",
      "Epoch [18/25], Train Loss: 854.6511, Eval Loss: 28.9013\n",
      "Epoch [19/25], Train Loss: 854.6506, Eval Loss: 28.9013\n",
      "Epoch [20/25], Train Loss: 854.6502, Eval Loss: 28.9013\n",
      "Epoch [21/25], Train Loss: 854.6496, Eval Loss: 28.9013\n",
      "Epoch [22/25], Train Loss: 854.6491, Eval Loss: 28.9013\n",
      "Epoch [23/25], Train Loss: 854.6485, Eval Loss: 28.9012\n",
      "Epoch [24/25], Train Loss: 854.6479, Eval Loss: 28.9012\n",
      "Epoch [25/25], Train Loss: 854.6473, Eval Loss: 28.9012\n",
      "Epoch [1/25], Train Loss: 1701.9045, Eval Loss: 29.7450\n",
      "Epoch [2/25], Train Loss: 958.9030, Eval Loss: 29.9704\n",
      "Epoch [3/25], Train Loss: 961.1603, Eval Loss: 30.8975\n",
      "Epoch [4/25], Train Loss: 959.4805, Eval Loss: 30.8601\n",
      "Epoch [5/25], Train Loss: 951.7178, Eval Loss: 30.3393\n",
      "Epoch [6/25], Train Loss: 940.8853, Eval Loss: 29.9159\n",
      "Epoch [7/25], Train Loss: 930.2387, Eval Loss: 29.6273\n",
      "Epoch [8/25], Train Loss: 917.6163, Eval Loss: 29.4515\n",
      "Epoch [9/25], Train Loss: 900.9899, Eval Loss: 29.1806\n",
      "Epoch [10/25], Train Loss: 874.0370, Eval Loss: 28.9109\n",
      "Epoch [11/25], Train Loss: 883.6130, Eval Loss: 27.4194\n",
      "Epoch [12/25], Train Loss: 800.0038, Eval Loss: 26.8468\n",
      "Epoch [13/25], Train Loss: 762.2925, Eval Loss: 25.7240\n",
      "Epoch [14/25], Train Loss: 732.4760, Eval Loss: 24.8868\n",
      "Epoch [15/25], Train Loss: 718.7310, Eval Loss: 24.5645\n",
      "Epoch [16/25], Train Loss: 695.8379, Eval Loss: 24.3657\n",
      "Epoch [17/25], Train Loss: 685.2506, Eval Loss: 24.4569\n",
      "Epoch [18/25], Train Loss: 667.4322, Eval Loss: 24.1495\n",
      "Epoch [19/25], Train Loss: 675.1075, Eval Loss: 24.5502\n",
      "Epoch [20/25], Train Loss: 672.0531, Eval Loss: 24.5065\n",
      "Epoch [21/25], Train Loss: 666.2531, Eval Loss: 24.1206\n",
      "Epoch [22/25], Train Loss: 655.5316, Eval Loss: 23.7125\n",
      "Epoch [23/25], Train Loss: 642.6699, Eval Loss: 23.6199\n",
      "Epoch [24/25], Train Loss: 635.9742, Eval Loss: 23.3894\n",
      "Epoch [25/25], Train Loss: 625.3417, Eval Loss: 23.3522\n",
      "Epoch [1/25], Train Loss: 1860.7344, Eval Loss: 29.1422\n",
      "Epoch [2/25], Train Loss: 951.3024, Eval Loss: 29.8440\n",
      "Epoch [3/25], Train Loss: 945.8119, Eval Loss: 28.9896\n",
      "Epoch [4/25], Train Loss: 941.5664, Eval Loss: 28.8287\n",
      "Epoch [5/25], Train Loss: 936.3819, Eval Loss: 28.7810\n",
      "Epoch [6/25], Train Loss: 923.1165, Eval Loss: 28.8100\n",
      "Epoch [7/25], Train Loss: 920.2689, Eval Loss: 28.5829\n",
      "Epoch [8/25], Train Loss: 910.7596, Eval Loss: 28.3910\n",
      "Epoch [9/25], Train Loss: 898.5247, Eval Loss: 28.1488\n",
      "Epoch [10/25], Train Loss: 882.8109, Eval Loss: 27.8344\n",
      "Epoch [11/25], Train Loss: 861.7260, Eval Loss: 27.4181\n",
      "Epoch [12/25], Train Loss: 833.1134, Eval Loss: 26.8888\n",
      "Epoch [13/25], Train Loss: 796.0550, Eval Loss: 26.3591\n",
      "Epoch [14/25], Train Loss: 760.6671, Eval Loss: 25.5797\n",
      "Epoch [15/25], Train Loss: 736.3913, Eval Loss: 24.8682\n",
      "Epoch [16/25], Train Loss: 715.6479, Eval Loss: 24.5891\n",
      "Epoch [17/25], Train Loss: 703.6813, Eval Loss: 24.6206\n",
      "Epoch [18/25], Train Loss: 694.5738, Eval Loss: 24.6073\n",
      "Epoch [19/25], Train Loss: 678.5139, Eval Loss: 23.9601\n",
      "Epoch [20/25], Train Loss: 674.8453, Eval Loss: 24.5085\n",
      "Epoch [21/25], Train Loss: 716.2096, Eval Loss: 23.7809\n",
      "Epoch [22/25], Train Loss: 617.7417, Eval Loss: 24.0043\n",
      "Epoch [23/25], Train Loss: 592.4416, Eval Loss: 21.2556\n",
      "Epoch [24/25], Train Loss: 526.9796, Eval Loss: 20.0387\n",
      "Epoch [25/25], Train Loss: 484.9225, Eval Loss: 19.4133\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 6636.1149, Eval Loss: 65.0882\n",
      "Epoch [2/25], Train Loss: 3235.4583, Eval Loss: 46.2704\n",
      "Epoch [3/25], Train Loss: 1781.8944, Eval Loss: 36.1610\n",
      "Epoch [4/25], Train Loss: 1193.7270, Eval Loss: 31.5467\n",
      "Epoch [5/25], Train Loss: 968.4022, Eval Loss: 29.7241\n",
      "Epoch [6/25], Train Loss: 888.1253, Eval Loss: 29.1079\n",
      "Epoch [7/25], Train Loss: 862.5330, Eval Loss: 28.9377\n",
      "Epoch [8/25], Train Loss: 855.4973, Eval Loss: 28.9033\n",
      "Epoch [9/25], Train Loss: 853.9027, Eval Loss: 28.9009\n",
      "Epoch [10/25], Train Loss: 853.6534, Eval Loss: 28.9031\n",
      "Epoch [11/25], Train Loss: 853.6740, Eval Loss: 28.9047\n",
      "Epoch [12/25], Train Loss: 853.7319, Eval Loss: 28.9055\n",
      "Epoch [13/25], Train Loss: 853.7884, Eval Loss: 28.9059\n",
      "Epoch [14/25], Train Loss: 853.8404, Eval Loss: 28.9061\n",
      "Epoch [15/25], Train Loss: 853.8891, Eval Loss: 28.9062\n",
      "Epoch [16/25], Train Loss: 853.9353, Eval Loss: 28.9063\n",
      "Epoch [17/25], Train Loss: 853.9793, Eval Loss: 28.9063\n",
      "Epoch [18/25], Train Loss: 854.0214, Eval Loss: 28.9063\n",
      "Epoch [19/25], Train Loss: 854.0617, Eval Loss: 28.9064\n",
      "Epoch [20/25], Train Loss: 854.1001, Eval Loss: 28.9064\n",
      "Epoch [21/25], Train Loss: 854.1370, Eval Loss: 28.9064\n",
      "Epoch [22/25], Train Loss: 854.1721, Eval Loss: 28.9064\n",
      "Epoch [23/25], Train Loss: 854.2058, Eval Loss: 28.9064\n",
      "Epoch [24/25], Train Loss: 854.2380, Eval Loss: 28.9064\n",
      "Epoch [25/25], Train Loss: 854.2689, Eval Loss: 28.9064\n",
      "Epoch [1/25], Train Loss: 6583.2981, Eval Loss: 64.7654\n",
      "Epoch [2/25], Train Loss: 3204.1291, Eval Loss: 46.0683\n",
      "Epoch [3/25], Train Loss: 1769.4631, Eval Loss: 36.0856\n",
      "Epoch [4/25], Train Loss: 1190.0484, Eval Loss: 31.5276\n",
      "Epoch [5/25], Train Loss: 967.4290, Eval Loss: 29.7197\n",
      "Epoch [6/25], Train Loss: 887.8568, Eval Loss: 29.1068\n",
      "Epoch [7/25], Train Loss: 862.4626, Eval Loss: 28.9375\n",
      "Epoch [8/25], Train Loss: 855.4871, Eval Loss: 28.9033\n",
      "Epoch [9/25], Train Loss: 853.9093, Eval Loss: 28.9010\n",
      "Epoch [10/25], Train Loss: 853.6639, Eval Loss: 28.9032\n",
      "Epoch [11/25], Train Loss: 853.6852, Eval Loss: 28.9048\n",
      "Epoch [12/25], Train Loss: 853.7432, Eval Loss: 28.9056\n",
      "Epoch [13/25], Train Loss: 853.7998, Eval Loss: 28.9060\n",
      "Epoch [14/25], Train Loss: 853.8519, Eval Loss: 28.9062\n",
      "Epoch [15/25], Train Loss: 853.9007, Eval Loss: 28.9063\n",
      "Epoch [16/25], Train Loss: 853.9469, Eval Loss: 28.9064\n",
      "Epoch [17/25], Train Loss: 853.9910, Eval Loss: 28.9064\n",
      "Epoch [18/25], Train Loss: 854.0330, Eval Loss: 28.9064\n",
      "Epoch [19/25], Train Loss: 854.0732, Eval Loss: 28.9064\n",
      "Epoch [20/25], Train Loss: 854.1116, Eval Loss: 28.9064\n",
      "Epoch [21/25], Train Loss: 854.1483, Eval Loss: 28.9064\n",
      "Epoch [22/25], Train Loss: 854.1834, Eval Loss: 28.9064\n",
      "Epoch [23/25], Train Loss: 854.2169, Eval Loss: 28.9064\n",
      "Epoch [24/25], Train Loss: 854.2488, Eval Loss: 28.9064\n",
      "Epoch [25/25], Train Loss: 854.2794, Eval Loss: 28.9064\n",
      "Epoch [1/25], Train Loss: 1330.8996, Eval Loss: 29.3539\n",
      "Epoch [2/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [3/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [4/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [5/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [6/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [7/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [8/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [9/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [10/25], Train Loss: 869.3526, Eval Loss: 29.3539\n",
      "Epoch [11/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [12/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [13/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [14/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [15/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [16/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [17/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [18/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [19/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [20/25], Train Loss: 869.3526, Eval Loss: 29.3539\n",
      "Epoch [21/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [22/25], Train Loss: 869.3526, Eval Loss: 29.3539\n",
      "Epoch [23/25], Train Loss: 869.3526, Eval Loss: 29.3539\n",
      "Epoch [24/25], Train Loss: 869.3527, Eval Loss: 29.3539\n",
      "Epoch [25/25], Train Loss: 869.3526, Eval Loss: 29.3539\n",
      "Epoch [1/25], Train Loss: 1271.5229, Eval Loss: 29.3538\n",
      "Epoch [2/25], Train Loss: 869.3516, Eval Loss: 29.3538\n",
      "Epoch [3/25], Train Loss: 869.3514, Eval Loss: 29.3538\n",
      "Epoch [4/25], Train Loss: 869.3513, Eval Loss: 29.3538\n",
      "Epoch [5/25], Train Loss: 869.3511, Eval Loss: 29.3538\n",
      "Epoch [6/25], Train Loss: 869.3509, Eval Loss: 29.3538\n",
      "Epoch [7/25], Train Loss: 869.3508, Eval Loss: 29.3538\n",
      "Epoch [8/25], Train Loss: 869.3505, Eval Loss: 29.3538\n",
      "Epoch [9/25], Train Loss: 869.3504, Eval Loss: 29.3538\n",
      "Epoch [10/25], Train Loss: 869.3502, Eval Loss: 29.3538\n",
      "Epoch [11/25], Train Loss: 869.3499, Eval Loss: 29.3538\n",
      "Epoch [12/25], Train Loss: 869.3497, Eval Loss: 29.3538\n",
      "Epoch [13/25], Train Loss: 869.3494, Eval Loss: 29.3538\n",
      "Epoch [14/25], Train Loss: 869.3490, Eval Loss: 29.3537\n",
      "Epoch [15/25], Train Loss: 869.3486, Eval Loss: 29.3537\n",
      "Epoch [16/25], Train Loss: 869.3482, Eval Loss: 29.3537\n",
      "Epoch [17/25], Train Loss: 869.3476, Eval Loss: 29.3537\n",
      "Epoch [18/25], Train Loss: 869.3468, Eval Loss: 29.3536\n",
      "Epoch [19/25], Train Loss: 869.3459, Eval Loss: 29.3535\n",
      "Epoch [20/25], Train Loss: 869.3447, Eval Loss: 29.3534\n",
      "Epoch [21/25], Train Loss: 869.3434, Eval Loss: 29.3533\n",
      "Epoch [22/25], Train Loss: 869.3419, Eval Loss: 29.3530\n",
      "Epoch [23/25], Train Loss: 869.3407, Eval Loss: 29.3527\n",
      "Epoch [24/25], Train Loss: 869.3435, Eval Loss: 29.3522\n",
      "Epoch [25/25], Train Loss: 869.3387, Eval Loss: 29.3519\n",
      "Epoch [1/25], Train Loss: 9182.1319, Eval Loss: 92.3667\n",
      "Epoch [2/25], Train Loss: 7277.0155, Eval Loss: 62.8640\n",
      "Epoch [3/25], Train Loss: 1519.7534, Eval Loss: 28.9410\n",
      "Epoch [4/25], Train Loss: 914.8127, Eval Loss: 28.9085\n",
      "Epoch [5/25], Train Loss: 931.1273, Eval Loss: 28.9396\n",
      "Epoch [6/25], Train Loss: 909.7872, Eval Loss: 28.9353\n",
      "Epoch [7/25], Train Loss: 914.3571, Eval Loss: 28.9048\n",
      "Epoch [8/25], Train Loss: 912.0874, Eval Loss: 28.9315\n",
      "Epoch [9/25], Train Loss: 910.3485, Eval Loss: 28.9444\n",
      "Epoch [10/25], Train Loss: 883.4669, Eval Loss: 28.9242\n",
      "Epoch [11/25], Train Loss: 902.1004, Eval Loss: 28.9575\n",
      "Epoch [12/25], Train Loss: 931.5657, Eval Loss: 28.9173\n",
      "Epoch [13/25], Train Loss: 913.3610, Eval Loss: 28.9597\n",
      "Epoch [14/25], Train Loss: 901.1038, Eval Loss: 28.9236\n",
      "Epoch [15/25], Train Loss: 892.3437, Eval Loss: 28.9519\n",
      "Epoch [16/25], Train Loss: 895.1629, Eval Loss: 28.9184\n",
      "Epoch [17/25], Train Loss: 924.0683, Eval Loss: 28.9400\n",
      "Epoch [18/25], Train Loss: 893.7664, Eval Loss: 28.9248\n",
      "Epoch [19/25], Train Loss: 892.0641, Eval Loss: 28.9191\n",
      "Epoch [20/25], Train Loss: 899.9325, Eval Loss: 28.9392\n",
      "Epoch [21/25], Train Loss: 908.9467, Eval Loss: 28.9077\n",
      "Epoch [22/25], Train Loss: 895.7371, Eval Loss: 28.8985\n",
      "Epoch [23/25], Train Loss: 898.0063, Eval Loss: 28.8803\n",
      "Epoch [24/25], Train Loss: 890.7811, Eval Loss: 28.9213\n",
      "Epoch [25/25], Train Loss: 901.4059, Eval Loss: 28.9284\n",
      "Epoch [1/25], Train Loss: 9132.0723, Eval Loss: 91.3775\n",
      "Epoch [2/25], Train Loss: 6953.8139, Eval Loss: 60.3828\n",
      "Epoch [3/25], Train Loss: 1605.4307, Eval Loss: 28.9750\n",
      "Epoch [4/25], Train Loss: 908.8178, Eval Loss: 28.9343\n",
      "Epoch [5/25], Train Loss: 914.2443, Eval Loss: 28.9338\n",
      "Epoch [6/25], Train Loss: 926.8646, Eval Loss: 28.9170\n",
      "Epoch [7/25], Train Loss: 913.2839, Eval Loss: 28.9299\n",
      "Epoch [8/25], Train Loss: 919.4215, Eval Loss: 28.9769\n",
      "Epoch [9/25], Train Loss: 905.6210, Eval Loss: 28.9538\n",
      "Epoch [10/25], Train Loss: 896.6963, Eval Loss: 28.9266\n",
      "Epoch [11/25], Train Loss: 922.0199, Eval Loss: 28.9353\n",
      "Epoch [12/25], Train Loss: 909.0288, Eval Loss: 28.9200\n",
      "Epoch [13/25], Train Loss: 888.7362, Eval Loss: 28.9414\n",
      "Epoch [14/25], Train Loss: 885.4591, Eval Loss: 28.9316\n",
      "Epoch [15/25], Train Loss: 893.6648, Eval Loss: 29.0010\n",
      "Epoch [16/25], Train Loss: 908.3723, Eval Loss: 28.9182\n",
      "Epoch [17/25], Train Loss: 914.7901, Eval Loss: 28.9796\n",
      "Epoch [18/25], Train Loss: 901.8789, Eval Loss: 28.9558\n",
      "Epoch [19/25], Train Loss: 894.0344, Eval Loss: 28.9799\n",
      "Epoch [20/25], Train Loss: 911.7309, Eval Loss: 28.9198\n",
      "Epoch [21/25], Train Loss: 895.1095, Eval Loss: 28.9158\n",
      "Epoch [22/25], Train Loss: 894.9999, Eval Loss: 28.9521\n",
      "Epoch [23/25], Train Loss: 905.6140, Eval Loss: 28.9461\n",
      "Epoch [24/25], Train Loss: 887.5027, Eval Loss: 28.9739\n",
      "Epoch [25/25], Train Loss: 883.6722, Eval Loss: 28.9452\n",
      "Epoch [1/25], Train Loss: 137666.5691, Eval Loss: 95.1152\n",
      "Epoch [2/25], Train Loss: 9303.6511, Eval Loss: 94.6728\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9331.8520, Eval Loss: 94.7438\n",
      "Epoch [2/25], Train Loss: 9201.4559, Eval Loss: 93.9789\n",
      "Epoch [3/25], Train Loss: 9056.8737, Eval Loss: 93.2349\n",
      "Epoch [4/25], Train Loss: 8926.5398, Eval Loss: 92.6182\n",
      "Epoch [5/25], Train Loss: 8820.3680, Eval Loss: 92.1131\n",
      "Epoch [6/25], Train Loss: 8731.0923, Eval Loss: 91.6709\n",
      "Epoch [7/25], Train Loss: 8652.1359, Eval Loss: 91.2632\n",
      "Epoch [8/25], Train Loss: 8578.0638, Eval Loss: 90.8770\n",
      "Epoch [9/25], Train Loss: 8508.0794, Eval Loss: 90.5051\n",
      "Epoch [10/25], Train Loss: 8440.5005, Eval Loss: 90.1437\n",
      "Epoch [11/25], Train Loss: 8375.1334, Eval Loss: 89.7902\n",
      "Epoch [12/25], Train Loss: 8311.1221, Eval Loss: 89.4431\n",
      "Epoch [13/25], Train Loss: 8248.5669, Eval Loss: 89.1011\n",
      "Epoch [14/25], Train Loss: 8186.9750, Eval Loss: 88.7635\n",
      "Epoch [15/25], Train Loss: 8126.5782, Eval Loss: 88.4295\n",
      "Epoch [16/25], Train Loss: 8066.9289, Eval Loss: 88.0987\n",
      "Epoch [17/25], Train Loss: 8007.9222, Eval Loss: 87.7708\n",
      "Epoch [18/25], Train Loss: 7949.7202, Eval Loss: 87.4454\n",
      "Epoch [19/25], Train Loss: 7892.1820, Eval Loss: 87.1223\n",
      "Epoch [20/25], Train Loss: 7835.2289, Eval Loss: 86.8012\n",
      "Epoch [21/25], Train Loss: 7778.8206, Eval Loss: 86.4821\n",
      "Epoch [22/25], Train Loss: 7722.9607, Eval Loss: 86.1646\n",
      "Epoch [23/25], Train Loss: 7667.5457, Eval Loss: 85.8488\n",
      "Epoch [24/25], Train Loss: 7612.6250, Eval Loss: 85.5345\n",
      "Epoch [25/25], Train Loss: 7558.1836, Eval Loss: 85.2216\n",
      "Epoch [1/25], Train Loss: 9306.1448, Eval Loss: 94.5296\n",
      "Epoch [2/25], Train Loss: 9150.5411, Eval Loss: 93.6494\n",
      "Epoch [3/25], Train Loss: 8992.2079, Eval Loss: 92.8987\n",
      "Epoch [4/25], Train Loss: 8866.9698, Eval Loss: 92.3216\n",
      "Epoch [5/25], Train Loss: 8767.4562, Eval Loss: 91.8362\n",
      "Epoch [6/25], Train Loss: 8680.3684, Eval Loss: 91.3969\n",
      "Epoch [7/25], Train Loss: 8601.6787, Eval Loss: 90.9860\n",
      "Epoch [8/25], Train Loss: 8527.3973, Eval Loss: 90.5967\n",
      "Epoch [9/25], Train Loss: 8457.0313, Eval Loss: 90.2229\n",
      "Epoch [10/25], Train Loss: 8389.4877, Eval Loss: 89.8602\n",
      "Epoch [11/25], Train Loss: 8324.0819, Eval Loss: 89.5059\n",
      "Epoch [12/25], Train Loss: 8260.1687, Eval Loss: 89.1582\n",
      "Epoch [13/25], Train Loss: 8197.7705, Eval Loss: 88.8159\n",
      "Epoch [14/25], Train Loss: 8136.3665, Eval Loss: 88.4781\n",
      "Epoch [15/25], Train Loss: 8076.1026, Eval Loss: 88.1440\n",
      "Epoch [16/25], Train Loss: 8016.5245, Eval Loss: 87.8133\n",
      "Epoch [17/25], Train Loss: 7957.8778, Eval Loss: 87.4854\n",
      "Epoch [18/25], Train Loss: 7899.7912, Eval Loss: 87.1602\n",
      "Epoch [19/25], Train Loss: 7842.4770, Eval Loss: 86.8372\n",
      "Epoch [20/25], Train Loss: 7785.7995, Eval Loss: 86.5163\n",
      "Epoch [21/25], Train Loss: 7729.5333, Eval Loss: 86.1974\n",
      "Epoch [22/25], Train Loss: 7673.8332, Eval Loss: 85.8803\n",
      "Epoch [23/25], Train Loss: 7618.7735, Eval Loss: 85.5647\n",
      "Epoch [24/25], Train Loss: 7564.0432, Eval Loss: 85.2507\n",
      "Epoch [25/25], Train Loss: 7509.7651, Eval Loss: 84.9382\n",
      "Epoch [1/25], Train Loss: 8775.2341, Eval Loss: 86.4386\n",
      "Epoch [2/25], Train Loss: 6682.0617, Eval Loss: 73.8606\n",
      "Epoch [3/25], Train Loss: 4922.3595, Eval Loss: 63.4255\n",
      "Epoch [4/25], Train Loss: 3687.7355, Eval Loss: 55.0465\n",
      "Epoch [5/25], Train Loss: 2827.3693, Eval Loss: 48.4135\n",
      "Epoch [6/25], Train Loss: 2227.9993, Eval Loss: 43.2486\n",
      "Epoch [7/25], Train Loss: 1810.6135, Eval Loss: 39.3004\n",
      "Epoch [8/25], Train Loss: 1519.8401, Eval Loss: 36.3389\n",
      "Epoch [9/25], Train Loss: 1317.2495, Eval Loss: 34.1576\n",
      "Epoch [10/25], Train Loss: 1176.1483, Eval Loss: 32.5766\n",
      "Epoch [11/25], Train Loss: 1077.9002, Eval Loss: 31.4464\n",
      "Epoch [12/25], Train Loss: 1009.5369, Eval Loss: 30.6477\n",
      "Epoch [13/25], Train Loss: 961.8806, Eval Loss: 30.0885\n",
      "Epoch [14/25], Train Loss: 928.7145, Eval Loss: 29.7003\n",
      "Epoch [15/25], Train Loss: 905.6918, Eval Loss: 29.4327\n",
      "Epoch [16/25], Train Loss: 889.5600, Eval Loss: 29.2495\n",
      "Epoch [17/25], Train Loss: 878.4273, Eval Loss: 29.1250\n",
      "Epoch [18/25], Train Loss: 870.6259, Eval Loss: 29.0411\n",
      "Epoch [19/25], Train Loss: 865.2893, Eval Loss: 28.9851\n",
      "Epoch [20/25], Train Loss: 861.4909, Eval Loss: 28.9482\n",
      "Epoch [21/25], Train Loss: 858.8679, Eval Loss: 28.9243\n",
      "Epoch [22/25], Train Loss: 857.0306, Eval Loss: 28.9091\n",
      "Epoch [23/25], Train Loss: 855.7769, Eval Loss: 28.8997\n",
      "Epoch [24/25], Train Loss: 854.8663, Eval Loss: 28.8942\n",
      "Epoch [25/25], Train Loss: 854.2279, Eval Loss: 28.8913\n",
      "Epoch [1/25], Train Loss: 8739.0751, Eval Loss: 86.4268\n",
      "Epoch [2/25], Train Loss: 6689.7312, Eval Loss: 73.8965\n",
      "Epoch [3/25], Train Loss: 4927.2519, Eval Loss: 63.4539\n",
      "Epoch [4/25], Train Loss: 3690.7996, Eval Loss: 55.0694\n",
      "Epoch [5/25], Train Loss: 2829.8117, Eval Loss: 48.4308\n",
      "Epoch [6/25], Train Loss: 2229.7337, Eval Loss: 43.2615\n",
      "Epoch [7/25], Train Loss: 1811.6783, Eval Loss: 39.3099\n",
      "Epoch [8/25], Train Loss: 1520.6290, Eval Loss: 36.3460\n",
      "Epoch [9/25], Train Loss: 1317.8180, Eval Loss: 34.1627\n",
      "Epoch [10/25], Train Loss: 1176.5479, Eval Loss: 32.5802\n",
      "Epoch [11/25], Train Loss: 1078.1845, Eval Loss: 31.4490\n",
      "Epoch [12/25], Train Loss: 1009.7660, Eval Loss: 30.6495\n",
      "Epoch [13/25], Train Loss: 962.0188, Eval Loss: 30.0899\n",
      "Epoch [14/25], Train Loss: 928.8417, Eval Loss: 29.7012\n",
      "Epoch [15/25], Train Loss: 905.7340, Eval Loss: 29.4333\n",
      "Epoch [16/25], Train Loss: 889.6888, Eval Loss: 29.2499\n",
      "Epoch [17/25], Train Loss: 878.5472, Eval Loss: 29.1253\n",
      "Epoch [18/25], Train Loss: 870.7058, Eval Loss: 29.0413\n",
      "Epoch [19/25], Train Loss: 865.2813, Eval Loss: 28.9853\n",
      "Epoch [20/25], Train Loss: 861.5593, Eval Loss: 28.9483\n",
      "Epoch [21/25], Train Loss: 858.8606, Eval Loss: 28.9243\n",
      "Epoch [22/25], Train Loss: 857.0984, Eval Loss: 28.9091\n",
      "Epoch [23/25], Train Loss: 855.7368, Eval Loss: 28.8997\n",
      "Epoch [24/25], Train Loss: 854.8730, Eval Loss: 28.8942\n",
      "Epoch [25/25], Train Loss: 854.2502, Eval Loss: 28.8913\n",
      "Epoch [1/25], Train Loss: 3501.6329, Eval Loss: 29.3710\n",
      "Epoch [2/25], Train Loss: 893.4854, Eval Loss: 29.3475\n",
      "Epoch [3/25], Train Loss: 923.0645, Eval Loss: 29.7217\n",
      "Epoch [4/25], Train Loss: 908.1358, Eval Loss: 29.1151\n",
      "Epoch [5/25], Train Loss: 900.0108, Eval Loss: 29.5422\n",
      "Epoch [6/25], Train Loss: 901.0624, Eval Loss: 28.9410\n",
      "Epoch [7/25], Train Loss: 922.8716, Eval Loss: 29.4128\n",
      "Epoch [8/25], Train Loss: 889.7454, Eval Loss: 29.1603\n",
      "Epoch [9/25], Train Loss: 893.7102, Eval Loss: 29.1457\n",
      "Epoch [10/25], Train Loss: 903.8732, Eval Loss: 28.8677\n",
      "Epoch [11/25], Train Loss: 911.1658, Eval Loss: 28.9297\n",
      "Epoch [12/25], Train Loss: 892.2864, Eval Loss: 28.7725\n",
      "Epoch [13/25], Train Loss: 883.5859, Eval Loss: 29.0134\n",
      "Epoch [14/25], Train Loss: 892.0126, Eval Loss: 29.4239\n",
      "Epoch [15/25], Train Loss: 885.5605, Eval Loss: 29.3118\n",
      "Epoch [16/25], Train Loss: 888.5626, Eval Loss: 29.0274\n",
      "Epoch [17/25], Train Loss: 890.4744, Eval Loss: 29.2516\n",
      "Epoch [18/25], Train Loss: 886.5032, Eval Loss: 28.8635\n",
      "Epoch [19/25], Train Loss: 888.1166, Eval Loss: 29.3258\n",
      "Epoch [20/25], Train Loss: 881.7825, Eval Loss: 29.2256\n",
      "Epoch [21/25], Train Loss: 890.8334, Eval Loss: 29.8899\n",
      "Epoch [22/25], Train Loss: 874.4698, Eval Loss: 28.9237\n",
      "Epoch [23/25], Train Loss: 859.1070, Eval Loss: 28.6723\n",
      "Epoch [24/25], Train Loss: 863.7653, Eval Loss: 29.5099\n",
      "Epoch [25/25], Train Loss: 874.5909, Eval Loss: 28.8179\n",
      "Epoch [1/25], Train Loss: 3289.7282, Eval Loss: 29.9408\n",
      "Epoch [2/25], Train Loss: 911.7040, Eval Loss: 29.5900\n",
      "Epoch [3/25], Train Loss: 917.7403, Eval Loss: 29.4424\n",
      "Epoch [4/25], Train Loss: 924.7330, Eval Loss: 29.6885\n",
      "Epoch [5/25], Train Loss: 908.3630, Eval Loss: 29.0350\n",
      "Epoch [6/25], Train Loss: 915.9600, Eval Loss: 29.3910\n",
      "Epoch [7/25], Train Loss: 893.7034, Eval Loss: 29.1460\n",
      "Epoch [8/25], Train Loss: 907.7185, Eval Loss: 28.9152\n",
      "Epoch [9/25], Train Loss: 892.0993, Eval Loss: 29.1821\n",
      "Epoch [10/25], Train Loss: 901.0200, Eval Loss: 29.0005\n",
      "Epoch [11/25], Train Loss: 896.4037, Eval Loss: 30.2633\n",
      "Epoch [12/25], Train Loss: 887.7884, Eval Loss: 29.5074\n",
      "Epoch [13/25], Train Loss: 898.1106, Eval Loss: 29.3268\n",
      "Epoch [14/25], Train Loss: 894.1686, Eval Loss: 29.1784\n",
      "Epoch [15/25], Train Loss: 886.3565, Eval Loss: 28.9923\n",
      "Epoch [16/25], Train Loss: 894.1367, Eval Loss: 29.3183\n",
      "Epoch [17/25], Train Loss: 887.0294, Eval Loss: 28.9320\n",
      "Epoch [18/25], Train Loss: 908.3272, Eval Loss: 28.7862\n",
      "Epoch [19/25], Train Loss: 892.3517, Eval Loss: 29.6789\n",
      "Epoch [20/25], Train Loss: 882.2264, Eval Loss: 29.2088\n",
      "Epoch [21/25], Train Loss: 890.7177, Eval Loss: 29.4256\n",
      "Epoch [22/25], Train Loss: 898.5062, Eval Loss: 29.2884\n",
      "Epoch [23/25], Train Loss: 872.2524, Eval Loss: 28.9239\n",
      "Epoch [24/25], Train Loss: 890.0733, Eval Loss: 29.6528\n",
      "Epoch [25/25], Train Loss: 877.0008, Eval Loss: 29.5307\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8894.2394, Eval Loss: 90.5473\n",
      "Epoch [2/25], Train Loss: 8160.5700, Eval Loss: 87.0255\n",
      "Epoch [3/25], Train Loss: 7567.3529, Eval Loss: 83.8002\n",
      "Epoch [4/25], Train Loss: 7033.0939, Eval Loss: 80.7445\n",
      "Epoch [5/25], Train Loss: 6542.4951, Eval Loss: 77.8233\n",
      "Epoch [6/25], Train Loss: 6089.2456, Eval Loss: 75.0219\n",
      "Epoch [7/25], Train Loss: 5669.5278, Eval Loss: 72.3324\n",
      "Epoch [8/25], Train Loss: 5280.5246, Eval Loss: 69.7499\n",
      "Epoch [9/25], Train Loss: 4919.9329, Eval Loss: 67.2710\n",
      "Epoch [10/25], Train Loss: 4585.7470, Eval Loss: 64.8932\n",
      "Epoch [11/25], Train Loss: 4276.1594, Eval Loss: 62.6143\n",
      "Epoch [12/25], Train Loss: 3989.5147, Eval Loss: 60.4322\n",
      "Epoch [13/25], Train Loss: 3724.2727, Eval Loss: 58.3453\n",
      "Epoch [14/25], Train Loss: 3478.9703, Eval Loss: 56.3517\n",
      "Epoch [15/25], Train Loss: 3252.2763, Eval Loss: 54.4497\n",
      "Epoch [16/25], Train Loss: 3042.9180, Eval Loss: 52.6378\n",
      "Epoch [17/25], Train Loss: 2849.7005, Eval Loss: 50.9141\n",
      "Epoch [18/25], Train Loss: 2671.5245, Eval Loss: 49.2770\n",
      "Epoch [19/25], Train Loss: 2507.3346, Eval Loss: 47.7250\n",
      "Epoch [20/25], Train Loss: 2356.1631, Eval Loss: 46.2562\n",
      "Epoch [21/25], Train Loss: 2217.0996, Eval Loss: 44.8689\n",
      "Epoch [22/25], Train Loss: 2089.2922, Eval Loss: 43.5614\n",
      "Epoch [23/25], Train Loss: 1971.9486, Eval Loss: 42.3317\n",
      "Epoch [24/25], Train Loss: 1864.3192, Eval Loss: 41.1778\n",
      "Epoch [25/25], Train Loss: 1765.7120, Eval Loss: 40.0976\n",
      "Epoch [1/25], Train Loss: 8854.5325, Eval Loss: 90.2803\n",
      "Epoch [2/25], Train Loss: 8113.0859, Eval Loss: 86.7550\n",
      "Epoch [3/25], Train Loss: 7522.3241, Eval Loss: 83.5362\n",
      "Epoch [4/25], Train Loss: 6991.1112, Eval Loss: 80.4900\n",
      "Epoch [5/25], Train Loss: 6503.7432, Eval Loss: 77.5801\n",
      "Epoch [6/25], Train Loss: 6053.7492, Eval Loss: 74.7911\n",
      "Epoch [7/25], Train Loss: 5637.2364, Eval Loss: 72.1149\n",
      "Epoch [8/25], Train Loss: 5251.3793, Eval Loss: 69.5464\n",
      "Epoch [9/25], Train Loss: 4893.8389, Eval Loss: 67.0822\n",
      "Epoch [10/25], Train Loss: 4562.5730, Eval Loss: 64.7195\n",
      "Epoch [11/25], Train Loss: 4255.7793, Eval Loss: 62.4559\n",
      "Epoch [12/25], Train Loss: 3971.7812, Eval Loss: 60.2893\n",
      "Epoch [13/25], Train Loss: 3709.0188, Eval Loss: 58.2179\n",
      "Epoch [14/25], Train Loss: 3466.0448, Eval Loss: 56.2397\n",
      "Epoch [15/25], Train Loss: 3241.5058, Eval Loss: 54.3529\n",
      "Epoch [16/25], Train Loss: 3034.1321, Eval Loss: 52.5558\n",
      "Epoch [17/25], Train Loss: 2842.7389, Eval Loss: 50.8465\n",
      "Epoch [18/25], Train Loss: 2666.2151, Eval Loss: 49.2234\n",
      "Epoch [19/25], Train Loss: 2503.5271, Eval Loss: 47.6846\n",
      "Epoch [20/25], Train Loss: 2353.6928, Eval Loss: 46.2285\n",
      "Epoch [21/25], Train Loss: 2215.8219, Eval Loss: 44.8532\n",
      "Epoch [22/25], Train Loss: 2089.0669, Eval Loss: 43.5568\n",
      "Epoch [23/25], Train Loss: 1972.6390, Eval Loss: 42.3373\n",
      "Epoch [24/25], Train Loss: 1865.8029, Eval Loss: 41.1929\n",
      "Epoch [25/25], Train Loss: 1767.8683, Eval Loss: 40.1211\n",
      "Epoch [1/25], Train Loss: 3684.6264, Eval Loss: 32.7982\n",
      "Epoch [2/25], Train Loss: 930.7058, Eval Loss: 28.9629\n",
      "Epoch [3/25], Train Loss: 856.5738, Eval Loss: 28.8962\n",
      "Epoch [4/25], Train Loss: 854.6668, Eval Loss: 28.9004\n",
      "Epoch [5/25], Train Loss: 854.6558, Eval Loss: 28.9014\n",
      "Epoch [6/25], Train Loss: 854.7072, Eval Loss: 28.9016\n",
      "Epoch [7/25], Train Loss: 854.6443, Eval Loss: 28.9017\n",
      "Epoch [8/25], Train Loss: 854.6982, Eval Loss: 28.9016\n",
      "Epoch [9/25], Train Loss: 854.6249, Eval Loss: 28.9016\n",
      "Epoch [10/25], Train Loss: 854.6336, Eval Loss: 28.9016\n",
      "Epoch [11/25], Train Loss: 854.6896, Eval Loss: 28.9016\n",
      "Epoch [12/25], Train Loss: 854.6063, Eval Loss: 28.9016\n",
      "Epoch [13/25], Train Loss: 854.6935, Eval Loss: 28.9016\n",
      "Epoch [14/25], Train Loss: 854.6830, Eval Loss: 28.9016\n",
      "Epoch [15/25], Train Loss: 854.6689, Eval Loss: 28.9016\n",
      "Epoch [16/25], Train Loss: 854.6351, Eval Loss: 28.9016\n",
      "Epoch [17/25], Train Loss: 854.6234, Eval Loss: 28.9016\n",
      "Epoch [18/25], Train Loss: 854.6163, Eval Loss: 28.9016\n",
      "Epoch [19/25], Train Loss: 854.6907, Eval Loss: 28.9016\n",
      "Epoch [20/25], Train Loss: 854.6821, Eval Loss: 28.9016\n",
      "Epoch [21/25], Train Loss: 854.6515, Eval Loss: 28.9016\n",
      "Epoch [22/25], Train Loss: 854.6725, Eval Loss: 28.9016\n",
      "Epoch [23/25], Train Loss: 854.6351, Eval Loss: 28.9016\n",
      "Epoch [24/25], Train Loss: 854.7043, Eval Loss: 28.9015\n",
      "Epoch [25/25], Train Loss: 854.6515, Eval Loss: 28.9016\n",
      "Epoch [1/25], Train Loss: 3607.7988, Eval Loss: 32.6440\n",
      "Epoch [2/25], Train Loss: 927.6033, Eval Loss: 28.9598\n",
      "Epoch [3/25], Train Loss: 856.5185, Eval Loss: 28.8964\n",
      "Epoch [4/25], Train Loss: 854.6907, Eval Loss: 28.9005\n",
      "Epoch [5/25], Train Loss: 854.6238, Eval Loss: 28.9015\n",
      "Epoch [6/25], Train Loss: 854.6547, Eval Loss: 28.9017\n",
      "Epoch [7/25], Train Loss: 854.6584, Eval Loss: 28.9017\n",
      "Epoch [8/25], Train Loss: 854.6866, Eval Loss: 28.9017\n",
      "Epoch [9/25], Train Loss: 854.6669, Eval Loss: 28.9017\n",
      "Epoch [10/25], Train Loss: 854.6583, Eval Loss: 28.9017\n",
      "Epoch [11/25], Train Loss: 854.6472, Eval Loss: 28.9017\n",
      "Epoch [12/25], Train Loss: 854.6674, Eval Loss: 28.9017\n",
      "Epoch [13/25], Train Loss: 854.6828, Eval Loss: 28.9017\n",
      "Epoch [14/25], Train Loss: 854.6649, Eval Loss: 28.9017\n",
      "Epoch [15/25], Train Loss: 854.6899, Eval Loss: 28.9017\n",
      "Epoch [16/25], Train Loss: 854.6276, Eval Loss: 28.9017\n",
      "Epoch [17/25], Train Loss: 854.7017, Eval Loss: 28.9017\n",
      "Epoch [18/25], Train Loss: 854.6907, Eval Loss: 28.9017\n",
      "Epoch [19/25], Train Loss: 854.6602, Eval Loss: 28.9016\n",
      "Epoch [20/25], Train Loss: 854.6314, Eval Loss: 28.9016\n",
      "Epoch [21/25], Train Loss: 854.6111, Eval Loss: 28.9016\n",
      "Epoch [22/25], Train Loss: 854.6944, Eval Loss: 28.9016\n",
      "Epoch [23/25], Train Loss: 854.6243, Eval Loss: 28.9016\n",
      "Epoch [24/25], Train Loss: 854.6896, Eval Loss: 28.9016\n",
      "Epoch [25/25], Train Loss: 854.6209, Eval Loss: 28.9016\n",
      "Epoch [1/25], Train Loss: 1569.6442, Eval Loss: 29.3690\n",
      "Epoch [2/25], Train Loss: 1126.1020, Eval Loss: 36.1303\n",
      "Epoch [3/25], Train Loss: 1109.2231, Eval Loss: 30.8232\n",
      "Epoch [4/25], Train Loss: 1031.9743, Eval Loss: 28.8962\n",
      "Epoch [5/25], Train Loss: 1039.8343, Eval Loss: 33.0364\n",
      "Epoch [6/25], Train Loss: 1012.3728, Eval Loss: 28.6253\n",
      "Epoch [7/25], Train Loss: 1029.9855, Eval Loss: 28.5479\n",
      "Epoch [8/25], Train Loss: 939.5556, Eval Loss: 28.0561\n",
      "Epoch [9/25], Train Loss: 935.0694, Eval Loss: 29.6903\n",
      "Epoch [10/25], Train Loss: 976.1214, Eval Loss: 27.4025\n",
      "Epoch [11/25], Train Loss: 870.7724, Eval Loss: 27.7792\n",
      "Epoch [12/25], Train Loss: 818.6853, Eval Loss: 25.9087\n",
      "Epoch [13/25], Train Loss: 820.2277, Eval Loss: 26.0962\n",
      "Epoch [14/25], Train Loss: 753.9249, Eval Loss: 25.8127\n",
      "Epoch [15/25], Train Loss: 805.8702, Eval Loss: 32.7814\n",
      "Epoch [16/25], Train Loss: 786.4456, Eval Loss: 26.5624\n",
      "Epoch [17/25], Train Loss: 716.0070, Eval Loss: 25.5283\n",
      "Epoch [18/25], Train Loss: 725.2319, Eval Loss: 26.6975\n",
      "Epoch [19/25], Train Loss: 716.9302, Eval Loss: 24.5209\n",
      "Epoch [20/25], Train Loss: 686.9163, Eval Loss: 26.0961\n",
      "Epoch [21/25], Train Loss: 679.8992, Eval Loss: 25.0938\n",
      "Epoch [22/25], Train Loss: 692.8523, Eval Loss: 27.9065\n",
      "Epoch [23/25], Train Loss: 702.8262, Eval Loss: 26.7374\n",
      "Epoch [24/25], Train Loss: 676.0845, Eval Loss: 24.7598\n",
      "Epoch [25/25], Train Loss: 626.6670, Eval Loss: 23.0601\n",
      "Epoch [1/25], Train Loss: 1686.5623, Eval Loss: 29.9569\n",
      "Epoch [2/25], Train Loss: 1041.0911, Eval Loss: 29.0587\n",
      "Epoch [3/25], Train Loss: 1028.5849, Eval Loss: 29.0051\n",
      "Epoch [4/25], Train Loss: 1095.7078, Eval Loss: 28.8560\n",
      "Epoch [5/25], Train Loss: 1033.6616, Eval Loss: 28.7548\n",
      "Epoch [6/25], Train Loss: 998.8667, Eval Loss: 28.8070\n",
      "Epoch [7/25], Train Loss: 944.8998, Eval Loss: 28.2770\n",
      "Epoch [8/25], Train Loss: 988.6924, Eval Loss: 28.2010\n",
      "Epoch [9/25], Train Loss: 1019.3922, Eval Loss: 28.6669\n",
      "Epoch [10/25], Train Loss: 912.0424, Eval Loss: 27.2417\n",
      "Epoch [11/25], Train Loss: 939.1002, Eval Loss: 27.0046\n",
      "Epoch [12/25], Train Loss: 898.0261, Eval Loss: 26.0577\n",
      "Epoch [13/25], Train Loss: 833.9220, Eval Loss: 27.6506\n",
      "Epoch [14/25], Train Loss: 774.4814, Eval Loss: 26.3981\n",
      "Epoch [15/25], Train Loss: 751.0775, Eval Loss: 26.8929\n",
      "Epoch [16/25], Train Loss: 807.5718, Eval Loss: 24.5237\n",
      "Epoch [17/25], Train Loss: 702.2985, Eval Loss: 25.7047\n",
      "Epoch [18/25], Train Loss: 693.4629, Eval Loss: 27.0261\n",
      "Epoch [19/25], Train Loss: 776.9390, Eval Loss: 26.7773\n",
      "Epoch [20/25], Train Loss: 722.5383, Eval Loss: 26.3834\n",
      "Epoch [21/25], Train Loss: 683.4966, Eval Loss: 25.7402\n",
      "Epoch [22/25], Train Loss: 659.1863, Eval Loss: 26.0968\n",
      "Epoch [23/25], Train Loss: 645.9834, Eval Loss: 27.0894\n",
      "Epoch [24/25], Train Loss: 623.1761, Eval Loss: 24.5303\n",
      "Epoch [25/25], Train Loss: 496.9866, Eval Loss: 18.7187\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 6618.6022, Eval Loss: 64.9083\n",
      "Epoch [2/25], Train Loss: 3218.6119, Eval Loss: 46.1294\n",
      "Epoch [3/25], Train Loss: 1773.4264, Eval Loss: 36.0777\n",
      "Epoch [4/25], Train Loss: 1189.7866, Eval Loss: 31.5067\n",
      "Epoch [5/25], Train Loss: 966.6734, Eval Loss: 29.7075\n",
      "Epoch [6/25], Train Loss: 887.4440, Eval Loss: 29.1022\n",
      "Epoch [7/25], Train Loss: 862.3067, Eval Loss: 28.9361\n",
      "Epoch [8/25], Train Loss: 855.4388, Eval Loss: 28.9030\n",
      "Epoch [9/25], Train Loss: 853.8955, Eval Loss: 28.9009\n",
      "Epoch [10/25], Train Loss: 853.6591, Eval Loss: 28.9030\n",
      "Epoch [11/25], Train Loss: 853.6819, Eval Loss: 28.9046\n",
      "Epoch [12/25], Train Loss: 853.7401, Eval Loss: 28.9054\n",
      "Epoch [13/25], Train Loss: 853.7962, Eval Loss: 28.9058\n",
      "Epoch [14/25], Train Loss: 853.8481, Eval Loss: 28.9060\n",
      "Epoch [15/25], Train Loss: 853.8962, Eval Loss: 28.9061\n",
      "Epoch [16/25], Train Loss: 853.9424, Eval Loss: 28.9061\n",
      "Epoch [17/25], Train Loss: 853.9858, Eval Loss: 28.9062\n",
      "Epoch [18/25], Train Loss: 854.0272, Eval Loss: 28.9062\n",
      "Epoch [19/25], Train Loss: 854.0670, Eval Loss: 28.9062\n",
      "Epoch [20/25], Train Loss: 854.1053, Eval Loss: 28.9062\n",
      "Epoch [21/25], Train Loss: 854.1417, Eval Loss: 28.9062\n",
      "Epoch [22/25], Train Loss: 854.1763, Eval Loss: 28.9062\n",
      "Epoch [23/25], Train Loss: 854.2095, Eval Loss: 28.9062\n",
      "Epoch [24/25], Train Loss: 854.2407, Eval Loss: 28.9063\n",
      "Epoch [25/25], Train Loss: 854.2718, Eval Loss: 28.9063\n",
      "Epoch [1/25], Train Loss: 6612.0643, Eval Loss: 64.8845\n",
      "Epoch [2/25], Train Loss: 3209.8017, Eval Loss: 46.0562\n",
      "Epoch [3/25], Train Loss: 1765.1682, Eval Loss: 36.0113\n",
      "Epoch [4/25], Train Loss: 1184.9168, Eval Loss: 31.4660\n",
      "Epoch [5/25], Train Loss: 964.4146, Eval Loss: 29.6892\n",
      "Epoch [6/25], Train Loss: 886.5717, Eval Loss: 29.0959\n",
      "Epoch [7/25], Train Loss: 862.0206, Eval Loss: 28.9346\n",
      "Epoch [8/25], Train Loss: 855.3584, Eval Loss: 28.9028\n",
      "Epoch [9/25], Train Loss: 853.8750, Eval Loss: 28.9010\n",
      "Epoch [10/25], Train Loss: 853.6527, Eval Loss: 28.9032\n",
      "Epoch [11/25], Train Loss: 853.6783, Eval Loss: 28.9048\n",
      "Epoch [12/25], Train Loss: 853.7364, Eval Loss: 28.9055\n",
      "Epoch [13/25], Train Loss: 853.7931, Eval Loss: 28.9059\n",
      "Epoch [14/25], Train Loss: 853.8451, Eval Loss: 28.9061\n",
      "Epoch [15/25], Train Loss: 853.8933, Eval Loss: 28.9062\n",
      "Epoch [16/25], Train Loss: 853.9396, Eval Loss: 28.9063\n",
      "Epoch [17/25], Train Loss: 853.9842, Eval Loss: 28.9063\n",
      "Epoch [18/25], Train Loss: 854.0262, Eval Loss: 28.9063\n",
      "Epoch [19/25], Train Loss: 854.0662, Eval Loss: 28.9063\n",
      "Epoch [20/25], Train Loss: 854.1044, Eval Loss: 28.9063\n",
      "Epoch [21/25], Train Loss: 853.8025, Eval Loss: 28.9935\n",
      "Epoch [22/25], Train Loss: 857.8375, Eval Loss: 28.8997\n",
      "Epoch [23/25], Train Loss: 854.1702, Eval Loss: 28.9055\n",
      "Epoch [24/25], Train Loss: 854.2306, Eval Loss: 28.9063\n",
      "Epoch [25/25], Train Loss: 854.2723, Eval Loss: 28.9064\n",
      "Epoch [1/25], Train Loss: 1335.9331, Eval Loss: 29.3539\n",
      "Epoch [2/25], Train Loss: 869.3549, Eval Loss: 29.3539\n",
      "Epoch [3/25], Train Loss: 869.3473, Eval Loss: 29.3538\n",
      "Epoch [4/25], Train Loss: 869.3750, Eval Loss: 29.3526\n",
      "Epoch [5/25], Train Loss: 869.3517, Eval Loss: 29.3539\n",
      "Epoch [6/25], Train Loss: 869.3530, Eval Loss: 29.3539\n",
      "Epoch [7/25], Train Loss: 869.3444, Eval Loss: 29.3539\n",
      "Epoch [8/25], Train Loss: 869.3555, Eval Loss: 29.3539\n",
      "Epoch [9/25], Train Loss: 869.3515, Eval Loss: 29.3539\n",
      "Epoch [10/25], Train Loss: 869.3553, Eval Loss: 29.3539\n",
      "Epoch [11/25], Train Loss: 869.3515, Eval Loss: 29.3539\n",
      "Epoch [12/25], Train Loss: 869.3452, Eval Loss: 29.3539\n",
      "Epoch [13/25], Train Loss: 869.3532, Eval Loss: 29.3537\n",
      "Epoch [14/25], Train Loss: 869.9138, Eval Loss: 29.3538\n",
      "Epoch [15/25], Train Loss: 869.3534, Eval Loss: 29.3538\n",
      "Epoch [16/25], Train Loss: 869.9199, Eval Loss: 29.3382\n",
      "Epoch [17/25], Train Loss: 869.3978, Eval Loss: 29.3539\n",
      "Epoch [18/25], Train Loss: 869.3516, Eval Loss: 29.3539\n",
      "Epoch [19/25], Train Loss: 869.3535, Eval Loss: 29.3539\n",
      "Epoch [20/25], Train Loss: 869.3546, Eval Loss: 29.3539\n",
      "Epoch [21/25], Train Loss: 869.3512, Eval Loss: 29.3539\n",
      "Epoch [22/25], Train Loss: 869.3519, Eval Loss: 29.3539\n",
      "Epoch [23/25], Train Loss: 869.3465, Eval Loss: 29.3539\n",
      "Epoch [24/25], Train Loss: 869.3564, Eval Loss: 29.3539\n",
      "Epoch [25/25], Train Loss: 869.3544, Eval Loss: 29.3539\n",
      "Epoch [1/25], Train Loss: 1336.9340, Eval Loss: 29.3539\n",
      "Epoch [2/25], Train Loss: 869.3546, Eval Loss: 29.3538\n",
      "Epoch [3/25], Train Loss: 869.4051, Eval Loss: 29.3539\n",
      "Epoch [4/25], Train Loss: 869.4246, Eval Loss: 29.3561\n",
      "Epoch [5/25], Train Loss: 869.3942, Eval Loss: 29.3535\n",
      "Epoch [6/25], Train Loss: 869.2109, Eval Loss: 29.3539\n",
      "Epoch [7/25], Train Loss: 869.3949, Eval Loss: 29.3533\n",
      "Epoch [8/25], Train Loss: 870.2225, Eval Loss: 29.3539\n",
      "Epoch [9/25], Train Loss: 869.3566, Eval Loss: 29.3540\n",
      "Epoch [10/25], Train Loss: 869.3427, Eval Loss: 29.3539\n",
      "Epoch [11/25], Train Loss: 869.3590, Eval Loss: 29.3540\n",
      "Epoch [12/25], Train Loss: 869.3457, Eval Loss: 29.3539\n",
      "Epoch [13/25], Train Loss: 869.3478, Eval Loss: 29.3539\n",
      "Epoch [14/25], Train Loss: 870.5150, Eval Loss: 29.3539\n",
      "Epoch [15/25], Train Loss: 869.4758, Eval Loss: 29.3540\n",
      "Epoch [16/25], Train Loss: 869.3513, Eval Loss: 29.3540\n",
      "Epoch [17/25], Train Loss: 869.3576, Eval Loss: 29.3540\n",
      "Epoch [18/25], Train Loss: 869.3492, Eval Loss: 29.3540\n",
      "Epoch [19/25], Train Loss: 869.3500, Eval Loss: 29.3540\n",
      "Epoch [20/25], Train Loss: 869.3504, Eval Loss: 29.3540\n",
      "Epoch [21/25], Train Loss: 869.3498, Eval Loss: 29.3540\n",
      "Epoch [22/25], Train Loss: 869.3499, Eval Loss: 29.3539\n",
      "Epoch [23/25], Train Loss: 869.3528, Eval Loss: 29.3540\n",
      "Epoch [24/25], Train Loss: 869.3526, Eval Loss: 29.3540\n",
      "Epoch [25/25], Train Loss: 869.3552, Eval Loss: 29.3540\n",
      "Epoch [1/25], Train Loss: 9124.6197, Eval Loss: 92.5792\n",
      "Epoch [2/25], Train Loss: 7439.2751, Eval Loss: 72.3320\n",
      "Epoch [3/25], Train Loss: 2324.7771, Eval Loss: 31.7418\n",
      "Epoch [4/25], Train Loss: 1211.8916, Eval Loss: 31.3032\n",
      "Epoch [5/25], Train Loss: 1178.3172, Eval Loss: 31.7713\n",
      "Epoch [6/25], Train Loss: 1075.4227, Eval Loss: 30.9951\n",
      "Epoch [7/25], Train Loss: 1146.3658, Eval Loss: 31.3195\n",
      "Epoch [8/25], Train Loss: 1114.7776, Eval Loss: 31.5600\n",
      "Epoch [9/25], Train Loss: 1149.1705, Eval Loss: 32.0822\n",
      "Epoch [10/25], Train Loss: 1057.4400, Eval Loss: 32.4901\n",
      "Epoch [11/25], Train Loss: 1118.5430, Eval Loss: 31.7375\n",
      "Epoch [12/25], Train Loss: 1075.9797, Eval Loss: 32.6155\n",
      "Epoch [13/25], Train Loss: 1087.0681, Eval Loss: 32.8788\n",
      "Epoch [14/25], Train Loss: 1062.7359, Eval Loss: 32.9110\n",
      "Epoch [15/25], Train Loss: 1085.1946, Eval Loss: 32.4259\n",
      "Epoch [16/25], Train Loss: 1079.0875, Eval Loss: 33.2824\n",
      "Epoch [17/25], Train Loss: 1078.5895, Eval Loss: 32.9760\n",
      "Epoch [18/25], Train Loss: 1040.4937, Eval Loss: 32.7779\n",
      "Epoch [19/25], Train Loss: 1074.6369, Eval Loss: 34.1088\n",
      "Epoch [20/25], Train Loss: 1010.4425, Eval Loss: 33.9129\n",
      "Epoch [21/25], Train Loss: 1019.4135, Eval Loss: 33.6402\n",
      "Epoch [22/25], Train Loss: 1072.0811, Eval Loss: 33.6825\n",
      "Epoch [23/25], Train Loss: 1010.5533, Eval Loss: 34.0895\n",
      "Epoch [24/25], Train Loss: 1052.3762, Eval Loss: 34.0184\n",
      "Epoch [25/25], Train Loss: 1058.4935, Eval Loss: 33.9963\n",
      "Epoch [1/25], Train Loss: 9309.4821, Eval Loss: 93.9919\n",
      "Epoch [2/25], Train Loss: 8427.8511, Eval Loss: 83.8949\n",
      "Epoch [3/25], Train Loss: 4049.8856, Eval Loss: 35.3541\n",
      "Epoch [4/25], Train Loss: 1378.5952, Eval Loss: 30.9647\n",
      "Epoch [5/25], Train Loss: 1163.0509, Eval Loss: 30.6327\n",
      "Epoch [6/25], Train Loss: 1156.0180, Eval Loss: 31.0580\n",
      "Epoch [7/25], Train Loss: 1151.5063, Eval Loss: 31.4561\n",
      "Epoch [8/25], Train Loss: 1131.7903, Eval Loss: 31.2115\n",
      "Epoch [9/25], Train Loss: 1167.7979, Eval Loss: 32.3195\n",
      "Epoch [10/25], Train Loss: 1167.7659, Eval Loss: 32.6135\n",
      "Epoch [11/25], Train Loss: 1104.3349, Eval Loss: 32.0903\n",
      "Epoch [12/25], Train Loss: 1069.6456, Eval Loss: 32.5955\n",
      "Epoch [13/25], Train Loss: 1066.5076, Eval Loss: 33.4457\n",
      "Epoch [14/25], Train Loss: 1125.2243, Eval Loss: 33.8755\n",
      "Epoch [15/25], Train Loss: 1107.8681, Eval Loss: 33.3902\n",
      "Epoch [16/25], Train Loss: 1068.6838, Eval Loss: 33.1422\n",
      "Epoch [17/25], Train Loss: 1027.7970, Eval Loss: 34.1570\n",
      "Epoch [18/25], Train Loss: 1044.9430, Eval Loss: 34.1690\n",
      "Epoch [19/25], Train Loss: 1052.1609, Eval Loss: 34.6610\n",
      "Epoch [20/25], Train Loss: 1043.5481, Eval Loss: 34.5868\n",
      "Epoch [21/25], Train Loss: 1018.6591, Eval Loss: 34.8833\n",
      "Epoch [22/25], Train Loss: 1052.6131, Eval Loss: 34.9286\n",
      "Epoch [23/25], Train Loss: 1030.4736, Eval Loss: 35.8903\n",
      "Epoch [24/25], Train Loss: 1053.9611, Eval Loss: 34.9531\n",
      "Epoch [25/25], Train Loss: 1066.1921, Eval Loss: 36.1694\n",
      "Epoch [1/25], Train Loss: 9618.2301, Eval Loss: 94.9566\n",
      "Epoch [2/25], Train Loss: 9245.3623, Eval Loss: 93.8776\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9598.5070, Eval Loss: 94.9261\n",
      "Epoch [2/25], Train Loss: 9267.2812, Eval Loss: 94.4979\n",
      "Epoch [3/25], Train Loss: 8936.5003, Eval Loss: 4695.6060\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 9328.3282, Eval Loss: 94.6967\n",
      "Epoch [2/25], Train Loss: 9225.9118, Eval Loss: 93.9907\n",
      "Epoch [3/25], Train Loss: 9099.1793, Eval Loss: 93.2893\n",
      "Epoch [4/25], Train Loss: 8969.6695, Eval Loss: 92.6587\n",
      "Epoch [5/25], Train Loss: 8852.0454, Eval Loss: 92.0960\n",
      "Epoch [6/25], Train Loss: 8746.8132, Eval Loss: 91.5937\n",
      "Epoch [7/25], Train Loss: 8652.1754, Eval Loss: 91.1368\n",
      "Epoch [8/25], Train Loss: 8566.1435, Eval Loss: 90.7082\n",
      "Epoch [9/25], Train Loss: 8485.7305, Eval Loss: 90.2986\n",
      "Epoch [10/25], Train Loss: 8410.0869, Eval Loss: 89.9086\n",
      "Epoch [11/25], Train Loss: 8338.9924, Eval Loss: 89.5330\n",
      "Epoch [12/25], Train Loss: 8269.7295, Eval Loss: 89.1670\n",
      "Epoch [13/25], Train Loss: 8203.3255, Eval Loss: 88.8088\n",
      "Epoch [14/25], Train Loss: 8139.2932, Eval Loss: 88.4580\n",
      "Epoch [15/25], Train Loss: 8075.8904, Eval Loss: 88.1127\n",
      "Epoch [16/25], Train Loss: 8013.0816, Eval Loss: 87.7716\n",
      "Epoch [17/25], Train Loss: 7952.3495, Eval Loss: 87.4347\n",
      "Epoch [18/25], Train Loss: 7893.4159, Eval Loss: 87.1019\n",
      "Epoch [19/25], Train Loss: 7833.7680, Eval Loss: 86.7715\n",
      "Epoch [20/25], Train Loss: 7775.7649, Eval Loss: 86.4439\n",
      "Epoch [21/25], Train Loss: 7718.1086, Eval Loss: 86.1190\n",
      "Epoch [22/25], Train Loss: 7661.2097, Eval Loss: 85.7964\n",
      "Epoch [23/25], Train Loss: 7605.0707, Eval Loss: 85.4758\n",
      "Epoch [24/25], Train Loss: 7549.4653, Eval Loss: 85.1573\n",
      "Epoch [25/25], Train Loss: 7494.5106, Eval Loss: 84.8406\n",
      "Epoch [1/25], Train Loss: 9321.0367, Eval Loss: 94.6777\n",
      "Epoch [2/25], Train Loss: 9213.0282, Eval Loss: 93.9799\n",
      "Epoch [3/25], Train Loss: 9082.8415, Eval Loss: 93.2594\n",
      "Epoch [4/25], Train Loss: 8948.4492, Eval Loss: 92.6107\n",
      "Epoch [5/25], Train Loss: 8829.7556, Eval Loss: 92.0537\n",
      "Epoch [6/25], Train Loss: 8728.8150, Eval Loss: 91.5640\n",
      "Epoch [7/25], Train Loss: 8639.1947, Eval Loss: 91.1193\n",
      "Epoch [8/25], Train Loss: 8557.0313, Eval Loss: 90.7064\n",
      "Epoch [9/25], Train Loss: 8481.2557, Eval Loss: 90.3149\n",
      "Epoch [10/25], Train Loss: 8410.2005, Eval Loss: 89.9382\n",
      "Epoch [11/25], Train Loss: 8341.9847, Eval Loss: 89.5724\n",
      "Epoch [12/25], Train Loss: 8275.4075, Eval Loss: 89.2154\n",
      "Epoch [13/25], Train Loss: 8210.7102, Eval Loss: 88.8653\n",
      "Epoch [14/25], Train Loss: 8147.9781, Eval Loss: 88.5208\n",
      "Epoch [15/25], Train Loss: 8086.0164, Eval Loss: 88.1810\n",
      "Epoch [16/25], Train Loss: 8025.1626, Eval Loss: 87.8452\n",
      "Epoch [17/25], Train Loss: 7965.6953, Eval Loss: 87.5130\n",
      "Epoch [18/25], Train Loss: 7906.5689, Eval Loss: 87.1838\n",
      "Epoch [19/25], Train Loss: 7848.4614, Eval Loss: 86.8574\n",
      "Epoch [20/25], Train Loss: 7790.9772, Eval Loss: 86.5335\n",
      "Epoch [21/25], Train Loss: 7734.0664, Eval Loss: 86.2118\n",
      "Epoch [22/25], Train Loss: 7677.9403, Eval Loss: 85.8923\n",
      "Epoch [23/25], Train Loss: 7622.4079, Eval Loss: 85.5745\n",
      "Epoch [24/25], Train Loss: 7567.1866, Eval Loss: 85.2585\n",
      "Epoch [25/25], Train Loss: 7512.5872, Eval Loss: 84.9442\n",
      "Epoch [1/25], Train Loss: 8915.6418, Eval Loss: 87.7510\n",
      "Epoch [2/25], Train Loss: 6912.8134, Eval Loss: 75.0629\n",
      "Epoch [3/25], Train Loss: 5084.4384, Eval Loss: 64.4054\n",
      "Epoch [4/25], Train Loss: 3800.4676, Eval Loss: 55.8312\n",
      "Epoch [5/25], Train Loss: 2905.5043, Eval Loss: 49.0312\n",
      "Epoch [6/25], Train Loss: 2282.8556, Eval Loss: 43.7244\n",
      "Epoch [7/25], Train Loss: 1848.5480, Eval Loss: 39.6599\n",
      "Epoch [8/25], Train Loss: 1546.3594, Eval Loss: 36.6050\n",
      "Epoch [9/25], Train Loss: 1335.6899, Eval Loss: 34.3511\n",
      "Epoch [10/25], Train Loss: 1189.1499, Eval Loss: 32.7145\n",
      "Epoch [11/25], Train Loss: 1086.8446, Eval Loss: 31.5433\n",
      "Epoch [12/25], Train Loss: 1015.7013, Eval Loss: 30.7150\n",
      "Epoch [13/25], Train Loss: 966.2712, Eval Loss: 30.1347\n",
      "Epoch [14/25], Train Loss: 931.6698, Eval Loss: 29.7318\n",
      "Epoch [15/25], Train Loss: 907.8356, Eval Loss: 29.4538\n",
      "Epoch [16/25], Train Loss: 891.0694, Eval Loss: 29.2635\n",
      "Epoch [17/25], Train Loss: 879.4552, Eval Loss: 29.1342\n",
      "Epoch [18/25], Train Loss: 871.3412, Eval Loss: 29.0470\n",
      "Epoch [19/25], Train Loss: 865.6719, Eval Loss: 28.9889\n",
      "Epoch [20/25], Train Loss: 861.8451, Eval Loss: 28.9505\n",
      "Epoch [21/25], Train Loss: 859.1399, Eval Loss: 28.9257\n",
      "Epoch [22/25], Train Loss: 857.2637, Eval Loss: 28.9099\n",
      "Epoch [23/25], Train Loss: 855.8227, Eval Loss: 28.9001\n",
      "Epoch [24/25], Train Loss: 855.3057, Eval Loss: 28.8944\n",
      "Epoch [25/25], Train Loss: 854.8314, Eval Loss: 28.8914\n",
      "Epoch [1/25], Train Loss: 8931.8311, Eval Loss: 88.0184\n",
      "Epoch [2/25], Train Loss: 7014.2689, Eval Loss: 75.6301\n",
      "Epoch [3/25], Train Loss: 5177.8509, Eval Loss: 64.9004\n",
      "Epoch [4/25], Train Loss: 3864.6377, Eval Loss: 56.2325\n",
      "Epoch [5/25], Train Loss: 2949.4947, Eval Loss: 49.3463\n",
      "Epoch [6/25], Train Loss: 2313.7708, Eval Loss: 43.9671\n",
      "Epoch [7/25], Train Loss: 1870.0015, Eval Loss: 39.8422\n",
      "Epoch [8/25], Train Loss: 1561.7118, Eval Loss: 36.7390\n",
      "Epoch [9/25], Train Loss: 1346.0571, Eval Loss: 34.4466\n",
      "Epoch [10/25], Train Loss: 1196.2498, Eval Loss: 32.7817\n",
      "Epoch [11/25], Train Loss: 1091.8947, Eval Loss: 31.5901\n",
      "Epoch [12/25], Train Loss: 1019.4635, Eval Loss: 30.7464\n",
      "Epoch [13/25], Train Loss: 968.8653, Eval Loss: 30.1554\n",
      "Epoch [14/25], Train Loss: 933.7308, Eval Loss: 29.7450\n",
      "Epoch [15/25], Train Loss: 909.2022, Eval Loss: 29.4623\n",
      "Epoch [16/25], Train Loss: 892.0793, Eval Loss: 29.2688\n",
      "Epoch [17/25], Train Loss: 880.0354, Eval Loss: 29.1374\n",
      "Epoch [18/25], Train Loss: 872.1056, Eval Loss: 29.0488\n",
      "Epoch [19/25], Train Loss: 866.0920, Eval Loss: 28.9897\n",
      "Epoch [20/25], Train Loss: 862.1822, Eval Loss: 28.9509\n",
      "Epoch [21/25], Train Loss: 859.0604, Eval Loss: 28.9257\n",
      "Epoch [22/25], Train Loss: 857.2012, Eval Loss: 28.9098\n",
      "Epoch [23/25], Train Loss: 856.2424, Eval Loss: 28.9000\n",
      "Epoch [24/25], Train Loss: 854.9480, Eval Loss: 28.8943\n",
      "Epoch [25/25], Train Loss: 854.3994, Eval Loss: 28.8913\n",
      "Epoch [1/25], Train Loss: 3974.7524, Eval Loss: 39.0819\n",
      "Epoch [2/25], Train Loss: 1198.6737, Eval Loss: 35.5283\n",
      "Epoch [3/25], Train Loss: 1099.1914, Eval Loss: 45.2569\n",
      "Epoch [4/25], Train Loss: 1037.8443, Eval Loss: 44.0037\n",
      "Epoch [5/25], Train Loss: 1020.1012, Eval Loss: 46.2496\n",
      "Epoch [6/25], Train Loss: 1054.2324, Eval Loss: 52.2812\n",
      "Epoch [7/25], Train Loss: 1014.4570, Eval Loss: 53.0728\n",
      "Epoch [8/25], Train Loss: 1053.8863, Eval Loss: 56.7029\n",
      "Epoch [9/25], Train Loss: 994.4041, Eval Loss: 54.3332\n",
      "Epoch [10/25], Train Loss: 1070.6274, Eval Loss: 58.6098\n",
      "Epoch [11/25], Train Loss: 981.9009, Eval Loss: 58.9842\n",
      "Epoch [12/25], Train Loss: 995.2248, Eval Loss: 60.8566\n",
      "Epoch [13/25], Train Loss: 962.6664, Eval Loss: 61.9222\n",
      "Epoch [14/25], Train Loss: 978.4517, Eval Loss: 62.7242\n",
      "Epoch [15/25], Train Loss: 967.9132, Eval Loss: 60.7200\n",
      "Epoch [16/25], Train Loss: 958.4075, Eval Loss: 63.8940\n",
      "Epoch [17/25], Train Loss: 977.9643, Eval Loss: 63.0323\n",
      "Epoch [18/25], Train Loss: 955.8072, Eval Loss: 63.7703\n",
      "Epoch [19/25], Train Loss: 928.8190, Eval Loss: 62.7225\n",
      "Epoch [20/25], Train Loss: 980.3775, Eval Loss: 61.8924\n",
      "Epoch [21/25], Train Loss: 976.2155, Eval Loss: 62.0393\n",
      "Epoch [22/25], Train Loss: 960.2143, Eval Loss: 63.5552\n",
      "Epoch [23/25], Train Loss: 950.3600, Eval Loss: 64.5890\n",
      "Epoch [24/25], Train Loss: 963.5696, Eval Loss: 61.2726\n",
      "Epoch [25/25], Train Loss: 909.6021, Eval Loss: 62.9800\n",
      "Epoch [1/25], Train Loss: 3423.4127, Eval Loss: 37.0974\n",
      "Epoch [2/25], Train Loss: 1128.1258, Eval Loss: 36.6049\n",
      "Epoch [3/25], Train Loss: 1110.8735, Eval Loss: 37.5449\n",
      "Epoch [4/25], Train Loss: 1017.4240, Eval Loss: 39.0607\n",
      "Epoch [5/25], Train Loss: 1038.0073, Eval Loss: 40.0480\n",
      "Epoch [6/25], Train Loss: 1057.5803, Eval Loss: 47.2328\n",
      "Epoch [7/25], Train Loss: 1039.3596, Eval Loss: 48.7995\n",
      "Epoch [8/25], Train Loss: 1020.6080, Eval Loss: 45.1854\n",
      "Epoch [9/25], Train Loss: 1008.0585, Eval Loss: 45.3030\n",
      "Epoch [10/25], Train Loss: 972.6132, Eval Loss: 48.9318\n",
      "Epoch [11/25], Train Loss: 974.3114, Eval Loss: 52.0016\n",
      "Epoch [12/25], Train Loss: 990.9543, Eval Loss: 54.2973\n",
      "Epoch [13/25], Train Loss: 965.2600, Eval Loss: 54.1927\n",
      "Epoch [14/25], Train Loss: 1010.2697, Eval Loss: 59.2080\n",
      "Epoch [15/25], Train Loss: 975.3293, Eval Loss: 58.4239\n",
      "Epoch [16/25], Train Loss: 972.1380, Eval Loss: 55.3799\n",
      "Epoch [17/25], Train Loss: 988.2460, Eval Loss: 56.2719\n",
      "Epoch [18/25], Train Loss: 961.6759, Eval Loss: 58.0331\n",
      "Epoch [19/25], Train Loss: 966.1471, Eval Loss: 57.2006\n",
      "Epoch [20/25], Train Loss: 964.4597, Eval Loss: 55.9905\n",
      "Epoch [21/25], Train Loss: 980.2313, Eval Loss: 59.2016\n",
      "Epoch [22/25], Train Loss: 1002.0439, Eval Loss: 56.8197\n",
      "Epoch [23/25], Train Loss: 929.3620, Eval Loss: 61.1671\n",
      "Epoch [24/25], Train Loss: 969.1968, Eval Loss: 62.3294\n",
      "Epoch [25/25], Train Loss: 932.2722, Eval Loss: 60.6667\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 8963.9341, Eval Loss: 90.7530\n",
      "Epoch [2/25], Train Loss: 8181.8968, Eval Loss: 87.0306\n",
      "Epoch [3/25], Train Loss: 7562.6621, Eval Loss: 83.7180\n",
      "Epoch [4/25], Train Loss: 7016.7029, Eval Loss: 80.6131\n",
      "Epoch [5/25], Train Loss: 6520.8382, Eval Loss: 77.6626\n",
      "Epoch [6/25], Train Loss: 6063.8210, Eval Loss: 74.8430\n",
      "Epoch [7/25], Train Loss: 5642.7324, Eval Loss: 72.1433\n",
      "Epoch [8/25], Train Loss: 5253.5872, Eval Loss: 69.5565\n",
      "Epoch [9/25], Train Loss: 4893.5345, Eval Loss: 67.0777\n",
      "Epoch [10/25], Train Loss: 4560.4525, Eval Loss: 64.7033\n",
      "Epoch [11/25], Train Loss: 4252.2970, Eval Loss: 62.4304\n",
      "Epoch [12/25], Train Loss: 3967.2434, Eval Loss: 60.2565\n",
      "Epoch [13/25], Train Loss: 3703.8282, Eval Loss: 58.1792\n",
      "Epoch [14/25], Train Loss: 3460.3478, Eval Loss: 56.1964\n",
      "Epoch [15/25], Train Loss: 3235.4389, Eval Loss: 54.3062\n",
      "Epoch [16/25], Train Loss: 3027.8999, Eval Loss: 52.5065\n",
      "Epoch [17/25], Train Loss: 2836.3787, Eval Loss: 50.7954\n",
      "Epoch [18/25], Train Loss: 2659.8602, Eval Loss: 49.1711\n",
      "Epoch [19/25], Train Loss: 2497.2238, Eval Loss: 47.6317\n",
      "Epoch [20/25], Train Loss: 2347.4967, Eval Loss: 46.1754\n",
      "Epoch [21/25], Train Loss: 2209.7753, Eval Loss: 44.8003\n",
      "Epoch [22/25], Train Loss: 2083.2354, Eval Loss: 43.5045\n",
      "Epoch [23/25], Train Loss: 1967.0047, Eval Loss: 42.2860\n",
      "Epoch [24/25], Train Loss: 1860.3936, Eval Loss: 41.1427\n",
      "Epoch [25/25], Train Loss: 1762.7107, Eval Loss: 40.0723\n",
      "Epoch [1/25], Train Loss: 8953.6631, Eval Loss: 90.6641\n",
      "Epoch [2/25], Train Loss: 8168.3382, Eval Loss: 86.9444\n",
      "Epoch [3/25], Train Loss: 7545.9767, Eval Loss: 83.6101\n",
      "Epoch [4/25], Train Loss: 6997.9087, Eval Loss: 80.4949\n",
      "Epoch [5/25], Train Loss: 6500.2885, Eval Loss: 77.5372\n",
      "Epoch [6/25], Train Loss: 6043.9008, Eval Loss: 74.7137\n",
      "Epoch [7/25], Train Loss: 5622.9318, Eval Loss: 72.0113\n",
      "Epoch [8/25], Train Loss: 5233.9770, Eval Loss: 69.4227\n",
      "Epoch [9/25], Train Loss: 4874.4149, Eval Loss: 66.9431\n",
      "Epoch [10/25], Train Loss: 4541.8487, Eval Loss: 64.5685\n",
      "Epoch [11/25], Train Loss: 4234.7019, Eval Loss: 62.2961\n",
      "Epoch [12/25], Train Loss: 3950.3129, Eval Loss: 60.1232\n",
      "Epoch [13/25], Train Loss: 3687.3884, Eval Loss: 58.0473\n",
      "Epoch [14/25], Train Loss: 3444.4782, Eval Loss: 56.0664\n",
      "Epoch [15/25], Train Loss: 3220.3382, Eval Loss: 54.1784\n",
      "Epoch [16/25], Train Loss: 3013.4770, Eval Loss: 52.3813\n",
      "Epoch [17/25], Train Loss: 2822.7460, Eval Loss: 50.6733\n",
      "Epoch [18/25], Train Loss: 2646.9287, Eval Loss: 49.0523\n",
      "Epoch [19/25], Train Loss: 2484.9987, Eval Loss: 47.5166\n",
      "Epoch [20/25], Train Loss: 2335.9961, Eval Loss: 46.0642\n",
      "Epoch [21/25], Train Loss: 2198.9566, Eval Loss: 44.6932\n",
      "Epoch [22/25], Train Loss: 2073.0647, Eval Loss: 43.4017\n",
      "Epoch [23/25], Train Loss: 1957.4990, Eval Loss: 42.1876\n",
      "Epoch [24/25], Train Loss: 1851.5181, Eval Loss: 41.0488\n",
      "Epoch [25/25], Train Loss: 1754.4520, Eval Loss: 39.9831\n",
      "Epoch [1/25], Train Loss: 3682.3649, Eval Loss: 32.7840\n",
      "Epoch [2/25], Train Loss: 930.7891, Eval Loss: 28.9608\n",
      "Epoch [3/25], Train Loss: 856.7385, Eval Loss: 28.8964\n",
      "Epoch [4/25], Train Loss: 854.3410, Eval Loss: 28.9012\n",
      "Epoch [5/25], Train Loss: 854.7949, Eval Loss: 28.9024\n",
      "Epoch [6/25], Train Loss: 854.7285, Eval Loss: 28.9024\n",
      "Epoch [7/25], Train Loss: 854.8064, Eval Loss: 28.9025\n",
      "Epoch [8/25], Train Loss: 854.5123, Eval Loss: 28.9026\n",
      "Epoch [9/25], Train Loss: 854.5569, Eval Loss: 28.9025\n",
      "Epoch [10/25], Train Loss: 854.8775, Eval Loss: 28.9028\n",
      "Epoch [11/25], Train Loss: 854.7518, Eval Loss: 28.9030\n",
      "Epoch [12/25], Train Loss: 854.5591, Eval Loss: 28.9031\n",
      "Epoch [13/25], Train Loss: 854.9497, Eval Loss: 28.9026\n",
      "Epoch [14/25], Train Loss: 854.5228, Eval Loss: 28.9027\n",
      "Epoch [15/25], Train Loss: 854.3141, Eval Loss: 28.9040\n",
      "Epoch [16/25], Train Loss: 854.2990, Eval Loss: 28.8999\n",
      "Epoch [17/25], Train Loss: 855.2790, Eval Loss: 28.9072\n",
      "Epoch [18/25], Train Loss: 856.8981, Eval Loss: 28.9133\n",
      "Epoch [19/25], Train Loss: 853.7630, Eval Loss: 28.8937\n",
      "Epoch [20/25], Train Loss: 855.1497, Eval Loss: 28.9107\n",
      "Epoch [21/25], Train Loss: 854.0856, Eval Loss: 28.9055\n",
      "Epoch [22/25], Train Loss: 856.0329, Eval Loss: 28.9162\n",
      "Epoch [23/25], Train Loss: 855.3592, Eval Loss: 28.9097\n",
      "Epoch [24/25], Train Loss: 854.1120, Eval Loss: 28.8839\n",
      "Epoch [25/25], Train Loss: 856.2213, Eval Loss: 28.9107\n",
      "Epoch [1/25], Train Loss: 3718.4940, Eval Loss: 32.8209\n",
      "Epoch [2/25], Train Loss: 931.7558, Eval Loss: 28.9617\n",
      "Epoch [3/25], Train Loss: 856.6165, Eval Loss: 28.8965\n",
      "Epoch [4/25], Train Loss: 854.5937, Eval Loss: 28.9010\n",
      "Epoch [5/25], Train Loss: 854.6375, Eval Loss: 28.9021\n",
      "Epoch [6/25], Train Loss: 854.5731, Eval Loss: 28.9025\n",
      "Epoch [7/25], Train Loss: 854.6284, Eval Loss: 28.9029\n",
      "Epoch [8/25], Train Loss: 854.6249, Eval Loss: 28.9028\n",
      "Epoch [9/25], Train Loss: 854.7949, Eval Loss: 28.9025\n",
      "Epoch [10/25], Train Loss: 854.8723, Eval Loss: 28.9026\n",
      "Epoch [11/25], Train Loss: 854.8520, Eval Loss: 28.9025\n",
      "Epoch [12/25], Train Loss: 854.6173, Eval Loss: 28.9025\n",
      "Epoch [13/25], Train Loss: 854.6293, Eval Loss: 28.9027\n",
      "Epoch [14/25], Train Loss: 854.6359, Eval Loss: 28.9025\n",
      "Epoch [15/25], Train Loss: 854.5516, Eval Loss: 28.9025\n",
      "Epoch [16/25], Train Loss: 854.6425, Eval Loss: 28.9026\n",
      "Epoch [17/25], Train Loss: 854.6204, Eval Loss: 28.9026\n",
      "Epoch [18/25], Train Loss: 854.4879, Eval Loss: 28.9028\n",
      "Epoch [19/25], Train Loss: 854.5009, Eval Loss: 28.9030\n",
      "Epoch [20/25], Train Loss: 854.3541, Eval Loss: 28.9039\n",
      "Epoch [21/25], Train Loss: 853.6317, Eval Loss: 28.9083\n",
      "Epoch [22/25], Train Loss: 855.9899, Eval Loss: 28.9057\n",
      "Epoch [23/25], Train Loss: 855.2853, Eval Loss: 28.9052\n",
      "Epoch [24/25], Train Loss: 854.5638, Eval Loss: 28.9035\n",
      "Epoch [25/25], Train Loss: 854.8046, Eval Loss: 28.9031\n",
      "Epoch [1/25], Train Loss: 3627.8589, Eval Loss: 47.0373\n",
      "Epoch [2/25], Train Loss: 1351.0008, Eval Loss: 46.0238\n",
      "Epoch [3/25], Train Loss: 1242.4404, Eval Loss: 49.2605\n",
      "Epoch [4/25], Train Loss: 1260.9670, Eval Loss: 58.4974\n",
      "Epoch [5/25], Train Loss: 1217.9868, Eval Loss: 49.3955\n",
      "Epoch [6/25], Train Loss: 1305.1210, Eval Loss: 53.1143\n",
      "Epoch [7/25], Train Loss: 1220.4080, Eval Loss: 50.9154\n",
      "Epoch [8/25], Train Loss: 1193.9758, Eval Loss: 58.4877\n",
      "Epoch [9/25], Train Loss: 1192.6176, Eval Loss: 56.5551\n",
      "Epoch [10/25], Train Loss: 1120.2123, Eval Loss: 55.2110\n",
      "Epoch [11/25], Train Loss: 1241.7819, Eval Loss: 58.5005\n",
      "Epoch [12/25], Train Loss: 1037.0585, Eval Loss: 50.9518\n",
      "Epoch [13/25], Train Loss: 1099.7073, Eval Loss: 56.7422\n",
      "Epoch [14/25], Train Loss: 1066.0090, Eval Loss: 51.0603\n",
      "Epoch [15/25], Train Loss: 1079.9177, Eval Loss: 61.4305\n",
      "Epoch [16/25], Train Loss: 1157.9315, Eval Loss: 54.5802\n",
      "Epoch [17/25], Train Loss: 1018.2751, Eval Loss: 56.8483\n",
      "Epoch [18/25], Train Loss: 1032.4894, Eval Loss: 54.1594\n",
      "Epoch [19/25], Train Loss: 976.8568, Eval Loss: 55.2728\n",
      "Epoch [20/25], Train Loss: 936.8596, Eval Loss: 51.6896\n",
      "Epoch [21/25], Train Loss: 1012.2008, Eval Loss: 56.4226\n",
      "Epoch [22/25], Train Loss: 939.5577, Eval Loss: 48.2582\n",
      "Epoch [23/25], Train Loss: 927.9205, Eval Loss: 48.4672\n",
      "Epoch [24/25], Train Loss: 877.1923, Eval Loss: 44.7875\n",
      "Epoch [25/25], Train Loss: 840.5441, Eval Loss: 43.4811\n",
      "Epoch [1/25], Train Loss: 2201.5184, Eval Loss: 39.6048\n",
      "Epoch [2/25], Train Loss: 1409.9112, Eval Loss: 41.0182\n",
      "Epoch [3/25], Train Loss: 1425.2472, Eval Loss: 40.1193\n",
      "Epoch [4/25], Train Loss: 1329.4648, Eval Loss: 49.7740\n",
      "Epoch [5/25], Train Loss: 1328.4385, Eval Loss: 54.8018\n",
      "Epoch [6/25], Train Loss: 1305.2297, Eval Loss: 42.8568\n",
      "Epoch [7/25], Train Loss: 1562.6853, Eval Loss: 39.8556\n",
      "Epoch [8/25], Train Loss: 1258.0690, Eval Loss: 48.2300\n",
      "Epoch [9/25], Train Loss: 1152.3424, Eval Loss: 52.2461\n",
      "Epoch [10/25], Train Loss: 1099.5288, Eval Loss: 49.0904\n",
      "Epoch [11/25], Train Loss: 1082.3187, Eval Loss: 52.6951\n",
      "Epoch [12/25], Train Loss: 1091.2320, Eval Loss: 52.5355\n",
      "Epoch [13/25], Train Loss: 1088.9828, Eval Loss: 52.3321\n",
      "Epoch [14/25], Train Loss: 1103.6358, Eval Loss: 53.0862\n",
      "Epoch [15/25], Train Loss: 952.5166, Eval Loss: 43.7660\n",
      "Epoch [16/25], Train Loss: 933.7872, Eval Loss: 41.4647\n",
      "Epoch [17/25], Train Loss: 838.6916, Eval Loss: 38.7490\n",
      "Epoch [18/25], Train Loss: 812.0486, Eval Loss: 35.0978\n",
      "Epoch [19/25], Train Loss: 766.5148, Eval Loss: 32.5720\n",
      "Epoch [20/25], Train Loss: 838.2018, Eval Loss: 35.5030\n",
      "Epoch [21/25], Train Loss: 754.3427, Eval Loss: 28.4337\n",
      "Epoch [22/25], Train Loss: 717.7145, Eval Loss: 30.3414\n",
      "Epoch [23/25], Train Loss: 706.4932, Eval Loss: 27.1083\n",
      "Epoch [24/25], Train Loss: 704.7685, Eval Loss: 28.1426\n",
      "Epoch [25/25], Train Loss: 687.3271, Eval Loss: 26.3614\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [2/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [3/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [4/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [5/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [6/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [7/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [8/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [9/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [10/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [11/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [12/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [13/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [14/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [15/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [16/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [17/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [18/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [19/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [20/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [21/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [22/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [23/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [24/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [25/25], Train Loss: nan, Eval Loss: nan\n",
      "Epoch [1/25], Train Loss: 6643.2260, Eval Loss: 64.8946\n",
      "Epoch [2/25], Train Loss: 3208.6377, Eval Loss: 46.0520\n",
      "Epoch [3/25], Train Loss: 1769.0241, Eval Loss: 36.0357\n",
      "Epoch [4/25], Train Loss: 1186.7086, Eval Loss: 31.4935\n",
      "Epoch [5/25], Train Loss: 965.8061, Eval Loss: 29.7031\n",
      "Epoch [6/25], Train Loss: 887.0953, Eval Loss: 29.0982\n",
      "Epoch [7/25], Train Loss: 862.5118, Eval Loss: 28.9352\n",
      "Epoch [8/25], Train Loss: 858.6241, Eval Loss: 28.9030\n",
      "Epoch [9/25], Train Loss: 852.3436, Eval Loss: 28.9926\n",
      "Epoch [10/25], Train Loss: 861.6909, Eval Loss: 28.8968\n",
      "Epoch [11/25], Train Loss: 855.1197, Eval Loss: 28.9053\n",
      "Epoch [12/25], Train Loss: 854.1575, Eval Loss: 28.9139\n",
      "Epoch [13/25], Train Loss: 854.1007, Eval Loss: 28.9082\n",
      "Epoch [14/25], Train Loss: 854.0435, Eval Loss: 28.9096\n",
      "Epoch [15/25], Train Loss: 861.5555, Eval Loss: 28.9067\n",
      "Epoch [16/25], Train Loss: 861.1301, Eval Loss: 29.0037\n",
      "Epoch [17/25], Train Loss: 852.4096, Eval Loss: 28.9671\n",
      "Epoch [18/25], Train Loss: 852.5900, Eval Loss: 28.9903\n",
      "Epoch [19/25], Train Loss: 864.5798, Eval Loss: 28.9945\n",
      "Epoch [20/25], Train Loss: 858.2569, Eval Loss: 28.9178\n",
      "Epoch [21/25], Train Loss: 854.7719, Eval Loss: 28.9098\n",
      "Epoch [22/25], Train Loss: 853.5227, Eval Loss: 28.9165\n",
      "Epoch [23/25], Train Loss: 856.3101, Eval Loss: 28.9156\n",
      "Epoch [24/25], Train Loss: 856.8553, Eval Loss: 28.9157\n",
      "Epoch [25/25], Train Loss: 856.4421, Eval Loss: 28.8926\n",
      "Epoch [1/25], Train Loss: 6587.9294, Eval Loss: 64.6221\n",
      "Epoch [2/25], Train Loss: 3183.0289, Eval Loss: 45.8698\n",
      "Epoch [3/25], Train Loss: 1753.6299, Eval Loss: 35.9359\n",
      "Epoch [4/25], Train Loss: 1181.2305, Eval Loss: 31.4441\n",
      "Epoch [5/25], Train Loss: 963.3096, Eval Loss: 29.6828\n",
      "Epoch [6/25], Train Loss: 886.2186, Eval Loss: 29.0939\n",
      "Epoch [7/25], Train Loss: 861.9116, Eval Loss: 28.9341\n",
      "Epoch [8/25], Train Loss: 855.3310, Eval Loss: 28.9028\n",
      "Epoch [9/25], Train Loss: 853.8823, Eval Loss: 28.9011\n",
      "Epoch [10/25], Train Loss: 879.0214, Eval Loss: 28.9283\n",
      "Epoch [11/25], Train Loss: 859.8748, Eval Loss: 28.9048\n",
      "Epoch [12/25], Train Loss: 855.9081, Eval Loss: 28.8999\n",
      "Epoch [13/25], Train Loss: 854.6994, Eval Loss: 28.9062\n",
      "Epoch [14/25], Train Loss: 852.8470, Eval Loss: 28.9106\n",
      "Epoch [15/25], Train Loss: 854.0974, Eval Loss: 28.9128\n",
      "Epoch [16/25], Train Loss: 855.1722, Eval Loss: 28.9039\n",
      "Epoch [17/25], Train Loss: 852.5260, Eval Loss: 28.9022\n",
      "Epoch [18/25], Train Loss: 855.8316, Eval Loss: 28.8974\n",
      "Epoch [19/25], Train Loss: 854.7618, Eval Loss: 28.9160\n",
      "Epoch [20/25], Train Loss: 852.6661, Eval Loss: 28.9137\n",
      "Epoch [21/25], Train Loss: 854.3262, Eval Loss: 28.9056\n",
      "Epoch [22/25], Train Loss: 853.6779, Eval Loss: 28.9095\n",
      "Epoch [23/25], Train Loss: 856.1238, Eval Loss: 28.9205\n",
      "Epoch [24/25], Train Loss: 854.4011, Eval Loss: 28.9116\n",
      "Epoch [25/25], Train Loss: 859.5451, Eval Loss: 28.9032\n",
      "Epoch [1/25], Train Loss: 1321.1665, Eval Loss: 29.3461\n",
      "Epoch [2/25], Train Loss: 869.6506, Eval Loss: 29.3537\n",
      "Epoch [3/25], Train Loss: 869.4221, Eval Loss: 29.3539\n",
      "Epoch [4/25], Train Loss: 869.4690, Eval Loss: 29.3539\n",
      "Epoch [5/25], Train Loss: 869.3479, Eval Loss: 29.3539\n",
      "Epoch [6/25], Train Loss: 869.3586, Eval Loss: 29.3539\n",
      "Epoch [7/25], Train Loss: 868.8464, Eval Loss: 29.3846\n",
      "Epoch [8/25], Train Loss: 869.3399, Eval Loss: 29.3539\n",
      "Epoch [9/25], Train Loss: 869.4026, Eval Loss: 29.3538\n",
      "Epoch [10/25], Train Loss: 869.2800, Eval Loss: 29.3539\n",
      "Epoch [11/25], Train Loss: 869.3467, Eval Loss: 29.3539\n",
      "Epoch [12/25], Train Loss: 869.4115, Eval Loss: 29.3539\n",
      "Epoch [13/25], Train Loss: 869.5158, Eval Loss: 29.3539\n",
      "Epoch [14/25], Train Loss: 869.3510, Eval Loss: 29.3539\n",
      "Epoch [15/25], Train Loss: 869.3509, Eval Loss: 29.3539\n",
      "Epoch [16/25], Train Loss: 869.3451, Eval Loss: 29.3539\n",
      "Epoch [17/25], Train Loss: 869.3403, Eval Loss: 29.3538\n",
      "Epoch [18/25], Train Loss: 869.3800, Eval Loss: 29.3539\n",
      "Epoch [19/25], Train Loss: 869.3469, Eval Loss: 29.3539\n",
      "Epoch [20/25], Train Loss: 869.7288, Eval Loss: 29.3539\n",
      "Epoch [21/25], Train Loss: 869.3591, Eval Loss: 29.3539\n",
      "Epoch [22/25], Train Loss: 869.3537, Eval Loss: 29.3539\n",
      "Epoch [23/25], Train Loss: 869.3552, Eval Loss: 29.3539\n",
      "Epoch [24/25], Train Loss: 869.4974, Eval Loss: 29.3501\n",
      "Epoch [25/25], Train Loss: 869.3746, Eval Loss: 29.3539\n",
      "Epoch [1/25], Train Loss: 1374.1449, Eval Loss: 29.3595\n",
      "Epoch [2/25], Train Loss: 872.2007, Eval Loss: 29.3415\n",
      "Epoch [3/25], Train Loss: 871.9162, Eval Loss: 29.3444\n",
      "Epoch [4/25], Train Loss: 871.9879, Eval Loss: 29.3563\n",
      "Epoch [5/25], Train Loss: 871.3617, Eval Loss: 29.3513\n",
      "Epoch [6/25], Train Loss: 868.9371, Eval Loss: 29.3502\n",
      "Epoch [7/25], Train Loss: 869.6022, Eval Loss: 29.3540\n",
      "Epoch [8/25], Train Loss: 869.9905, Eval Loss: 29.3539\n",
      "Epoch [9/25], Train Loss: 869.3526, Eval Loss: 29.3530\n",
      "Epoch [10/25], Train Loss: 869.7125, Eval Loss: 29.3541\n",
      "Epoch [11/25], Train Loss: 872.9168, Eval Loss: 29.3511\n",
      "Epoch [12/25], Train Loss: 871.9158, Eval Loss: 29.3540\n",
      "Epoch [13/25], Train Loss: 870.3567, Eval Loss: 29.3534\n",
      "Epoch [14/25], Train Loss: 869.7968, Eval Loss: 29.3816\n",
      "Epoch [15/25], Train Loss: 869.8989, Eval Loss: 29.3476\n",
      "Epoch [16/25], Train Loss: 871.5700, Eval Loss: 29.3503\n",
      "Epoch [17/25], Train Loss: 869.0781, Eval Loss: 29.3428\n",
      "Epoch [18/25], Train Loss: 869.3648, Eval Loss: 29.3478\n",
      "Epoch [19/25], Train Loss: 869.1936, Eval Loss: 29.4204\n",
      "Epoch [20/25], Train Loss: 869.7516, Eval Loss: 29.3495\n",
      "Epoch [21/25], Train Loss: 869.0500, Eval Loss: 29.3783\n",
      "Epoch [22/25], Train Loss: 869.2710, Eval Loss: 29.3525\n",
      "Epoch [23/25], Train Loss: 869.5206, Eval Loss: 29.3241\n",
      "Epoch [24/25], Train Loss: 869.3499, Eval Loss: 29.3538\n",
      "Epoch [25/25], Train Loss: 869.3469, Eval Loss: 29.3525\n",
      "Predição: tensor([[ 70.2719,  84.9925, 134.8723,  49.8800],\n",
      "        [ 70.2719,  84.9925, 134.8723,  49.8800],\n",
      "        [ 70.2719,  84.9925, 134.8723,  49.8800],\n",
      "        ...,\n",
      "        [ 70.2719,  84.9925, 134.8723,  49.8800],\n",
      "        [ 70.2719,  84.9925, 134.8723,  49.8800],\n",
      "        [ 70.2719,  84.9925, 134.8723,  49.8800]])\n"
     ]
    }
   ],
   "source": [
    "# Dados de exemplo\n",
    "# Suponha batch_size = 1, seq_len = 4, input_size = 2 (x, y)\n",
    "\n",
    "# Inicializa a RNN\n",
    "model = ControlRNN(input_size=4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "\n",
    "hidden_size = [300, 100, 50]\n",
    "num_layers = [1,2]\n",
    "dropout_rate = [0,0.25,0.75]\n",
    "learning_rate = [0.0001, 0.001, 0.01]\n",
    "weight_decay = [0, 0.0005]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adam', 'sgd']\n",
    "best_model = None\n",
    "best_score = None\n",
    "\n",
    "for hs in hidden_size:\n",
    "    for nl in num_layers:\n",
    "        for dr in dropout_rate:\n",
    "            if(not((dr>0) and (nl==1))):\n",
    "                for lr in learning_rate:\n",
    "                    for a in activation:\n",
    "                        for o in optimizer:\n",
    "                            #if(o=='lbfgs'):\n",
    "                            #    model = ControlRNN(input_size=4, hidden_size=hs, \n",
    "                            #                        num_layers=nl,\n",
    "                            #                        activation=a, dropout_rate=dr)\n",
    "                            #    opt = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "                            #    model, _, scores = train_net(model, train_loader, test_loader, 25, opt, verbose=1)\n",
    "                            #    score = np.mean(scores[1])\n",
    "                            #    if(best_score is None or best_score > score):\n",
    "                            #        print('[Melhor modelo atualizado]')\n",
    "                            #        print('hs:{}, nl:{}, dr:{}, lr:{}, a:{}, o:{}'.format(hs, nl, dr, lr, a, o))\n",
    "                            #        best_model = model\n",
    "                            #        best_score = score\n",
    "                            #else:\n",
    "                                for wd in weight_decay:\n",
    "                                    model = ControlRNN(input_size=4, hidden_size=hs, \n",
    "                                                    num_layers=nl,\n",
    "                                                    activation=a, dropout_rate=dr)\n",
    "                                    if(o=='adam'):\n",
    "                                        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "                                    else:\n",
    "                                        opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "                                    model, _, scores = train_net(model, train_loader, test_loader, 25, opt, verbose=1)\n",
    "                                    score = np.mean(scores[1])\n",
    "                                    if(best_score is None or best_score > score):\n",
    "                                        print('[Melhor modelo atualizado]')\n",
    "                                        print('hs:{}, nl:{}, dr:{}, lr:{}, a:{}, o:{}, wd:{}'.format(hs, nl, dr, lr, a, o, wd))\n",
    "                                        best_model = model\n",
    "                                        best_score = score\n",
    "                                \n",
    "\n",
    "# Teste\n",
    "predicted = best_model(input_data).detach()\n",
    "print(\"Predição:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlRNN(\n",
       "  (rnn): RNN(4, 300, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=300, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor modelo:\n",
    "\n",
    "- Número de camadas recorrentes: 2\n",
    "- Número de neurônios ocultos: 300\n",
    "- Funcção de ativação: ReLU\n",
    "- Taxa de dropout: 0\n",
    "- Ottimizador: Adam\n",
    "- Learning rate: 0.01\n",
    "- Weight decay: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(, 'wb') as f:\n",
    "best_model.eval()\n",
    "torch.save(best_model.state_dict(), 'models/nn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can replace pickle with joblib or cloudpickle\n",
    "#from pickle import load\n",
    "#with open(\"models/mlp_base.pkl\", \"rb\") as f:\n",
    "#    best_mlp = load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
